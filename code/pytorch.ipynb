{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch.ipynb",
      "provenance": [],
      "collapsed_sections": [
        "GGcQZU4QRRNS",
        "bmQ-Ft6HXB9U"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "b01407801eb4472f8108ef1dbf9f4387": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_598832004cb449bd913b3016921e42b1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3a805384f21740958a8d0df4da70f2cb",
              "IPY_MODEL_58e19de7d3ef4d018a67db4e60c0af74",
              "IPY_MODEL_304829cc958243f0a9665c988f866c8d"
            ]
          }
        },
        "598832004cb449bd913b3016921e42b1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3a805384f21740958a8d0df4da70f2cb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7bd3e8bc815c4183a7f2576bbdbd347c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_9baa080c78754c50a094ce61027d7568"
          }
        },
        "58e19de7d3ef4d018a67db4e60c0af74": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_70dc2d202d324345a64e6b5d787742b1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 170498071,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 170498071,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8c2c7ea42fcc488f9ea89ec20f6d3904"
          }
        },
        "304829cc958243f0a9665c988f866c8d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d8c5b346a8e34ffaafe0c47ba1bac6e4",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 170499072/? [00:02&lt;00:00, 75765051.68it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_4e493718f5074968b324f3eb50cccbaf"
          }
        },
        "7bd3e8bc815c4183a7f2576bbdbd347c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "9baa080c78754c50a094ce61027d7568": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "70dc2d202d324345a64e6b5d787742b1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8c2c7ea42fcc488f9ea89ec20f6d3904": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d8c5b346a8e34ffaafe0c47ba1bac6e4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "4e493718f5074968b324f3eb50cccbaf": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sh4kpqqrXTIq"
      },
      "source": [
        "# *PART1* 파이토치 기초\n",
        "### CNN모델 구조별 정확도와 파라미터 수 비교 그래프\n",
        "\n",
        "각 원의 크기는 파라미터 수를 의미하며 가장 큰 원은 1억 5000만 개의 파라미터로 구성된 모델\n",
        "\n",
        "VGG 계열 모델의 파라미터 수가 매우 많다. 흔히 파라미터 수가 많으면 그만큼 표현할 수 있는 능력이 높아지기 때문에 성능이 향상될 것이라 생각하지만 과적합의 문제로 학습에 이용되는 데이터에 대해서는 Task를 잘 수행할 수 있지만, 학습에 이용되지 않은 새로운 데이터에 대해서는 task를 잘 수행할 수 없는 현상이 발생\n",
        "\n",
        "따라서 파라미터 수를 무조건 늘리는 것이 중요한 것이 아니라 해당 Task를 수행하기 위해 적절한 수의 파라미터 수를 할당하고 학습에 이용되지 않는 데이터에 대해서도 Task를 정확히 수행하기 위해 일반화 과정이 꼭 필요하다. 일반화 과정에는 보통 weight decay, dropout, batch normalization 등과 같은 기법이 사용됨\n",
        "\n",
        "NASNet-A-Large 모델이 가장 높은 성능을 나타내고 있다. y축은 Top-1 Accuracy, top-5 Accuracy\n",
        "\n",
        "Top-1 Accuracy은 모델의 예측한 결과값 중 가장 높은 확률로 예측한 클래스가 실제 클래스와 동일한지를 평가하는 엄격한 기준\n",
        "\n",
        "Top-5 Accuracy는 모델의 예측한 결과값 중 상위 5개의 확률에 대해 실제 클래스가 포함되는지를 평가하는 비교적 덜 엄격한 기준\n",
        "\n",
        "y축을 보면 가장 높은 Top-1 Accuracy 수치는 80 수준, 가장 높은 Top-5 Accuracy 수치는 95 수준이다.\n",
        "\n",
        "즉, 그래프상에서 원의 크기가 작고 성능이 높은 모델이 가장 좋다. 동일한 성능을 나타내는 모델에 대해 파라미터 수가 적을수록 계산해야 하는 변수가 적어지기 때문에 계산양을 줄일 수 있다. 파라미터 수가 비슷하다면 성능이 높은 것이 당연히 좋다.\n",
        "\n",
        "x축은 G-FLOPs를 의미하고 G-FLOPs는 GPU FLoating Operations Per Second의 약자이다. 이는 초당 부동소수점 연산을 의미하며 흔히 GPU의 성능을 측정하는 요소이다. 각 모델을 학습하는 데 필요한 GPU의 성능을 의미한다. 가장 높은 성능을 보이고 상대적으로 적은 수치의 파라미터 값을 갖는 NASNet-A-Large 모델을 얻기 위해서는 그래프 내에 제시된 모델 중에서도 가장 좋은 성능을 갖고 있는 GPU를 이용했다고 볼 수 있다.\n",
        "\n",
        "많은 수의 파라미터를 이용해 모델을 설계할 때는 CPU보다 GPU가 훨씬 빨리 계산된다. CPU는 GPU에 비해 고차원의 일을 수행하는 능력을 가졌지만, 너무 많은 수의 파라미터 값을 계산하기에는 느리다. 하지만 GPU를 이용하면 파라미터 값을 병렬적으로 빠르게 계산할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FJnMmv4GRYXh"
      },
      "source": [
        "### **1.4 반드시 알아야 하는 파이토치 스킬**\n",
        "#### 4.1 tensor\n",
        "##### 1) scalar\n",
        "\n",
        "스칼라는 우리가 흔히 알고 있는 상숫값이다. 즉, 하나의 값을 표현할 때 1개의 수치로 표현한 것이다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6SImw6yfRPqx",
        "outputId": "030cfee3-ef69-4228-ffdf-d3f783f43f6b"
      },
      "source": [
        "import torch\n",
        "\n",
        "vector1 = torch.tensor([1.,2.,3.])\n",
        "print(vector1) # tensor([1.,2.,3.])\n",
        "\n",
        "vector2 = torch.tensor([4.,5.,6.,])\n",
        "print(vector2)\n",
        "\n",
        "add_vector = vector1 + vector2\n",
        "print(add_vector)\n",
        "\n",
        "sub_vector = vector1 - vector2\n",
        "print(sub_vector)\n",
        "\n",
        "mul_vector = vector1 * vector2\n",
        "print(mul_vector)\n",
        "\n",
        "div_vector = vector1 / vector2\n",
        "print(div_vector)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 2., 3.])\n",
            "tensor([4., 5., 6.])\n",
            "tensor([5., 7., 9.])\n",
            "tensor([-3., -3., -3.])\n",
            "tensor([ 4., 10., 18.])\n",
            "tensor([0.2500, 0.4000, 0.5000])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jRssH660zEMg",
        "outputId": "4cb21587-b016-4fd1-8e71-6ca72558a71d"
      },
      "source": [
        "import torch\n",
        "\n",
        "scalar1 = torch.tensor([1.])\n",
        "print(scalar1)\n",
        "\n",
        "scalar2 = torch.tensor([3.])\n",
        "print(scalar2)\n",
        "\n",
        "add_scalar = scalar1 + scalar2\n",
        "print(add_scalar)\n",
        "\n",
        "sub_scalar = scalar1 - scalar2\n",
        "print(sub_scalar)\n",
        "\n",
        "mul_scalar = scalar1 * scalar2\n",
        "print(mul_scalar)\n",
        "\n",
        "div_scalar = scalar1 / scalar2\n",
        "print(div_scalar)\n",
        "\n",
        "torch.add(scalar1, scalar2) # torch 내장 메서드를 통해 계산할 수 있다.\n",
        "torch.sub(scalar1, scalar2)\n",
        "torch.mul(scalar1, scalar2)\n",
        "torch.div(scalar1, scalar2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1.])\n",
            "tensor([3.])\n",
            "tensor([4.])\n",
            "tensor([-2.])\n",
            "tensor([3.])\n",
            "tensor([0.3333])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([0.3333])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GGcQZU4QRRNS"
      },
      "source": [
        "##### 3) 행렬\n",
        "\n",
        "행렬은 2개 이상의 벡터 값을 통합해 구성된 값. 벡터 값 간 연산 속도를 빠르게 진행할 수 있는 선형 대수의 기본 단위"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tl-okFBwW-8I",
        "outputId": "9f89321c-242b-42a5-ce5a-f9a71a9e5409"
      },
      "source": [
        "matrix1 = torch.tensor([[1.,2.],[3.,4.]])\n",
        "matrix2 = torch.tensor([[5.,6.],[7.,8.]])\n",
        "\n",
        "torch.add(matrix1, matrix2)\n",
        "\n",
        "torch.sub(matrix1, matrix2)\n",
        "\n",
        "torch.mul(matrix1, matrix2)\n",
        "\n",
        "torch.div(matrix1, matrix2)\n",
        "\n",
        "torch.matmul(matrix1,matrix2) # [[(1*5)+(2*7)],[(1*6)+(2*8)],[(3*5)+(4*7)],[(3*6)+(4*8)]], 행렬 곱 연산"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[19., 22.],\n",
              "        [43., 50.]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bmQ-Ft6HXB9U"
      },
      "source": [
        "##### 4) 텐서\n",
        "\n",
        "행렬은 2차원의 배열이라 표현하지만 텐서는 2차원 이상의 배열을 표현"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3dsSuAU9XbZh",
        "outputId": "c079e9f6-08cd-4b2a-899c-9195872863f3"
      },
      "source": [
        "tensor1 = torch.tensor([[[1.,2.], [3.,4.]],[[5.,6.],[7.,8.]]])\n",
        "tensor2 = torch.tensor([[[9.,10.],[11.,12.]],[[13.,14.],[15.,16.]]])\n",
        "\n",
        "sum_tensor = tensor1 + tensor2 # torch.add(tensor1,tensor2)\n",
        "print(sum_tensor)\n",
        "\n",
        "sub_tensor = tensor1 - tensor2 # torch.sub(tensor1,tensor2)\n",
        "print(sub_tensor)\n",
        "\n",
        "mul_tensor = tensor1 * tensor2 # torch.mul(tensor1,tnesor2)\n",
        "print(mul_tensor)\n",
        "\n",
        "div_tensor = tensor1 / tensor2 # torch.div(tensor1,tensor2)\n",
        "print(div_tensor)\n",
        "\n",
        "torch.matmul(tensor1,tensor2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[[10., 12.],\n",
            "         [14., 16.]],\n",
            "\n",
            "        [[18., 20.],\n",
            "         [22., 24.]]])\n",
            "tensor([[[-8., -8.],\n",
            "         [-8., -8.]],\n",
            "\n",
            "        [[-8., -8.],\n",
            "         [-8., -8.]]])\n",
            "tensor([[[  9.,  20.],\n",
            "         [ 33.,  48.]],\n",
            "\n",
            "        [[ 65.,  84.],\n",
            "         [105., 128.]]])\n",
            "tensor([[[0.1111, 0.2000],\n",
            "         [0.2727, 0.3333]],\n",
            "\n",
            "        [[0.3846, 0.4286],\n",
            "         [0.4667, 0.5000]]])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[[ 31.,  34.],\n",
              "         [ 71.,  78.]],\n",
              "\n",
              "        [[155., 166.],\n",
              "         [211., 226.]]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BXvowRIHZoPi"
      },
      "source": [
        "#### 4.2 autograd\n",
        "\n",
        "back propagation을 이용해 파라미터를 업데이트하는 방법은 autograd 방식으로 쉽게 구현할 수 있도록 설정되어 있다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WBzR9JinYdiE"
      },
      "source": [
        "import torch\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "\n",
        "BATCH_SIZE = 64     # 딥러닝 모델에서 파라미터를 업데이트할 때 계산되는 데이터의 개수, \n",
        "                    # 즉 batch_size 수만큼 데이터를 이용해 output을 계산하고 batch_size 수만큼 출력된 결괏값에 대한 오찻값을 계산, \n",
        "                    # batch_size 수만큼 계산된 오찻값을 평균해 back propagation을 적용하고 이를 바탕으로 파라미터를 업데이트한다. batch_size는 input으로 이용되는 데이터가 64개라는 것을 의미\n",
        "INPUT_SIZE = 1000   # input의 크기이자 입력층의 노드 수를 의미, input_size는 딥러닝 모델에서의 입력층의 노드 수를 의미한다. 즉, 입력 데이터의 크기, \n",
        "                    # 즉, 1000크기의 벡터 값을 의미한다.따라서 1000크기의 벡터 값을 64개 이용한다는 의미이다. (64,1000)\n",
        "HIDDEN_SIZE = 100   # input을 다수의 파라미터를 이용해 계산한 결과에 한 번 더 계산되는 파라미터 수. 즉, 입력층에서 은닉층으로 전달됐을 때 은닉층의 노드 수를 의미. 이 예제는 (64,1000)의 input들이 (1000,100) 크기의 행렬과 행렬 곱을 계산\n",
        "OUTPUT_SIZE = 10    # 최종으로 출력되는 값의 벡터의 크기. 보통 output의 크기는 최종으로 비교하고자 하는 레이블의 크기와 동일하게 설정. \n",
        "                    # 예를 들어 10개로 분류하려면 크기가 10짜리의 원-핫 인코딩을 이용하기 때문에 output의 크기를 10으로 맞추기도 하며 5 크기의 벡터 값에 대해 mean squred error를 계산하기 위해 output의 크기를 5로 맞추기도 한다.\n",
        "                    \n",
        "# 더미 변수 : 0 또는 1만으로 표현되는 값으로 어떤 특징이 존재하는가 존재하지 않는가를 표시하는 독립변수이다. 더미 변수를 만드는 방법으로는 크게 두 가지, 원핫인코딩 방식과 축소랭크 방식이 있다.\n",
        "# 원핫인코딩 : 해당하는 값에 대해서 맞으면 1, 아니면 0을 부여. 즉 고유값에 해당되는 특징에는 1, 나머지는 0\n",
        "# 축소랭크 : 특정한 하나의 범주값을 기준값으로 설정하고, 기준값 더미변수의 가중치는 항상 1으로 놓는다. 기준값을 제외하고 해당하는 값에 대하여 맞으면 1, 아니면 0을 부여. 즉, 기준값은 1로 두고, 이를 제외하고 고유값에 해당되는 특징에 1을 부여\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HKLPjnG0eS5H"
      },
      "source": [
        "DEVICE = torch.device('cpu')\n",
        "BATCH_SIZE = 64\n",
        "INPUT_SIZE = 1000\n",
        "HIDDEN_SIZE = 100\n",
        "OUTPUT_SIZE = 10\n",
        "\n",
        "x = torch.randn(BATCH_SIZE,                   # input 설정                                              \n",
        "                INPUT_SIZE,                   # randn 는 평균이 0, 표준편차가 1인 정규분포에서 샘플링한 값으로, 데이터를 만든다는 것. 즉 크기가 1000짜리의 벡터를 64개 만들기 위해 설정. x는 (64,1000)이 생성된다.\n",
        "                device = DEVICE,              # DEVICE를 이용해 계산할 것이고\n",
        "                dtype = torch.float,          # 데이터 형태는 float으로 설정\n",
        "                requires_grad = False)        # input으로 이용되기 때문에 gradient를 계산할 필요가 없다. grad는 파라미터를 업데이트하기 위해 gradient를 계산하는 것이다.\n",
        "\n",
        "y = torch.randn(BATCH_SIZE,                   # output도 위와 동일\n",
        "                OUTPUT_SIZE,                  # output과의 오차를 계산하기 위해 output의 크기를 10으로 설정\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = False)\n",
        "\n",
        "w1 = torch.randn(INPUT_SIZE,                  # 본격적으로 업데이터할 파라미터 값을 설정, 이 때 행렬 곱을 하기 위해 input의 데이터 크기가 10000이며 다음 행의 값이 1000이어야 한다.\n",
        "                HIDDEN_SIZE,                  # 행렬 곱을 이용해 100 크기의 데이터를 생성하기 위해 (1000,100) 크기의 데이터를 생성\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = True)         # 파라미터를 업데이트해야 하기에 gradient를 한다.\n",
        "\n",
        "w2 = torch.randn(HIDDEN_SIZE,                 # w2는 w1과 x를 행렬 곱한 결과에 계산할 수 있는 데이터여야 한다. w1과 x의 행렬 곱을 한 결과는 (1,100)이며, (100,10)행렬을 통해 output을 계산할 수 있도록 w2의 모양을 설정\n",
        "                OUTPUT_SIZE,\n",
        "                device = DEVICE,\n",
        "                dtype = torch.float,\n",
        "                requires_grad = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HuXSOqtZegvo",
        "outputId": "0b2699ca-ee4c-4b97-d62e-dd717d71fda3"
      },
      "source": [
        "learning_rate = 1e-6 # gardient를 계산한 결과값에 learning_rate만큼 곱한 값을 이용해 업데이트된다. 이를 learning rate라고 한다. 딥러닝 모델에서 파라미터 값을 업데이트할 때 가장 중요한 하이퍼파라미터이기도 함\n",
        "\n",
        "for t in range(1,501):                        # 500번 반복해 파라미터 값을 업데이트하기 위해 반복문을 설정\n",
        "  y_pred = x.mm(w1).clamp(min = 0).mm(w2)     # 딥러닝 모델의 결과값을 보통 예측값이라 표현한다. 딥러닝 모델의 input인 x와 w1 간의 행렬 곱을 이용해 나온 결과값을 계산. clamp라는 메서드를 이용해 비선형 함수를 적용\n",
        "                                              # 층과 층 사이에 비선형 함수를 이용해 높은 표현력을 지니는 방정식을 얻게 된다. \n",
        "                                              # 여기서 clamp는 ReLU와 같은 역할. 최솟값은 0, 0보다 큰 값은 자기 자신을 갖게 되는 메서드, clamp를 이용해 계산된 결과와 w2를 이용해 행렬 곱을 한 번 더 계산\n",
        "                                              # 행렬 곱을 한 결과는 딥러닝 모델에서의 output을 의미하며 이는 예측값이라고 표현되기 때문에 y_pred로 지정\n",
        "  loss =(y_pred - y).pow(2).sum()             # 예측값과 실제 레이블 값을 비교해 오차를 계산한 값을 loss 라 한다. y_pred와 실제 레이블을 의미하는 y 간의 차잇값을 계산한 후 pow(제곱을 취함) 함수를 이용해 제곱을 취한다. 차를 제곱하여 합함\n",
        "  if t % 100 == 0:                            # 반복문 횟수와 오차를 출력\n",
        "    print(\"Iteration: \", t, \"\\t\", \"Loss: \", loss.item())\n",
        "  loss.backward()                             # backward 를 사용하면 각 파라미터 값에 대해 gradient를 계산하고 이를 통해 back propagation을 진행한다는 것을 의미\n",
        "\n",
        "  with torch.no_grad():\n",
        "    w1 -= learning_rate * w1.grad             # w1의 gradient 값을 의미하는 w1.grad에 위에서 설정한 learning_rate값을 곱한 결괏값을 기존 w1에서 빼준다.\n",
        "    w2 -= learning_rate * w2.grad             # 음수를 이용하는 이유는 loss 값이 최소로 계산될 수 있는 파라미터 값을 찾기 위해 gradient 값에 대한 반대 방향으로 계산한다는 것을 의미\n",
        "\n",
        "    w1.grad.zero_()                           # 다음 반복문을 진행할 수 있도록 gradient 값을 0으로 설정\n",
        "    w2.grad.zero_()\n",
        "\n",
        "# 이때 반복할수록 loss 값이 줄어든다는 것은 input이 w1과 w2를 통해 계산된 결과값과 y 값이 점점 비슷해진다는 것, y 값과 비슷한 output을 계산할 수 있도록 w1과 w2가 계산된다는 것을 알 수 있다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Iteration:  100 \t Loss:  507.2475280761719\n",
            "Iteration:  200 \t Loss:  4.278642654418945\n",
            "Iteration:  300 \t Loss:  0.08332622796297073\n",
            "Iteration:  400 \t Loss:  0.002188140992075205\n",
            "Iteration:  500 \t Loss:  0.00016944925300776958\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YugZUFWw0X_Q"
      },
      "source": [
        "# *PART2* AI Background"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gwdUqFoA0jS0"
      },
      "source": [
        "##  1. 인공지능이란?\n",
        "컴퓨터가 데이터를 이용해 학습할 수 있도록 하는 기술"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YBY-81hbnp5b"
      },
      "source": [
        "## 2. 머신러닝\n",
        "### 2.1 머신러닝과 딥러닝\n",
        "머신러닝: 행과 열이 존재하는 행렬(정형화된 데이터)을 이용해 예측 또는 분류하고 싶을 때 사용\n",
        "\n",
        "딥러닝: 이미지 또는 텍스트와 같은 정형화돼 있지 않은(비정형 데이터) 데이터를 사용활 때는 사용\n",
        "\n",
        "### 2.2 머신러닝의 종류\n",
        "#### 2.2.1 모델학습\n",
        "머신러닝 모델의 학습 목표는 '데이터(input)에 대한 모델의 결과(output)가 정답(label)에 가깝게 나오도록 학습시키는 것'이다.\n",
        "\n",
        "방법에는 \n",
        "1. 데이터를 모델에 넣고 결과를 냄\n",
        "2. 결과를 정답과 비교해 다른 만큼 모델을 변경\n",
        "3. 특정 조건이 만족할 때까지 1, 2를 반복\n",
        "\n",
        "#### 2.2.2 손실 함수\n",
        "위 2번 단계에서 모델의 결과값이 실제 정답과 차이를 수치화하고 그것을 함수화한 것을 손실함수(loss function) 또는 비용함수(cost function)이라 한다. \n",
        "\n",
        "다시 말해, 손실함수는 모델의 선택(결과)에 대해 얼마나 손실이 일어났는지를 정의하는 함수로 이 의미에 맞게 모델을 손실 함수의 값을 줄이는 방향으로 학습한다. 손실함수는 보통 스칼라(scalar)값으로 정의하는데, 모델이나 task에 따라 다양한 종류가 존재한다. loss를 어떻게 설정하느냐가 모델 학습의 중요한 핵심 요인이 되기도 한다. 손실 함수 중 가장 대표적인 함수로는 mean squared error(MSE)를 들 수 있다. 수식은 \n",
        "\n",
        "* xi: ith data\n",
        "* yi: ith data\n",
        "* ^yi: ith output\n",
        "* n: the number of data\n",
        "\n",
        "MSE = 1/n sigma(i=1~n)(yi-^yi)^2\n",
        "\n",
        "### 2.3 머신러닝의 구분\n",
        "#### 2.3.1 지도학습\n",
        "데이터와 결과가 주어지고 그를 바탕으로 예측하는 것\n",
        "\n",
        "즉, 데이터와 결과가 무조건 존재해야 한다.\n",
        "\n",
        "y=f(x) 에서 함수f를 머신러닝 모델이라 한다.\n",
        "\n",
        "x를 독립 변수 또는 Feature, y를 종속 변수, 반응변수 또는 타깃변수라 한다.\n",
        "\n",
        "지도학습 내에서도 두 가지로 나뉘어 \n",
        "1. 회귀\n",
        "\n",
        "y=f(x)에서 y가 실수형 값을 가질 때 풀어야 하는 문제를 '회귀' 문제, 이때의 함수 f를 회귀 모델이라 한다.\n",
        "\n",
        "2. 분류\n",
        "\n",
        "반면, 위 수식에서 y가 특정 class(성별, 흡연 유무 등 셀 수 있는 개수의 선택지를 가진 경우)를 가질 때 풀어야 하는 문제를 '분류' 문제라 하며 이때의 함수 f를 분류 모델이라 한다.\n",
        "\n",
        "키를 이용해 몸무게를 예측하고 싶을 때 또는 아파트 가격이나 주식의 가격을 예측하고 싶을 때는 '회귀 모델'을, 비만여부, 아파트 또는 주식의 가격 상승 여부를 예측하고 싶을 때는 '분류 모델'을 고려해야 한다.\n",
        "\n",
        "#### 2.3.2 비지도 학습\n",
        "데이터는 제공하지만 정답은 제공하지 않는 학습 방법\n",
        "\n",
        "독립 변수만으로 새로운 Feature를 찾아낸다거나 군집화하는 등 데이터 내에서 새로운 패턴을 찾아내는 것에 초점을 맞춘다. \n",
        "\n",
        "대표적 방법 - 군집화, 차원 축소법\n",
        "\n",
        "#### 2.3.3 강화학습\n",
        "수많은 시뮬레이션을 통해 컴퓨터가 현재 상태에서 어떤 행동을 취해야 먼 미래의 보상을 최대로 할 것인지를 학습하는 알고리즘\n",
        "\n",
        "상태(state),행동(action), 보상(reward), 다음 상태(next state)가 있어야 한다. 즉, 시뮬레이션된 연속적인 데이터의 값이 존재해야 한다.\n",
        "\n",
        "알파고에서 \n",
        "*   현재 바둑판 - '현재 상태'\n",
        "*   바둑의 수 - '행동'\n",
        "*   바둑의 수를 두고 난 후의 바둑판 - '다음 행동'\n",
        "\n",
        "보상은 이 수를 두면 이길지, 질지 알 수 없기에 기본적으로 0으로 두고 대국이 끝난 후에 이겼는지, 졌는지 여부로 부여한다. 대국이 끝나면 승패 여부로 과거에 뒀던 수가 좋은 수인지, 나쁜 수 인지 알 수 있다. \n",
        "\n",
        "### 2.4 지도학습 모델의 종류\n",
        "#### 2.4.1 선형 회귀 모델\n",
        "y=ax+b 와 같은 형태로 X를 이용해 Y를 예측\n",
        "\n",
        "독립 변수 하나만으로 종속 변수를 예측하는 모델을 '단순 선형 회귀 모델'이라 하고, 변수가 여러 개일 때 적합시키는 회귀 모델을 다중 선형 회귀 모델, 선형 회귀 모델은 우수하지는 않지만 변수의 설명력 측면에서는 장점\n",
        "\n",
        "#### 2.4.2 회귀 계수 축소 모델\n",
        "변수가 많을수록 회귀 모델의 성능이 낮아진다. 각각의 독립 변수가 지니고 있는 설명력을 중복으로 가져가지 못한다. 따라서 하나만 적합시켰을때보다 그 변수의 영향력이 적게 된다. 따라서 적절한 변수를 설정하는 것이 중요\n",
        "\n",
        "이 문제를 해결하기 위한 방법이 회귀 계수 축소 모델이다. MSE를 최소화시키고 회귀 계수 자체도 축소시키도록 Loss를 구성한다. \n",
        "\n",
        "축소 모델은 크게 Lasso, Ridge, ElasticNet로 나눌 수 있다. \n",
        "\n",
        "Lasso는 회귀계수가 완전히 0이 되도록 축소시킬 수 있다.\n",
        "\n",
        "Ridge는 회귀계수가 0으로 가까워지지만 완전히 0이 되지 않는다. 변수를 선택한다는 점에서 Lasso가 좋지만, 성능은 Ridge가 우위에 있다. ElasticNet은 두 개의 중간 모델\n",
        "\n",
        "#### 2.4.3 의사 결정 나무\n",
        "해석력이 높고 직관적인 모델, 높은 설명력을 가지고 있지만 예측은 부족하다.\n",
        "\n",
        "#### 2.4.4 k-NN\n",
        "가장 가까운 k개의 데이터를 이용해 해당 데이터의 출력 값을 예측하는 직관적인 모델\n",
        "\n",
        "k는 사용자가 사전에 지정해야하는 하이퍼파라미터로, 데이터 간 거리 측정 지표나 k개 데이터의 정보를 종합하는 방법을 선택해 모델의 변화를 준다.\n",
        "k를 5라고 설정하면 새로운 데이터가 들어왔을 때 주변 5개의 데이터를 찾고 여기서 가장 비중이 높은 class를 분류\n",
        "\n",
        "#### 2.4.5 신경망\n",
        "딥러닝의 기초가 되는 모델\n",
        "\n",
        "신경망은 기본적으로 입력(input)층, 은닉(hidden)층, 출력(output)층으로 구성\n",
        "\n",
        "각 층을 연결하는 노드의 가중값을 업데이트하면서 학습\n",
        "\n",
        "MSE와 같은 Loss를 설정하고 이 Loss가 최소화되는 지점을 찾기 위해 가중값을 점차 업뎃한다. \n",
        "\n",
        "신경망은 내가 지니고 있는 학습 데이터로 완벽한 모델을 만들 수 있다. 즉, 정확도가 100%인 모델을 구축할 수 있다는 것이다.하지만 학습된 데이터 내에서만 100%가 될 수 있기에 예측은 잘 하지 못한다. \n",
        "\n",
        "학습에 사용된 데이터에만 완벽히 적합되는 현상을 과적합이라 한다.\n",
        "\n",
        "#### 2.4.6 SVM (Support Vector Machine)\n",
        "신경망의 과적합 문제를 보완한 모델\n",
        "\n",
        "SVM은 직선을 그었을 때 Class 간의 거리가 각각 비슷하도록, 즉 직선을 가운데로 잘 긋도록 하는 학습 방법\n",
        "\n",
        "내가 지니고 있는 학습 데이터 내에서 일정 에러를 허용한 상태에서 직선을 그을 수 있다. 즉, 학습 과정 내에서 과적합을 어느 정도 방지할 수 있다.\n",
        "\n",
        "데이터의 차원이 커질수록 변수나 데이터 수가 많아질수록 학습하는 시간이 매우 오래 걸린다.\n",
        "\n",
        "#### 2.4.7 Ensemble Learning\n",
        "다양한 모델을 만들어 우리가 예측하고자 하는 모델에 대한 다양한 의견을 수렴해 투표를 바탕으로 최종적인 예측 값을 만들고자 한다.\n",
        "\n",
        "* Bagging - 데이터를 재구성해 모델을 만듬 \n",
        "* RandomForest - 데이터와 변수를 랜덤으로 추출해 모델을 만듬 \n",
        "* Boosting - 잘 맞추지 못하는 데이터를 좀 더 집중적으로 학습시킴 \n",
        "* stacking - 여러 모델의 예측값을 다시 독립 변수로 활용\n",
        "\n",
        "일반적으로 학습 성능을 높이는 데 많이 사용하는 모델은 boosting 이고, 그중에서도 예측값과 실제값의 차이를 점차 줄여 나가면서 학습시키는 gradient boosting\n",
        "\n",
        "### 적합성 평가\n",
        "우리가 가지고 있는 데이터 내에서 모형을 잘 선택한다 해도 과접합됐는지 알기 어렵기 때문에 우리가 갖고 있는 데이터를 분할해 과적합 정도를 판단한다. 이를 실험 설계를 통한 적합성 평가라 한다. 학습, 검증, 테스트 데이터로 랜덤하게 분할하여 평가한다.\n",
        "\n",
        "### K-Fold Cross Validation\n",
        "가지고 있는 데이터가 많지 않다면 데이터를 분할하기에 부담이 될수 있다. 이때 K-Fold Cross Validation를 사용하면 어느정도 보완할 수 있다. 학습 데이터를 모델에 학습시킬 때 사용자가 지정해야 할 다양한 파라미터를 하이퍼파라미터라고 한다.\n",
        "1. 가지고 있는 데이터를 랜덤하게 k개의 fold로 구분한다. k는 하이퍼파라미터, 보통 5 또는 10으로 설정한다.\n",
        "2. k를 5로 가정하고 5개의 fold로 데이터를 랜덤하게 분할한 후 첫번째 fold를 제외한 나머지 fold 데이터를 합쳐 학습 데이터로 사용, 첫번째 fold를 검증 데이터로 사용\n",
        "3. 두번째 fold를 검증 데이터로 사용하고 나머지 fold를 학습 데이터로 사용한다. 이를 k번 반복하면 모든 데이터를 학습, 검증 데이터로 사용할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iHq7I3yY01gV"
      },
      "source": [
        "## 3. 인공 신경망\n",
        "### 3.1 퍼셉트론\n",
        "Feed-Forward Network 모형이며 선형 분류 모델의 형태를 띄고 있다.\n",
        "\n",
        "출력 값이 0보다 크면 1, 작으면 -1로 결과값을 내보내 분류하는 모델\n",
        "\n",
        "임곗값의 초과 여부를 판단하는 함수를 활성화 함수라 한다.\n",
        "\n",
        "퍼셉트론은 처음에 weight를 랜덤하게 설정한 후 점차 수를 개선해 나간다. \n",
        "\n",
        "### 3.1.1 MLP\n",
        "입력층 - 은닉층 - 출력층으로 이루어져있다.\n",
        "\n",
        "각 원을 노드라고 하며, 회귀 분석을 하고자 하는 경우 output node수는 1, 0부터 9까지의 숫자 분류를 하고자 하는 경우 output node수는 10이 된다.\n",
        "\n",
        "input -> hidden -> output 의 과정을 feed forward라 한다.\n",
        "\n",
        "보통 뒤의 weight를 먼저 업데이트하고 앞의 weight를 업데이트한다. 이를 back propagation이라 한다.\n",
        "\n",
        "feed forward와 back propagation을 반복하면서 weight를 업데인트하며 점차 신경망의 output이 실제 값에 가까워지면서 모델의 학습이 이루어진다. 반복하는 횟수를 epoch(세대)라고 한다. 100epoch라 하면 전체 데이터셋에 대해 100번의 반복을 햇다는 것이다. \n",
        "\n",
        "### 3.1.2 활성 함수\n",
        "어떤 신호를 입력받아 이를 적절히 처리해 출력해주는 함수를 의미한다.\n",
        "\n",
        "### 3.1.3 시그모이드 함수\n",
        "비선형 활성 함수 중 가장 기본적으로 사용하는 함수는 시그모이드 함수이다. 입력 값이 0 이하면 0.5이하의 값을 출력하고, 0이상이면 0.5이상의 값을 출력한다. \n",
        "\n",
        "비선형 활성 함수를 사용하는 이유는 우리가 풀고자 하는 문제의 형태가 선형적이 아니기 때문이다.\n",
        "\n",
        "### 3.1.4 gradient descent method\n",
        "기울기 경사 하강법이라 한다.\n",
        "\n",
        "loss function을 MSE로 설정해 MSE가 감소하도록 회귀계수(베타)를 추적한다. 이 MSE를 회귀계수에 대한 함수로 볼 수 있다. MSE는 회귀계수에 대한 함수이므로 이 MSE가 최소가 되는 지점을 찾을 수 있는데, MSE를 회귀계수로 미분해 기울기가 0이 되는 지점을 찾는다. 선형일 경우는 직선으로 이루어진 간단한 모델이므로 MSE를 회귀계수로 미분해 기울기가 되는 지점을 간단히 찾을 수 있다.\n",
        "\n",
        "신경망 모형에서는 이런 방법이 어렵기에 MSE를 신경망 모형의 Weight로 계속 미분해 기울기를 점차 감소시켜 최소가 되는 지점을 찾아가야 한다. gradient를 구할 때 일반적으로 구해지는 gradient의 크기는 매우 크기때문에 크기를 조절해줄 필요가 있다. 이 조절해주는 상수를 learning rate라 부른다.\n",
        "\n",
        "여기서 모든 데이터를 한 번에 feed forward하지 않고 나눠서 진행한다. 전체 데이터가 1000개라 하면 100개씩 쪼개 10번 반복한다. 이 한 과정을 epoch라 하고 여기서 100개의 데이터를 mini-batch라 하며 100의 크기에 대해서는 batch size라 한다.\n",
        "\n",
        "#### 3.1.5 universal approximation theorem\n",
        "hidden layer가 1개 이상인 신경망, 즉 MLP는 '학습 데이터 내에서' 어떤 함수든 근사시킬 수 있다. 하지만 실제 데이터에는 다를 수 있다. 이를 과적합이라 한다.\n",
        "\n",
        "### 3.2 신경망 모형의 단점\n",
        "#### 3.2.1 과적합\n",
        "신경망의 목적은 학습 데이터 내에서 loss를 최소화하는 것이다.\n",
        "\n",
        "#### 3.2.2 gradient vanishing problem\n",
        "기울기가 사라지는 현상을 의미하는 것\n",
        "\n",
        "output의 범위는 0~1인데 back propagation하는 과정에서 hidden layer을 미분하는 과정에서 이 값을 에러 값에 곱해야 하는데 계속 곱하다보면 0에 수렴하게 된다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ui-mqoO505IY"
      },
      "source": [
        "## 4. 성능지표\n",
        "모델의 성능을 측정하는 방법, 즉 loss를 줄이는 것\n",
        "\n",
        "1. MSE: 기본적으로 회귀 모형에서 많이 사용하는 loss이자 성능 지표. 예측값과 실제 값의 차이에 대해 평균 제곱합의 개념으로서 낮을수록 좋은 성능 지표\n",
        "2. MAPE: MSE는 상대적인 성능 지표로 같은 문제에 대해 다른 모델을 적용했을 때만 가능한 모델이다. Mean Absolute Percentage Error는 비교적 절대적인 지표로 예측값과 실제값의 차이를 실제값으로 나눠 실제 값 대비 몇 % 정도으 ㅣ오차가 있는지에 대한 성능 지표\n",
        "3. 정확도: 분류 문제에서 가장 많이 사용하는 성능지표. 전체 데이터 중 실제로 잘 예측했는지에 대한 비율을 의미한다. 정밀도, 재현율, 특이도 중에서 상황에 맞게 설정해야 한다.\n",
        "4. F1-Measure: Class Imbalance 상황에서 많이 사용하는 성능 지표로 precision과 recall의 조화 평균으로 불량으로 예측했을 때 정확히 예측한 비율과 실제 불량 중 잘 예측한 비율을 말한다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWoSPvePicsf"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import MNIST\n",
        "import tensorflow_datasets\n",
        "import torchvision.transforms as transforms\n",
        "import tqdm.notebook as tqdm\n",
        "\n",
        "'''1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "\n",
        "print(torch.__version__,DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32 # MLP모델을 학습할 때 필요한 데이터 개수의 단위, 즉 MINI-BATCH 1개 단위에 대해 데이터가 32개로 구성\n",
        "EPOCHS = 10 # 1개의 MINI-BATCH를 이용해 학습하는 횟수를 Iteration, 전체 데이터를 이용해 학습을 진행한 횟수를 epoch라 한다.\n",
        "\n",
        "'''2. MNIST 데이터 다운로드(Train set, Test set 분리하기) '''\n",
        "train_dataset = datasets.MNIST(root = \"../data/MNIST\",                  # 데이터가 저장될 장소를 지정, 여기서'../'는 상위폴더\n",
        "                               train = True,                            # 대상 데이터가 MLP모델을 학습하기 위해 이용하는 학습용 데이터인지 학습된이후 성능을 검증하기 위한 검증용 데이터인지를 지정한다. true가 학습용 false는 검증용 데이터\n",
        "                               transform  = transforms.ToTensor(),      # 이미지 데이터로 다운받아지기 때문에, tensor형태로 변경한다. 0~255 범위의 스칼라 값인 픽셀을 안정화를 위해 0~1 범위에서 정규화 과정을 진행한다.\n",
        "                               download = True)                         # 해당 데이터를 인터넷상에서 다운로드해 이용할 것인지를 지정한다.\n",
        "\n",
        "test_dataset = datasets.MNIST(root = \"../data/MNIST\",\n",
        "                              train = False,\n",
        "                              transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,     # mini-batch 단위로 할당하고자 하는 데이터셋을 지정, dataloader함수를 이용해 mini-batch를 구성, 할당하고자 하는 데이터셋을 지정\n",
        "                                           batch_size = BATCH_SIZE,     # mini-batch 1개 단위를 구성하는 데이터의 개수를 지정\n",
        "                                           shuffle = True)              # 컴퓨터가 순서를 암기하지 못하도록 데이터의 순서를 섞는다.\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "'''3. 데이터 확인하기 (1) '''\n",
        "for (x_train,y_train) in train_loader:\n",
        "  print('x_train:', x_train.size(), 'type:', x_train.type()) # 32개의 이미지 데이터가 1개의 mini-batch를 구성, 가로 28개, 세로 28개의 픽셀로 구성, 채널이 1이므로 gray scale로 이루어진, 즉 흑백으로 이루어진 이미지 데이터\n",
        "  print('y_train:', y_train.size(), 'type:', y_train.type()) # 32개의 이미지 데이터 각각에 label 값이 1개씩 존재하기 때문에 32개의 값을 가지고 있다. "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 111
        },
        "id": "ueAatUAPSodc",
        "outputId": "f450912f-b69d-4a98-bb2a-ef042f8d6a22"
      },
      "source": [
        "'''4. 데이터 확인하기 (2) '''\n",
        "pltsize = 1                                                             \n",
        "plt.figure(figsize=(10*pltsize,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1,10, i +1)\n",
        "  plt.axis('on')\n",
        "  plt.imshow(x_train[i,:,:,:].numpy().reshape(28,28), cmap =\"gray_r\")\n",
        "  plt.title('Class: ' + str(y_train[i].item()))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 875
        },
        "id": "v7g7slU1CjGb",
        "outputId": "71130f2b-7c35-4012-8a8f-fbb9766cc612"
      },
      "source": [
        "''' 5. MLP(Multi Layer Perceptron) 모델 설계하기 '''\n",
        "class Net(nn.Module):                 # nn.module클래스를 상속받는 NET클래스, nn.module클래스를 상속받았을 때, nn.module클래스가 이용할 수 있는 함수를 그대로 이용 가능\n",
        "  def __init__(self):                 # net클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드\n",
        "    super(Net,self).__init__()        # nn.module 내에 있는 메서드를 상속받아 이용\n",
        "    self.fc1 = nn.Linear(28*28,512)   # fully connected layer를 정의, 가로 픽셀 수*세로 픽셀 수 * 채널 수 크기의 노드 수를 설정, 두번째 노드 수를 512로 설정할 것이기에 output의 노드 수는 512로 설정\n",
        "    self.fc2 = nn.Linear(512,256)     # output의 노드 수를 input으로 받아 세번째 노드 수로 사용할 256을 output으로 설정\n",
        "    self.fc3 = nn.Linear(256,10)      # 0부터 9까지 총 10가지 클래스를 표현하기 위한 label 값은 원핫인코딩으로 표현, (원핫인코딩 : 해당하는 값에 대해서 맞으면 1, 아니면 0을 부여. 즉 고유값에 해당되는 특징에는 1, 나머지는 0)\n",
        "  def forward(self, x):               # net클래스를 이용해 설계한 MLP 모델의 forward propagation을 정의, 즉 input -> output의 과정을 나열\n",
        "    x = x.view(-1,28*28)              # MLP모델은 1차원의 벡터 값을 입력으로 받는다. 이미지는 2차원이기에 1차원으로 바꾸기 위한 View메서드를 이용해 784크기의 1차원 데이터로 변환해 진행, 이 과정을 flatten한다고 한다.\n",
        "    x = self.fc1(x)                   \n",
        "    x = F.sigmoid(x)                  # pytorch 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수인 sigmoid()를 이용해 두번째 층의 input으로 계산\n",
        "    x = self.fc2(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)     # log.softmax()를 이용해 최종 output을 계산 \n",
        "                                      # 0~9까지 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값을 계산, 이때 loss에 대한 gradient 값을 원활하게 계산하기 위해 log_softmax를 사용\n",
        "    return x\n",
        "\n",
        "''' 6. optimizer, objective function 설정하기 '''\n",
        "model = Net().to(DEVICE)                                                    # 5에서 정의한 MLP모델을 기존에 선정한 DEVICE에 할당한다. DEVICE장비를 이용해 MLP모델을 완성하기 위해서\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)  # Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 optimizer을 정의\n",
        "                                                                            # SGD알고리즘을 사용해 업데이트하는데, learning rate를 0.01, optimizer의 관성을 나타내는 momentum을 0.5\n",
        "criterion = nn.CrossEntropyLoss()                                           # MLP 모델의 output 값과 계산할 label 값은 class를 표현하는 원핫 인코딩 값이다. 이 두개의 Loss를 계산하기 위한 함수\n",
        "\n",
        "print(model)\n",
        "\n",
        "''' 7. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):                    # 이미지 데이터와 레이블 데이터를 이용해 MLP모델을 학습하는 train함수를 정의\n",
        "  model.train()                                                             # 기존에 정의한 MLP모델을 학습 상태로 지정\n",
        "  for batch_idx,(image, label) in enumerate(train_loader):                  # 기존의 train_loader에 이미지와 레이블 데이터가 mini-batch단위로 묶여있다. 저장된 데이터를 순서대로 이용해 MLP를 학습\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "    optimizer.zero_grad()                                                   # 기존에 정의한 장비에 이미지 데이터와 레이블을 할당할 경우 \n",
        "                                                                            # 과거에 이용한 mini-batch 내에 있는 이미지 데이터와 레이블 데이터를 바탕으로 계산된 loss의 gradient값이 optimizer에 할당돼 있으므로 optimizer의 gradient 초기화\n",
        "    output = model(image)                                                   # 장비에 할당된 이미지 데이터를 MKP모델의 input으로 이용해 output을 계산\n",
        "    loss = criterion(output,label)                                          # 계산된 ouptut과 장비에 할당된 레이블 데이터를 기존에 정의한 crossentropy를 이용해 loss를 계산\n",
        "    loss.backward()                                                         # 계산한 loss를 바탕으로 back propagation을 통해 계산된 gradient 값을 할당\n",
        "    optimizer.step()                                                        # 각 파라미터에 할당된 gradient 값을 이용해 파라미터 값을 업데이트한다.\n",
        "    \n",
        "    if batch_idx % log_interval == 0:\n",
        "      print(\"train epoch: {} [{}/{}({:.0f}%]\\tTrain Loss: {:.6f}\".format(Epoch,batch_idx * len(image),len(train_loader.dataset),100.*batch_idx / len(train_loader),loss.item()))\n",
        "\n",
        "\n",
        "''' 8. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):                                           # MLP모델 학습 과정 또는 학습이 완료된 상태에서 MLP모델의 성능을 평가 함수\n",
        "  model.eval()                                                              # 학습 과정 또는 학습이 완료된 MLP모델을 평가상태로 지정한다.\n",
        "  test_loss = 0                                                             # test_loader내의 데이터를 이용해 loss값을 계산하기 위해 test_loss를 0으로 지정\n",
        "  correct = 0                                                               # 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 0으로 임시 설정\n",
        "\n",
        "  with torch.no_grad():                                                     # gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 gradient의 흐름을 억제\n",
        "    for image, label in test_loader:                                        \n",
        "      image = image.to(DEVICE)                                              \n",
        "      label = label.to(DEVICE)\n",
        "      output = model(image)                                                 # 장비에 할당한 이미지 데이터를 MLP 모델의 input으로 output을 계산\n",
        "      test_loss += criterion(output, label).item()                          # 계산된 output과 장비에 할당된 레이블 데이터를 기존에 정의한 crossentropy를 이용해 loss값을 계산한 결과값을 test_loss에 더해 업데이트\n",
        "      prediction = output.max(1, keepdim = True)[1]                         # MLP 모델의 Output 값은 크기가 10인 벡터 값이기에 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다 판단\n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item()      # MLP모델이 예측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)                                     # 계산된 test_loss의 값을 test_loader 내에 존재하는 mini-batch 개수만큼 나누어 평균 loss값을 계산\n",
        "  test_accuracy = 100*correct/len(test_loader.dataset)                      # test_loader 데이터 중 얼마나 맞췄는지를 계산해 정확도를 계산\n",
        "  return test_loss, test_accuracy\n",
        "\n",
        "''' 9. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기 '''\n",
        "for Epoch in range(1, EPOCHS + 1):                                          \n",
        "  train(model, train_loader, optimizer, log_interval = 200)                 # model은 기존에 정의한 MLP모델, train_loader는 학습 데이터, optimizer는 SGD, log_interval은 학습이 진행되면서 mini-batch의 index를 이용\n",
        "  test_loss, test_accuracy = evaluate(model, test_loader) \n",
        "  print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Net(\n",
            "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
            "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
            "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
            ")\n",
            "train epoch: 1 [0/60000(0%]\tTrain Loss: 2.831132\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py:1709: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
            "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "train epoch: 1 [6400/60000(11%]\tTrain Loss: 2.257404\n",
            "train epoch: 1 [12800/60000(21%]\tTrain Loss: 2.076853\n",
            "train epoch: 1 [19200/60000(32%]\tTrain Loss: 1.890658\n",
            "train epoch: 1 [25600/60000(43%]\tTrain Loss: 1.747658\n",
            "train epoch: 1 [32000/60000(53%]\tTrain Loss: 1.576324\n",
            "train epoch: 1 [38400/60000(64%]\tTrain Loss: 1.349623\n",
            "train epoch: 1 [44800/60000(75%]\tTrain Loss: 1.229416\n",
            "train epoch: 1 [51200/60000(85%]\tTrain Loss: 1.097955\n",
            "train epoch: 1 [57600/60000(96%]\tTrain Loss: 0.949970\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.0259, \tTest Accuracy: 82.74 %\n",
            "\n",
            "train epoch: 2 [0/60000(0%]\tTrain Loss: 0.900191\n",
            "train epoch: 2 [6400/60000(11%]\tTrain Loss: 0.687948\n",
            "train epoch: 2 [12800/60000(21%]\tTrain Loss: 0.798250\n",
            "train epoch: 2 [19200/60000(32%]\tTrain Loss: 0.770674\n",
            "train epoch: 2 [25600/60000(43%]\tTrain Loss: 0.554485\n",
            "train epoch: 2 [32000/60000(53%]\tTrain Loss: 0.827075\n",
            "train epoch: 2 [38400/60000(64%]\tTrain Loss: 0.489850\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-f483b77fe1c9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m''' 9. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기 '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mEpoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 71\u001b[0;31m   \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m                 \u001b[0;31m# model은 기존에 정의한 MLP모델, train_loader는 학습 데이터, optimizer는 SGD, log_interval은 학습이 진행되면서 mini-batch의 index를 이용\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     72\u001b[0m   \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEpoch\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f483b77fe1c9>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                                   \u001b[0;31m# 기존에 정의한 장비에 이미지 데이터와 레이블을 할당할 경우\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m                                                                             \u001b[0;31m# 과거에 이용한 mini-batch 내에 있는 이미지 데이터와 레이블 데이터를 바탕으로 계산된 loss의 gradient값이 optimizer에 할당돼 있으므로 optimizer의 gradient 초기화\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 41\u001b[0;31m     \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m                                                   \u001b[0;31m# 장비에 할당된 이미지 데이터를 MKP모델의 input으로 이용해 output을 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     42\u001b[0m     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m                                          \u001b[0;31m# 계산된 ouptut과 장비에 할당된 레이블 데이터를 기존에 정의한 crossentropy를 이용해 loss를 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m     \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m                                                         \u001b[0;31m# 계산한 loss를 바탕으로 back propagation을 통해 계산된 gradient 값을 할당\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-27-f483b77fe1c9>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m               \u001b[0;31m# net클래스를 이용해 설계한 MLP 모델의 forward propagation을 정의, 즉 input -> output의 과정을 나열\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m)\u001b[0m              \u001b[0;31m# MLP모델은 1차원의 벡터 값을 입력으로 받는다. 이미지는 2차원이기에 1차원으로 바꾸기 위한 View메서드를 이용해 784크기의 1차원 데이터로 변환해 진행, 이 과정을 flatten한다고 한다.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msigmoid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m                  \u001b[0;31m# pytorch 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수인 sigmoid()를 이용해 두번째 층의 input으로 계산\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m     \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *input, **kwargs)\u001b[0m\n\u001b[1;32m    887\u001b[0m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_slow_forward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    888\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 889\u001b[0;31m             \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    890\u001b[0m         for hook in itertools.chain(\n\u001b[1;32m    891\u001b[0m                 \u001b[0m_global_forward_hooks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/modules/linear.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m     92\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mforward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 94\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mF\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     95\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     96\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mextra_repr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/nn/functional.py\u001b[0m in \u001b[0;36mlinear\u001b[0;34m(input, weight, bias)\u001b[0m\n\u001b[1;32m   1751\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhas_torch_function_variadic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mhandle_torch_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1753\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_C\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_nn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbias\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1754\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1755\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVmpP3awgV_r"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import MNIST\n",
        "import tensorflow_datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "'''1. 딥러닝 모델을 설계할 때 활용하는 장비 확인 '''\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "\n",
        "print(torch.__version__,DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32 # MLP모델을 학습할 때 필요한 데이터 개수의 단위, 즉 MINI-BATCH 1개 단위에 대해 데이터가 32개로 구성\n",
        "EPOCHS = 10 # 1개의 MINI-BATCH를 이용해 학습하는 횟수를 Iteration, 전체 데이터를 이용해 학습을 진행한 횟수를 epoch라 한다.\n",
        "\n",
        "'''2. MNIST 데이터 다운로드(Train set, Test set 분리하기) '''\n",
        "train_dataset = datasets.FashionMNIST(root = \"../data/FashionMNIST\",                  # 데이터가 저장될 장소를 지정, 여기서'../'는 상위폴더\n",
        "                               train = True,                            # 대상 데이터가 MLP모델을 학습하기 위해 이용하는 학습용 데이터인지 학습된이후 성능을 검증하기 위한 검증용 데이터인지를 지정한다. true가 학습용 false는 검증용 데이터\n",
        "                               transform  = transforms.ToTensor(),      # 이미지 데이터로 다운받아지기 때문에, tensor형태로 변경한다. 0~255 범위의 스칼라 값인 픽셀을 안정화를 위해 0~1 범위에서 정규화 과정을 진행한다.\n",
        "                               download = True)                         # 해당 데이터를 인터넷상에서 다운로드해 이용할 것인지를 지정한다.\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root = \"../data/FashionMNIST\",\n",
        "                              train = False,\n",
        "                              transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,     # mini-batch 단위로 할당하고자 하는 데이터셋을 지정, dataloader함수를 이용해 mini-batch를 구성, 할당하고자 하는 데이터셋을 지정\n",
        "                                           batch_size = BATCH_SIZE,     # mini-batch 1개 단위를 구성하는 데이터의 개수를 지정\n",
        "                                           shuffle = True)              # 컴퓨터가 순서를 암기하지 못하도록 데이터의 순서를 섞는다.\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "'''3. 데이터 확인하기 (1) '''\n",
        "for (x_train,y_train) in train_loader:\n",
        "  print('x_train:', x_train.size(), 'type:', x_train.type()) # 32개의 이미지 데이터가 1개의 mini-batch를 구성, 가로 28개, 세로 28개의 픽셀로 구성, 채널이 1이므로 gray scale로 이루어진, 즉 흑백으로 이루어진 이미지 데이터\n",
        "  print('y_train:', y_train.size(), 'type:', y_train.type()) # 32개의 이미지 데이터 각각에 label 값이 1개씩 존재하기 때문에 32개의 값을 가지고 있다. \n",
        "\n",
        "'''4. 데이터 확인하기 (2) '''\n",
        "pltsize = 1                                                             \n",
        "plt.figure(figsize=(10*pltsize,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1,10, i +1)\n",
        "  plt.axis('on')\n",
        "  plt.imshow(x_train[i,:,:,:].numpy().reshape(28,28), cmap =\"gray_r\")\n",
        "  plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "''' 5. MLP(Multi Layer Perceptron) 모델 설계하기 '''\n",
        "class Net(nn.Module):                 # nn.module클래스를 상속받는 NET클래스, nn.module클래스를 상속받았을 때, nn.module클래스가 이용할 수 있는 함수를 그대로 이용 가능\n",
        "  def __init__(self):                 # net클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드\n",
        "    super(Net,self).__init__()        # nn.module 내에 있는 메서드를 상속받아 이용\n",
        "    self.fc1 = nn.Linear(28*28,512)   # fully connected layer를 정의, 가로 픽셀 수*세로 픽셀 수 * 채널 수 크기의 노드 수를 설정, 두번째 노드 수를 512로 설정할 것이기에 output의 노드 수는 512로 설정\n",
        "    self.fc2 = nn.Linear(512,256)     # output의 노드 수를 input으로 받아 세번째 노드 수로 사용할 256을 output으로 설정\n",
        "    self.fc3 = nn.Linear(256,10)      # 0부터 9까지 총 10가지 클래스를 표현하기 위한 label 값은 원핫인코딩으로 표현, (원핫인코딩 : 해당하는 값에 대해서 맞으면 1, 아니면 0을 부여. 즉 고유값에 해당되는 특징에는 1, 나머지는 0)\n",
        "  def forward(self, x):               # net클래스를 이용해 설계한 MLP 모델의 forward propagation을 정의, 즉 input -> output의 과정을 나열\n",
        "    x = x.view(-1,28*28)              # MLP모델은 1차원의 벡터 값을 입력으로 받는다. 이미지는 2차원이기에 1차원으로 바꾸기 위한 View메서드를 이용해 784크기의 1차원 데이터로 변환해 진행, 이 과정을 flatten한다고 한다.\n",
        "    x = self.fc1(x)                   \n",
        "    x = F.sigmoid(x)                  # pytorch 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수인 sigmoid()를 이용해 두번째 층의 input으로 계산\n",
        "    x = self.fc2(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)     # log.softmax()를 이용해 최종 output을 계산 \n",
        "                                      # 0~9까지 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값을 계산, 이때 loss에 대한 gradient 값을 원활하게 계산하기 위해 log_softmax를 사용\n",
        "    return x\n",
        "\n",
        "''' 6. optimizer, objective function 설정하기 '''\n",
        "model = Net().to(DEVICE)                                                    # 5에서 정의한 MLP모델을 기존에 선정한 DEVICE에 할당한다. DEVICE장비를 이용해 MLP모델을 완성하기 위해서\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)  # Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 optimizer을 정의\n",
        "                                                                            # SGD알고리즘을 사용해 업데이트하는데, learning rate를 0.01, optimizer의 관성을 나타내는 momentum을 0.5\n",
        "criterion = nn.CrossEntropyLoss()                                           # MLP 모델의 output 값과 계산할 label 값은 class를 표현하는 원핫 인코딩 값이다. 이 두개의 Loss를 계산하기 위한 함수\n",
        "\n",
        "print(model)\n",
        "\n",
        "''' 7. MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):                    # 이미지 데이터와 레이블 데이터를 이용해 MLP모델을 학습하는 train함수를 정의\n",
        "  model.train()                                                             # 기존에 정의한 MLP모델을 학습 상태로 지정\n",
        "  for batch_idx,(image, label) in enumerate(train_loader):                  # 기존의 train_loader에 이미지와 레이블 데이터가 mini-batch단위로 묶여있다. 저장된 데이터를 순서대로 이용해 MLP를 학습\n",
        "    image = image.to(DEVICE)\n",
        "    label = label.to(DEVICE)\n",
        "    optimizer.zero_grad()                                                   # 기존에 정의한 장비에 이미지 데이터와 레이블을 할당할 경우 \n",
        "                                                                            # 과거에 이용한 mini-batch 내에 있는 이미지 데이터와 레이블 데이터를 바탕으로 계산된 loss의 gradient값이 optimizer에 할당돼 있으므로 optimizer의 gradient 초기화\n",
        "    output = model(image)                                                   # 장비에 할당된 이미지 데이터를 MKP모델의 input으로 이용해 output을 계산\n",
        "    loss = criterion(output,label)                                          # 계산된 ouptut과 장비에 할당된 레이블 데이터를 기존에 정의한 crossentropy를 이용해 loss를 계산\n",
        "    loss.backward()                                                         # 계산한 loss를 바탕으로 back propagation을 통해 계산된 gradient 값을 할당\n",
        "    optimizer.step()                                                        # 각 파라미터에 할당된 gradient 값을 이용해 파라미터 값을 업데이트한다.\n",
        "    \n",
        "    if batch_idx % log_interval == 0:\n",
        "      print(\"train epoch: {} [{}/{}({:.0f}%]\\tTrain Loss: {:.6f}\".format(Epoch,batch_idx * len(image),len(train_loader.dataset),100.*batch_idx / len(train_loader),loss.item()))\n",
        "\n",
        "\n",
        "''' 8. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):                                           # MLP모델 학습 과정 또는 학습이 완료된 상태에서 MLP모델의 성능을 평가 함수\n",
        "  model.eval()                                                              # 학습 과정 또는 학습이 완료된 MLP모델을 평가상태로 지정한다.\n",
        "  test_loss = 0                                                             # test_loader내의 데이터를 이용해 loss값을 계산하기 위해 test_loss를 0으로 지정\n",
        "  correct = 0                                                               # 학습 과정 또는 학습이 완료된 MLP 모델이 올바른 Class로 분류한 경우를 세기 위해 0으로 임시 설정\n",
        "\n",
        "  with torch.no_grad():                                                     # gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 gradient의 흐름을 억제\n",
        "    for image, label in test_loader:                                        \n",
        "      image = image.to(DEVICE)                                              \n",
        "      label = label.to(DEVICE)\n",
        "      output = model(image)                                                 # 장비에 할당한 이미지 데이터를 MLP 모델의 input으로 output을 계산\n",
        "      test_loss += criterion(output, label).item()                          # 계산된 output과 장비에 할당된 레이블 데이터를 기존에 정의한 crossentropy를 이용해 loss값을 계산한 결과값을 test_loss에 더해 업데이트\n",
        "      prediction = output.max(1, keepdim = True)[1]                         # MLP 모델의 Output 값은 크기가 10인 벡터 값이기에 계산된 벡터 값 내 가장 큰 값인 위치에 대해 해당 위치에 대응하는 클래스로 예측했다 판단\n",
        "      correct += prediction.eq(label.view_as(prediction)).sum().item()      # MLP모델이 예측한 클래스 값과 실제 레이블이 의미하는 클래스가 맞으면 correct에 더해 올바르게 예측한 횟수를 저장\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)                                     # 계산된 test_loss의 값을 test_loader 내에 존재하는 mini-batch 개수만큼 나누어 평균 loss값을 계산\n",
        "  test_accuracy = 100*correct/len(test_loader.dataset)                      # test_loader 데이터 중 얼마나 맞췄는지를 계산해 정확도를 계산\n",
        "  return test_loss, test_accuracy\n",
        "\n",
        "''' 9. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy를 확인하기 '''\n",
        "for Epoch in range(1, EPOCHS + 1):                                          \n",
        "  train(model, train_loader, optimizer, log_interval = 200)                 # model은 기존에 정의한 MLP모델, train_loader는 학습 데이터, optimizer는 SGD, log_interval은 학습이 진행되면서 mini-batch의 index를 이용\n",
        "  test_loss, test_accuracy = evaluate(model, test_loader) \n",
        "  print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} %\\n\".format(Epoch, test_loss, test_accuracy))\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rPeEdVcg1CeW"
      },
      "source": [
        "# *PART3* deep learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yJeX93Ds1GP6"
      },
      "source": [
        "## 1. 딥러닝의 정의\n",
        "신경망은 학습하는 알고리즘의 특성상 과적합이 심하게 일어나며 Gradient Vanishing이 일어난다. 그래서 학습 과정 내에서 과적합을 어느 정도 방지할 수 있는 SVM과 Ensemble Learning이 많이 사용되었다. 딥러닝은 2개 이상의 Hidden Layer를 를 지나고 있는 다층 신경망(deep neural network,DNN)라 할 수 있다. 신경망을 기반으로 한 모델이기 때문이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "txz2qQDn1LG7"
      },
      "source": [
        "## 2. 딥러닝 종류\n",
        "- AI Background 부분 - MLP\n",
        "- 이지미 관련 분야 - CNN\n",
        "- 텍스트와 같은 시계열 분야 - RNN\n",
        "딥러닝은 CNN과 RNN 구조를 바탕으로 다양하게 파생"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cPb4y5CX1Sjx"
      },
      "source": [
        "## 3. 딥러닝의 발전을 이끈 알고리즘"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkMuDbcrvIU4"
      },
      "source": [
        "### 3.1 Dropout\n",
        "신경망의 학습 과정 중 layer의 노드를 랜덤하게 drop함으로서 generalization 효과를 가져오게 하는 테크닉입니다. \n",
        "\n",
        "dropout을 적용한다는 것은 weight matrix에 랜덤하게 일부 column에 0을 집어넣어 연산을 한다는 것. dropout을 적용할 때는 얼마나 랜덤하게 dropout한 것인지에 대한 확률 값을 지정해야 하고, 이는 input layer과 hidden layer에도 적용할 수 있다. epoch마다 랜덤하게 dropout할 수도 있다. dropout은 유전 알고리즘에서 아이디어를 차용한 것이다. \n",
        "\n",
        "Ensemble Learning의 기본 콘셉트는 다양한 모델이다. 다양한 모델을 만들기 위해 데이터를 랜덤하게 구성하고 변수도 랜덤하게 구성한 것이 RandomForest이다. 신경망의 한 epoch을 하나의 모델로 보고 dropout을 랜덤한 변수의 구성으로 본다면 dropout을 적용한 신경망은 일종의 randomforest와 비슷한 모델 구성이라 할 수 있다.\n",
        "\n",
        "MNIST 손글씨 데이터를 활용하여 dropout을 적용시켜본다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NFHxqeNXDrwv"
      },
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F \n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.datasets import MNIST\n",
        "import tensorflow_datasets\n",
        "import torchvision.transforms as transforms\n",
        "\n",
        "''' 5. Multi Layer Perception(MLP) 모델 설계하기 - dropout 적용 전\n",
        "class Net(nn.Module):                 # nn.module클래스를 상속받는 NET클래스, nn.module클래스를 상속받았을 때, nn.module클래스가 이용할 수 있는 함수를 그대로 이용 가능\n",
        "  def __init__(self):                 # net클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드\n",
        "    super(Net,self).__init__()        # nn.module 내에 있는 메서드를 상속받아 이용\n",
        "    self.fc1 = nn.Linear(28*28,512)   # fully connected layer를 정의, 가로 픽셀 수*세로 픽셀 수 * 채널 수 크기의 노드 수를 설정, 두번째 노드 수를 512로 설정할 것이기에 output의 노드 수는 512로 설정\n",
        "    self.fc2 = nn.Linear(512,256)     # output의 노드 수를 input으로 받아 세번째 노드 수로 사용할 256을 output으로 설정\n",
        "    self.fc3 = nn.Linear(256,10)      # 0부터 9까지 총 10가지 클래스를 표현하기 위한 label 값은 원핫인코딩으로 표현, (원핫인코딩 : 해당하는 값에 대해서 맞으면 1, 아니면 0을 부여. 즉 고유값에 해당되는 특징에는 1, 나머지는 0)\n",
        "  def forward(self, x):               # net클래스를 이용해 설계한 MLP 모델의 forward propagation을 정의, 즉 input -> output의 과정을 나열\n",
        "    x = x.view(-1,28*28)              # MLP모델은 1차원의 벡터 값을 입력으로 받는다. 이미지는 2차원이기에 1차원으로 바꾸기 위한 View메서드를 이용해 784크기의 1차원 데이터로 변환해 진행, 이 과정을 flatten한다고 한다.\n",
        "    x = self.fc1(x)                   \n",
        "    x = F.sigmoid(x)                  # pytorch 중 인공 신경망 설계에 유용한 함수를 모아 놓은 torch.nn.functional 내에 정의된 비선형 함수인 sigmoid()를 이용해 두번째 층의 input으로 계산\n",
        "    x = self.fc2(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)     # log.softmax()를 이용해 최종 output을 계산 \n",
        "                                      # 0~9까지 총 10가지 경우의 수 중 하나로 분류하는 일을 수행하기 때문에 softmax를 이용해 확률 값을 계산, 이때 loss에 대한 gradient 값을 원활하게 계산하기 위해 log_softmax를 사용\n",
        "    return x                                                      '''\n",
        "\n",
        "# 5. Multi Layer Perception(MLP) 모델 설계하기 - dropout 적용 후\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28,512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,10)\n",
        "    self.dropout_prob = 0.5           # 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지 명시, 50%의 노드에 대해 가중값을 계산하지 않기 위해 0.5로 정의\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # 각 sigmoid함수의 결괏값에 대해 dropout을 적용하는 부분, x값에 적용하여 p 값은 몇 퍼센트의 노드에 대해 계산하지 않을 것인지 \n",
        "                                                                      # 조정하는 요소, training = self.training 은 학습 상태일 때와 검증 상태에 따라 다르게 적용되기 위해 존재하는 파라미터\n",
        "    x = self.fc2(x)\n",
        "    x = F.sigmoid(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout은 학습 과정 속에서 랜덤으로 노드를 선택해 가중값이 업데이트되지 않도록 하지만 평가 과정 속에서는 모든 노드를 \n",
        "                                                                      # 이용해 output을 계산하기 때문에 학습 상태와 검증 상태에서 다르게 적용돼야 한다.\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U8NcfFmS1a3P"
      },
      "source": [
        "### 3.2 Activation 함수\n",
        "activation 함수는 어떤 신호를 입력받아 이를 적절히 처리해 출력해주는 함수\n",
        "\n",
        "MLP에서 기본적으로 시그모이드 함수를 사용한다. 이때 시그모이드 함수를 activation 함수라 한다.\n",
        "\n",
        "#### 3.2.1 ReLU함수\n",
        "ReLU(rectified linear unit) 함수는 시그모이드 함수와 같은 비선형 활성 함수가 지니고 있는 문제점을 어느 정도 해결한 활성 함수이다. ReLU는 f(x)=max(0,x)와 같이 정의\n",
        "\n",
        "입력 값이 0 이상이면 이 값 그대로 출력, 0 이하이면 0으로 출력\n",
        "\n",
        "dropout은 보통 ReLU() 비선형 함수와 잘 어울린다.\n",
        "\n",
        "이 활성 함수를 미분할 때 입력 값이 0 이상인 부분은 기울기가 1, 입력 값이 0 이하인 부분은 0이 된다. 즉, Back Propagation 과정 중 곱해지는 Activation 미분값이 0 또는 1이 되기 때문에 아예 없애거나 완전히 살리는 것으로 해석할 수 있다. 이를 통해 Hidden Layer이 깊어져도 Gradient Vanishing이 일어나는 것을 완화시키며 layer를 깊게 쌓아 복잡한 모형을 만들 수 있게 된 것\n",
        "\n",
        "ReLU의 변형으로 Leaky ReLU, ELU, parametric ReLU, SELU, SERLU 등 다양한 Activation 함수가 있고, CIFAR10 데이터에 각 활성 함수를 적용한 성능 그래프는 SERLU의 성능이 가장 좋다는 것을 볼 수 있다, \n",
        "\n",
        "기존에 Fully Connected Layer에서 sigmoid 대신 ReLU 비선형 함수를 사용해본다.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oaFF2RSmx5WW"
      },
      "source": [
        "''' 5. Multi Layer Perception(MLP) 모델 설계하기 '''\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28,512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,10)\n",
        "    self.dropout_prob = 0.5           # 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지 명시, 50%의 노드에 대해 가중값을 계산하지 않기 위해 0.5로 정의\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # 각 sigmoid함수의 결괏값에 대해 dropout을 적용하는 부분, x값에 적용하여 p 값은 몇 퍼센트의 노드에 대해 계산하지 않을 것인지 \n",
        "                                                                      # 조정하는 요소, training = self.training 은 학습 상태일 때와 검증 상태에 따라 다르게 적용되기 위해 존재하는 파라미터\n",
        "    x = self.fc2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout은 학습 과정 속에서 랜덤으로 노드를 선택해 가중값이 업데이트되지 않도록 하지만 평가 과정 속에서는 모든 노드를 \n",
        "                                                                      # 이용해 output을 계산하기 때문에 학습 상태와 검증 상태에서 다르게 적용돼야 한다.\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vVLoVs934-9b"
      },
      "source": [
        "### 3.3 batch normalization\n",
        "신경망에서 Internal Coveriance shift라는 현상도 발생한다. 각 layer마다 input분포가 달라짐에 따라 학습 속도가 느려지는 현상을 말한다. batch normalization은 이를 방지하기 위한 기법으로 layer의 input분포를 정규화해 학습 속도를 빠르게 하겠다는 것\n",
        "\n",
        "기본적인 정규화하는 수식과 거의 일치한다. \n",
        "\n",
        "ReLU 함수를 통해 데이터의 0의 미만 값이 0으로 된다. 이후 다음 Weight와 선형 결합을 통해 분포가 우측으로 이동되고, batch normalization을 통해 정규 분포와 비슷한 형태로 정규화된다. batch normalization을 하지 않고 바로 ReLU 함수에 들어간다면 그래프가 우측 편향된 상태로 hidden layer을 하는 의미가 사라질 수 있다. batch normalization의 분포를 정규화해 y축을 기준으로 정규화시켜 대칭으로 만들어 비선형 활성 함수의 의미를 살린다.\n",
        "\n",
        "nn.BatchNorm 함수를 activation function 이전에 적용하는지 이후에 적용하는지는 다 다르다. 전에 적용해서 더 좋을 수도 있고, 이후에 적용해서 더 좋을 수도 있다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hqTd9_MP4x48"
      },
      "source": [
        "''' 5. Multi Layer Perception(MLP) 모델 설계하기 '''\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28,512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,10)\n",
        "    self.dropout_prob = 0.5                 # 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지 명시, 50%의 노드에 대해 가중값을 계산하지 않기 위해 0.5로 정의\n",
        "    self.batch_norm1 = nn.BatchNormld(512)  # nn.BatchNorm 을 class 내에서 이용, 이때 첫번째 fully connect layer의 output이 512 크기의 벡터 값이 기때문에 512로 설정\n",
        "    self.batch_norm2 = nn.BatctNormld(256)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = self.batch_norm1(x)                 # 첫번째 fully connected layer의 output을 위에서 정의한 self.batch_norm1 의 input으로 이용\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # 각 sigmoid함수의 결괏값에 대해 dropout을 적용하는 부분, x값에 적용하여 p 값은 몇 퍼센트의 노드에 대해 계산하지 않을 것인지 \n",
        "                                                                      # 조정하는 요소, training = self.training 은 학습 상태일 때와 검증 상태에 따라 다르게 적용되기 위해 존재하는 파라미터\n",
        "    x = self.fc2(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout은 학습 과정 속에서 랜덤으로 노드를 선택해 가중값이 업데이트되지 않도록 하지만 평가 과정 속에서는 모든 노드를 \n",
        "                                                                      # 이용해 output을 계산하기 때문에 학습 상태와 검증 상태에서 다르게 적용돼야 한다.\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wAZKNJfV9k7C"
      },
      "source": [
        "### 3.4 initialization\n",
        "초기 분포로 uniform distribution이나 normal distribution을 사용했다. weight를 램덤하게 초기화하면 신경망의 초기 loss가 달라진다. 즉 신경망을 초기화할 때마다 신경망의 loss상에서의 위치가 달라질 수 있다. 즉, 신경망을 어떻게 초기화하느냐에 따라 학습 속도가 달라질 수 있다. 그래서 기법이 다양하게 연구되고 있다.\n",
        "- LeCun Initialization\n",
        "\n",
        "LeCun Uniform Initialization 과 LeCun Normal Initialization이 있다. 각각 초기 분포가 다음과 같은 분포를 따르도록 weight를 초기화하는 것\n",
        "\n",
        "- He Initialization\n",
        "\n",
        "ReLU함수를 사용할 때 비효율 적이라는 것을 보완한 초기화 기법이다\n",
        "\n",
        "일반적인 딥러닝 모델은 다음 순서대로 설계해 학습하고 성능을 평가한다.\n",
        "1. 모델 구조를 설계하고 설계된 모델 구조의 파라미터 값을 랜덤으로 샘플링\n",
        "2. Feature 값으로 이용되는 데이터를 설계한 모델의 input으로 사용해 output을 계산\n",
        "3. 계산된 output을 input으로 이용한 feature 값과 매칭되는 레이블 값을 기존에 정의한 objective function을 통해 loss 값으로 계산\n",
        "4. 계산된 loss 값을 통해 gradient를 계산해 모델 내 파라미터 값을 back propagation에 의해 업데이트\n",
        "5. 이를 반복해 학습을 진행하며 학습이 완료된 이후 완성된 모델의 성능을 평가\n",
        "\n",
        "이때 1에서 모델 구조의 파라미터 값을 랜덤으로 샘플링하는 과정에서 어떤 분포에서 샘플링을 진행하는지에 따라 좋은 방향으로 학습이 진행될 수도 있기 때문에 중요하다. 현재 이용하고 있는 nn.linear는 output으로 계산되는 벡터의 차원 수의 역수 값에 대한 +/- 범위 내 uniform distribution을 설정해 샘플링한다.\n",
        "\n",
        "이를 he initialization을 이용해 파라미터를 초기화하자.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IrXRDfre83dp"
      },
      "source": [
        "''' 6. optimizer, objective function 설정하기 '''\n",
        "import torch.nn.init as init\n",
        "def weight_init(m):\n",
        "  if isinstance(m, nn.Linear):\n",
        "    init.kaiming_uniform_(m.weight.data)\n",
        "\n",
        "model = Net().to(DEVICE)                                                    # 5에서 정의한 MLP모델을 기존에 선정한 DEVICE에 할당한다. DEVICE장비를 이용해 MLP모델을 완성하기 위해서\n",
        "model.apply(weight_init)\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)  # Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 optimizer을 정의\n",
        "                                                                            # SGD알고리즘을 사용해 업데이트하는데, learning rate를 0.01, optimizer의 관성을 나타내는 momentum을 0.5\n",
        "criterion = nn.CrossEntropyLoss()                                           # MLP 모델의 output 값과 계산할 label 값은 class를 표현하는 원핫 인코딩 값이다. 이 두개의 Loss를 계산하기 위한 함수\n",
        "\n",
        "print(model)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNhR0oRCBw7R",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 244
        },
        "outputId": "c2077ff3-434b-4166-b4e9-1791e5cc3e7b"
      },
      "source": [
        "''' 5. Multi Layer Perception(MLP) 모델 설계하기 '''\n",
        "class Net(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Net, self).__init__()\n",
        "    self.fc1 = nn.Linear(28*28,512)\n",
        "    self.fc2 = nn.Linear(512,256)\n",
        "    self.fc3 = nn.Linear(256,10)\n",
        "    self.dropout_prob = 0.5                 # 몇 퍼센트의 노드에 대해 가중값을 계산하지 않을 것인지 명시, 50%의 노드에 대해 가중값을 계산하지 않기 위해 0.5로 정의\n",
        "    self.batch_norm1 = nn.BatchNorm1d(512)  # nn.BatchNorm 을 class 내에서 이용, 이때 첫번째 fully connect layer의 output이 512 크기의 벡터 값이 기때문에 512로 설정\n",
        "    self.batch_norm2 = nn.BatchNorm1d(256)\n",
        "\n",
        "  def forward(self,x):\n",
        "    x = x.view(-1, 28*28)\n",
        "    x = self.fc1(x)\n",
        "    x = self.batch_norm1(x)                 # 첫번째 fully connected layer의 output을 위에서 정의한 self.batch_norm1 의 input으로 이용\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # 각 sigmoid함수의 결괏값에 대해 dropout을 적용하는 부분, x값에 적용하여 p 값은 몇 퍼센트의 노드에 대해 계산하지 않을 것인지 \n",
        "                                                                      # 조정하는 요소, training = self.training 은 학습 상태일 때와 검증 상태에 따라 다르게 적용되기 위해 존재하는 파라미터\n",
        "    x = self.fc2(x)\n",
        "    x = self.batch_norm2(x)\n",
        "    x = F.relu(x)\n",
        "    x = F.dropout(x, training = self.training, p = self.dropout_prob) # dropout은 학습 과정 속에서 랜덤으로 노드를 선택해 가중값이 업데이트되지 않도록 하지만 평가 과정 속에서는 모든 노드를 \n",
        "                                                                      # 이용해 output을 계산하기 때문에 학습 상태와 검증 상태에서 다르게 적용돼야 한다.\n",
        "    x = self.fc3(x)\n",
        "    x = F.log_softmax(x, dim = 1)\n",
        "    return x\n",
        "\n",
        "''' 6. optimizer, objective function 설정하기 '''\n",
        "import torch.nn.init as init                                                # weight, bias 등 딥러닝 모델에서 초깃값으로 설정되는 요소에 대한 모듈인 init를 임포트\n",
        "def weight_init(m):                                                         # MLP모델 내의 Weight를 초기화할 부분을 설정하기 위해 weight_init 함수를 정의\n",
        "  if isinstance(m, nn.Linear):                                              # nn.Linear 에 해당하는 파라미터 값에 대해서만 지정\n",
        "    init.kaiming_uniform_(m.weight.data)                                    # nn.Linear 에 해당하는 파라미터 값에 대해 he_initialization을 이용해 파라미터 값을 초기화한다.\n",
        "\n",
        "model = Net().to(DEVICE)                                                    # 5에서 정의한 MLP모델을 기존에 선정한 DEVICE에 할당한다. DEVICE장비를 이용해 MLP모델을 완성하기 위해서\n",
        "model.apply(weight_init)                                                    # 정의한 weight_init 함수를 net 클래스의 인스턴스인 model에 적용\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)  # Back Propagation을 이용해 파라미터를 업데이트할 때 이용하는 optimizer을 정의\n",
        "                                                                            # SGD알고리즘을 사용해 업데이트하는데, learning rate를 0.01, optimizer의 관성을 나타내는 momentum을 0.5\n",
        "criterion = nn.CrossEntropyLoss()                                           # MLP 모델의 output 값과 계산할 label 값은 class를 표현하는 원핫 인코딩 값이다. 이 두개의 Loss를 계산하기 위한 함수\n",
        "\n",
        "print(model)\n",
        "\n",
        "                                                                            # 이전에는 class 내 모델을 설계하는 영역에서 설정했다면 이번에는 모델을 정의하는 부분에서 설정을 바꾼다.\n",
        "                                                                            # 우선 model을 정의하고 apply를 이용해 모델의 파라미터를 초기화한다.\n",
        "                                                                            # nn.Linear 인스턴스에 대해서 kaiming_uniform, 즉 he initialization을 이용하여 초기화한다."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-7ff5ed35f070>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m''' 5. Multi Layer Perception(MLP) 모델 설계하기 '''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0;32mclass\u001b[0m \u001b[0mNet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mModule\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mNet\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfc1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLinear\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0;36m28\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'nn' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BICoLWQNIqY1"
      },
      "source": [
        "### 3.5 optimizer\n",
        "앞서 batch단위로 back propagation하는 과정을 SGD(stochastic gradient descent)라 하고 이런 과정을 optimization이라 한다. 이 optimizer에는 SGD 이외에 다양한 것들이 있다. \n",
        "\n",
        "momentum은 미분을 통한 gradient 방향으로 가되, 일종의 관성을 추가하는 개념이다\n",
        "\n",
        "SGD는 조금씩 최적 해(global optinum)을 찾아간다. 전체 데이터에 대해 back propagation을 하는 것이 아니라 batch단위로 back propagation한다. 이때 momentum을 사용하면 최적의 장소로 더 빠르게 수렴한다.\n",
        "\n",
        "momentum을 약간 변형한 방법\n",
        "- NAG(Nesterov Accelerated Gradient)\n",
        "- Adagrad(Adaptive Gradient)\n",
        "- RMSProp\n",
        "- Adadelta(Adaptive Delta)\n",
        "- Adam(Adaptive Moment Estimation): 가장 많이 사용하는 optimizer\n",
        "- RAdam(Rectified Adam optimizer)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pBnV8O0HCl-S"
      },
      "source": [
        "# optimizer = torch.optim.SGD(model.parameters(), lr = 0.01, momentum = 0.5)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZV1mrFv4LBPg"
      },
      "source": [
        "### 3.6 AutoEncoder(AE)\n",
        "회귀과 분류모델은 지도학습\n",
        "\n",
        "AE는 대표적인 비지도학습 신경망 모델\n",
        "\n",
        "hidden layer 앞부분을 인코더(encoder), 뒷부분을 디코더(decoder)라고 한다. 즉, input data에 대해 hidden layer로 인코딩한 후 다시 원래 input data로 디코딩하는 개념\n",
        "\n",
        "AE를 사용하면 Input data를 latent space에 압축시켜 새로운 feature로 사용할 수 있다. 이것으로 dimension을 줄일 수 있다.\n",
        "\n",
        "AE의 학습 과정은 데이터를 원래의 데이터로 잘 복원하도록 학습시키는 것\n",
        "\n",
        "### 3.7 Stacked AutoEncoder\n",
        "AE를 변형한 모델로 말 그대로 AE를 쌓아 올린 모델\n",
        "\n",
        "과정은\n",
        "1. input data로 AE1을 학습\n",
        "2. 1에서 학습된 모형의 Hidden Layer를 input으로 해 AE2를 학습\n",
        "3. 2과정을 원하는 만큼 반복\n",
        "4. 1~3에서 학습된 Hidden layer를 쌓아 올림\n",
        "5. 마지막 layer에 softamx와 같은 classification 기능이 있는 output layer를 추가\n",
        "6. fine-tuning으로 전체 다층 신경망을 재학습\n",
        "\n",
        "fine-tuning은 따로 학습시킨 모델을 재학습시키는 개념로, 미리 학습시키는 것을 pre-trained-model 이라고 하고 이 모델을 재학습시키는 것을 fine-tuning이라 한다.\n",
        "\n",
        "### 3.8 Denoising AutoEncoder(DAE)\n",
        "robust는 강건한 이라는 뜻으로 학습하지 않은 데이터도 잘 분류하는 강건한 모델이라는 것입니다. DAE는 좀 더 강건한 feature을 만들기 위한 AE이다.\n",
        "\n",
        "AE와 마찬가지로 Input 데이터를 잘 복원하도록 학습시키는 모델이지만, input에 약간의 noise를 추가해 학습시킨다. 즉, input이 'x + noise', output이 'x'가 된다.\n",
        "\n",
        "input data에 noise를 주어 학습시킴으로써 어떤 데이터가 input으로 와도 강건한 모델을 만든다는 것"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ooLIV6JgK9SJ"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "print('Using pytorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "''' 1. FashionMNIST 데이터 다운로드(Train set, Test set 분리하기) '''\n",
        "train_dataset = datasets.FashionMNIST(root = \"../data/FashionMNIST\",\n",
        "                                      train = True,\n",
        "                                      download = True,\n",
        "                                      transform = transforms.ToTensor())\n",
        "\n",
        "test_dataset = datasets.FashionMNIST(root = \"../data/FashionMNIST\",\n",
        "                                     train = False,\n",
        "                                     transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = BATCH_SIZE,\n",
        "                                           shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "''' 2. 데이터 확인하기 (1) '''\n",
        "for(x_train, y_train) in train_loader:\n",
        "  break\n",
        "\n",
        "''' 3. 데이터 확인하기 (2) '''\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10*pltsize,pltsize))\n",
        "for i in range(10):\n",
        "  plt.subplot(1,10,i+1)\n",
        "  plt.axis('on')\n",
        "  plt.imshow(x_train[i,:,:,:].numpy().reshape(28,28),cmap=\"gray_r\")\n",
        "  plt.title('class: ' + str(y_train[i].item()))\n",
        "\n",
        "''' 4. AutoEncoder(AE) 모델 설계하기 '''\n",
        "class AE(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(AE, self).__init__()\n",
        "\n",
        "    self.encoder = nn.Sequential(                 # autoencoder은 인코더와 디코더로 이뤄져 있는데, 그 중 인코더를 정의. 앞에는 forward를 사용했지만 nn.sequential을 사용하여 인코더 단위를 한 번에 정의\n",
        "        nn.Linear(28*28,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,32),)                       # Latent Variable Vector의 크기를 32로 설정\n",
        "    \n",
        "    self.decoder = nn.Sequential(\n",
        "        nn.Linear(32,256),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(256,512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512,28*28),)\n",
        "    \n",
        "  def forward(self, x):                           # 인코더와 디코더에 데이터를 입력했을 때 output을 계산하기까지의 과정을 나열\n",
        "    encoded = self.encoder(x)\n",
        "    decoded = self.decoder(encoded)\n",
        "    return encoded, decoded\n",
        "\n",
        "''' 5. Optimizer, Objective Function 설정하기 '''\n",
        "model = AE().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(),lr = 0.001)\n",
        "criterion = nn.MSELoss()                          # AE 모델의 output 값과 label 값은 이미지 데이터 이므로 output값은 input으로 이용된 이미지 데이터와 복원된 이미지 데이터 값 간의\n",
        "                                                  # MeanSquaredError를 이용해 계산하기 위해 nn.MSELoss 로 설정\n",
        "print(model)\n",
        "\n",
        "''' 6. AE 모델 학습을 진행하여 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "  model.train()\n",
        "  for batch_idx,(image, _) in enumerate(train_loader):  # 레이블 데이터를 활용해 학습하지 않고 입력 데이터를 타깃으로 학습하기 때문에 레이블 데이터를 이용할 필요가 없다. _를 사용해 생략했다.\n",
        "    image = image.view(-1,28*28).to(DEVICE)\n",
        "    target = image.view(-1,28*28).to(DEVICE)\n",
        "    optimizer.zero_grad()                               # 이미지 데이터를 바탕으러 계산된 loss의 gradient 값이 optimizer에 할당돼 있으므로 optimizer의 gradient를 초기화한다.\n",
        "    encoded, decoded = model(image)                     \n",
        "    loss = criterion(decoded, target)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if batch_idx % log_interval == 0:\n",
        "      print(\"train epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(Epoch, batch_idx * len(image), len(train_loader.dataset),100. * batch_idx / len(train_loader),loss.item()))\n",
        "\n",
        "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "  model.eval()\n",
        "  test_loss = 0\n",
        "  real_image = []\n",
        "  gen_image = []\n",
        "  with torch.no_grad():                                                   # gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 gradient의 흐름을 억제\n",
        "    for image, _ in test_loader:                                          # mini-batch 단위로 저장되어 있기에 반복문을 이용해 차례대로 접근\n",
        "      image = image.view(-1, 28*28).to(DEVICE)\n",
        "      target = image.view(-1,28*28).to(DEVICE)\n",
        "      encoded, decoded = model(image)\n",
        "\n",
        "      test_loss += criterion(decoded, image).item()                       \n",
        "      real_image.append(image.to(\"cpu\"))                                  # 실제 이미지로 할당된 이미지를 real_image 리스트에 추가\n",
        "      gen_image.append(decoded.to(\"cpu\"))                                 # autoencoder 모델을 통해 생성된 이미지를 gen_image 리스트에 추가\n",
        "\n",
        "  test_loss /= len(test_loader.dataset)\n",
        "  return test_loss, real_image, gen_image\n",
        "\n",
        "''' 8. AutoEncoder 학습을 실행하며 test set의 reconstruction error 확인하기 '''\n",
        "for Epoch in range(1, EPOCHS+1):                                          \n",
        "  train(model, train_loader, optimizer, log_interval = 200)               # 정의한 train함수를 실행하는데, model은 기존에 정의한 MLP모델, train_loader는 학습 데이터, optimizer는 SGD,\n",
        "                                                                          # log_interval 는 학습이 진행되면서 mini-batch의 index를 인해 과정을 모니터링할 수 있도록 출력\n",
        "  test_loss, real_image, gen_image = evaluate(model, test_loader)         # 각 epoch별 출력되는 loss값과 실제 이미지, 생성된 이미지를 저장한 real_image, gen_image 리스트를 작성\n",
        "  print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}\".format(Epoch, test_loss))    # 2개의 for 반복문을 통해 실제 이미지와 생성된 이미지를 비교, autoencoder 모델을 이용해 생성된 이미지와 실제 이미지 간\n",
        "                                                                          # MeanSquaredError 값을 계산해 test_loss 값을 업데이트\n",
        "  f, a = plt.subplots(2,10, figsize = (10,4))\n",
        "  for i in range(10):\n",
        "    img = np.reshape(real_image[0][i],(28,28))\n",
        "    a[0][i].imshow(img, cmap = \"gray_r\")\n",
        "    a[0][i].set_xticks(( ))\n",
        "    a[0][i].set_yticks(( ))\n",
        "\n",
        "  for i in range(10):\n",
        "    img = np.reshape(gen_image[0][i],(28,28))\n",
        "    a[1][i].imshow(img, cmap = \"gray_r\")\n",
        "    a[1][i].set_xticks(( ))\n",
        "    a[1][i].set_yticks(( ))\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "R-t1pZ8bydoS"
      },
      "source": [
        "# *PART4* 컴퓨터 비전"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5-4J6ZjG0QpL"
      },
      "source": [
        "## 1. CNN(Convolutional Neural Network)\n",
        "특정 이미지를 컴퓨터에게 보여주거나 이미지를 분류하는 모델을 만들 때는 이미지를 구성하는 픽셀 값을 input으로 사용\n",
        "\n",
        "이미지 픽셀을 Flatten해서 사용하면 x11과 x12는 매우 근접하고 연관되어 있지만 머신러닝이라 하면 input 변수가 독릭적이다. 따라서 x11과 x12의 연관성을 반영하지 못한다.\n",
        "\n",
        "그렇게 지역 정보(region feature)을 학습할 수 있는 신경망 구조가 필요했기에 이러한 신경망 구조를 CNN이라 한다.\n",
        "\n",
        "- region feature: region feature을 뽑아내는 convolution layer과 feature dimension 을 위한 pooling layer 그리고 최종적인 분류를 위한 Fully Connected Layer(일반적인 MLP구조를 지니는)로 구성돼 있다.\n",
        "\n",
        "- convolutional layer: receptive field를 정의해 입력 층의 이미지의 feature를 추출하는 역할이다. 이미지가 input으로 들어왔을 때 사각형 모양의 receptive filed가 이미지를 스캔하면서 이미지의 region feature를 추출한다. 빨간 사각형이 이미지 전체를 돌면서 값을 추출한다. input이미지의 dimension 이 20x20 이고 receptive field가 3x3이라면 여기서 feature의 dimension은 18x18이 된다. 여기서 추출한 feature을 feature map이라 한다. 여기서 weight는 신경망 모형을 이용해 학습하면서 바뀌는 값\n",
        "\n",
        "- stride: convolution layer에서 receptive field가 이미지를 돌면서 feature을 뽑을 때 이동하는 칸 수이다.\n",
        "\n",
        "- padding: 5x5 image에 3x3 convolution을 적용하면 3x3 이미지로 줄어든다. 이와 같이 convolution을 적용하면 다음 image 또는 feature의 size가 줄어들고 가장자리에 있는 픽셀 값은 안쪽에 있는 픽셀 값보다 적게 convolution이 적용된다. image size를 줄이지 않고 모든 픽셀 값에 convolution을 적용하기 위해 padding을 적용한다. 기본 이미지의 테두리에 0 값을 넣어 크기를 키워 적용 후 image 또는 feature의 크기를 유지한다.\n",
        "\n",
        "- weight sharing: convolution layer에서 receptive field를 움직여가며 다음 feature map을 추출할 때 추출한 map의 수를 정한다. 이때 map을 추출할 때 매우 많은 파라미터를 학습해야 한다. 많은 파라미터의 수를 줄이기 위해 CNN을 학습할 때 Weight sharing 기법을 이용한다. weight를 공유한다는 개념으로 field를 옮길 때마다 해당 convolution에서는 같은 weight를 사용한다는 것이다. \n",
        "\n",
        "- pooling layer: image 또는 feature의 convolution을 거친 후에 pooling layer를 거친다. pooling은 feature size를 반으로 줄여주는 것이다. stride max pooling을 옆으로 이동시키며 그 사각형 안에서 가장 큰 값을 추출한다. pooling layer을 거치지 않으면 많은 파라미터를 학습해야 하기에 학습 시간이 오래 걸린다. 따라서 CNN의 학습 속도를 향상시키기 위해 feature의 dimension을 줄이는 개념이다. 가장 큰 픽셀 값을 max pooling, 평균 픽셀 값을 average pooling이라 한다.\n",
        "\n",
        "- fully connected layer: fully connected layer는 MLP구조와 동일하다. pooling layer에 나온 feature를 flatten시켜 MLP의 input으로 놓고 학습을 진행한다. convolution의 receptive field 크기와 stride, pooling의 종류, layer를 쌓는 횟수 모두 사용자가 지정해야 하는 하이퍼파라미터이다. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NjPOujaH4jU-"
      },
      "source": [
        "## 2. CNN과 MLP\n",
        "CNN과 MLP의 가장 큰 차이점은 이밎지의 feature을 어떻게 추출하느냐이다.\n",
        "- MLP는 이미지의 픽셀 값을 바로 네트워크의 input으로 사용하는 것이고, CNN은 이미지의 region feature을 convolutino layer와 pooling layer을 이용해 추출하고 그 feature을 MLP의 input으로 사용한다는 것이다. \n",
        "\n",
        "CNN이 이미지 처리와 관련된 비전 방면에서 성능이 좋은 이유는 단지 region feature을 추출할 수 있기 때문이다. \n",
        "\n",
        "딥러닝이란 새로운 모델이 아닌 graphical feature을 추출하는 것에 초점을 맞춘 모델\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "niQPKoeKOxc_"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "  DEVICE = torch.device('cuda')\n",
        "else:\n",
        "  DEVICE = torch.device('cpu')\n",
        "\n",
        "BATCH_SIZE = 32                                                           # MLP 모델을 학습할 때 필요한 데이터 개수의 단위\n",
        "EPOCHS = 10                                                               # 1개의 Mini-Batch를 통해 학습하는 횟수를 iteration, 전체 데이터를 이용해 학습을 진행한 횟수를 epoch\n",
        "\n",
        "''' CIFAR10 데이터 다운로드(train set, test set 분리하기) '''\n",
        "train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                  train = True,\n",
        "                                  download = True,\n",
        "                                  transform = transforms.ToTensor()) \n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                train = False,\n",
        "                                transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())             # 32개의 이미지 데이터가 1개의 mini-batch를 이루고 있고, 채널이 3이므로 red,green, blue 색상으로 이뤄진 데이터\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n",
        "''' 데이터 확인하기 '''\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "''' multi layer perceptron(MLP) 모델 설계하기 '''\n",
        "class Net(nn.Module):                                                      # nn.module 클래스를 상속받는 net 클래스를 정의\n",
        "    def __init__(self):                                                    # net 클래스의 인스턴스를 생성했을 때 갖게 되는 성질을 정의\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(32 * 32 * 3, 512)\n",
        "        self.fc2 = nn.Linear(512, 256)\n",
        "        self.fc3 = nn.Linear(256,10)\n",
        "\n",
        "    def forward(self,x):\n",
        "      x = x.view(-1,32*32*3)                                               # cifar-10 이미지 데이터는 32*32*3 크기의 2차원 데이터이기 때문에 이를 1차원으로 바꾸기 위함\n",
        "      x = self.fc1(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc2(x)\n",
        "      x = F.relu(x)\n",
        "      x = self.fc3(x)\n",
        "      x = F.log_softmax(x, dim = 1)\n",
        "      return x\n",
        "\n",
        "''' optimizr, objective function 설정하기 '''\n",
        "model = Net().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(model)\n",
        "\n",
        "''' MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()                                                          # 학습 상태로 지정\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):              \n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()                                              # loss의 gradient값이 optimizer에 할당돼 있으므로 gradient를 초기화한다.\n",
        "        output = model(image)                                              # MLP모델의 input으로 이용해 output을 계산\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()                                                    # loss값을 계산한 결과를 바탕으로 back grapagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
        "        optimizer.step()                                                   # 파라미터들을 업데이트\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))\n",
        "            \n",
        "''' 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "''' MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1gZymuaZ6Wu"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                  train = True,\n",
        "                                  download = True,\n",
        "                                  transform = transforms.ToTensor())\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                train = False,\n",
        "                                transform = transforms.ToTensor())\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "class CNN(nn.Module):                                                     # 마찬가지로 nn.module 클래스를 상속받는다.\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()                                       \n",
        "        self.conv1 = nn.Conv2d(                                           # 2차원 이미지 데이터를 nn.conv2d메서드를 이용해 convolution연산을 하는 filter,\n",
        "                               in_channels = 3,                           # filter의 크기는 상관없지만, 채널 수를 이미지의 채널 수와 동일하게 맞춰야 한다. 그래서 3으로 지정\n",
        "                               out_channels = 8,                          # 설정해주는 filter개수만큼 depth가 정해진다. filter개수만큼 앞뒤로 쌓아 feature map을 형성하기 때문이다.\n",
        "                               kernel_size = 3,                           # filter의 크기를 정하는 부분이다. 스칼라 값으로 설정하려면 가로*세로 크기인 filter을 이용해야 한다. \n",
        "                                                                          # 여기서 3x3 로 이용한다. 3x3 filter가 이미지 위를 9개의 픽셀 값과 filter 내에 있는 9개의 파라미터 값을 연산으로 진행\n",
        "                               padding = 1)                               # 중앙에 비해 가장자리가 덜 연산되기에 테두리에 0을 채워 연산 횟수를 동일하게 맞춰주는 것\n",
        "                                                                          # 1로 설정하면 왼쪽에 1층, 오른쪽에 1층, 위 1층, 아래 1층으로 채움\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8,                           # 앞에서 filter 수를 8로 했기에 입력을 8로 한다.\n",
        "                               out_channels = 16,                         # depth를 16으로 지정\n",
        "                               kernel_size = 3, \n",
        "                               padding = 1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)             # convolution을 통해 feature map이 생성됐을 때, feture map을 부분적으로 이용한다. \n",
        "                                                                          # convolution을 통해 다양한 수치가 생성되기 때문이다. maxpool2d는 2차원의 feature map 내에서 가장 큰 값만 이용\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 64)                              # convolution을 하는 이유는 이미지 내 픽셀과의 조합을 통한 특징을 추출\n",
        "                                                                          # feature map을 다양한 convolution을 통해 추출 후 1차원으로 펼친 후 여러 층의 fully connected layer를 통과시켜 분류\n",
        "                                                                          # 1차원으로 펼쳐도 이미 주변 정보를 반영한 결괏값으로 존재하기 때문에, 기존의 한계를 해결할 수 있다. \n",
        "                                                                          # 앞의 conv1,conv2 연산에서 feature map의 크기는 forward부분을 계산한 결과 8*8*16크기의 map이 된다.\n",
        "                                                                          # 즉 8*8의 2차원 데이터 16개가 겹쳐 있는 형태이다. 이를 1차원 데이터로 펼쳐 이용한다.\n",
        "        self.fc2 = nn.Linear(64, 32)                        \n",
        "        self.fc3 = nn.Linear(32, 10)                                      # 원핫인코딩으로 표현된 벡터 값과 loss를 계산해야 하므로 10으로 설정\n",
        "        \n",
        "    def forward(self, x):                                                 # forward propagation을 정의\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)                                                     # convolution연산을 통해 생성된 feature map값에 비선형 함수 relu를 적용\n",
        "        x = self.pool(x)                                                  # maxpooling을 통해 생성된 feature map에 다운 샘플링을 적용한다.\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "''' optimizr, objective function 설정하기 '''\n",
        "model = Net().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "print(model)\n",
        "\n",
        "''' MLP 모델 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()                                                          # 학습 상태로 지정\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):              \n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()                                              # loss의 gradient값이 optimizer에 할당돼 있으므로 gradient를 초기화한다.\n",
        "        output = model(image)                                              # MLP모델의 input으로 이용해 output을 계산\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()                                                    # loss값을 계산한 결과를 바탕으로 back grapagation을 통해 계산된 gradient 값을 각 파라미터에 할당\n",
        "        optimizer.step()                                                   # 파라미터들을 업데이트\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))\n",
        "            \n",
        "''' 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "\n",
        "''' MLP 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "x1CrcTrrxW7J"
      },
      "source": [
        "## 3. Data Augmentation\n",
        "CNN을 포함한 딥러닝 모델은 graphical Feature을 학습시키는 것이 목적이다. 복잡한 모델을 만들기 위해서는 다양한 데이터가 필요하다. 하지만 우리가 갖고 있는 데이터는 한정적이다. 이를 위해 data augmentation을 사용한다. 데이터를 임의로 변형해 데이터의 수를 늘려 다양한 feature을 뽑는 방법을 data augmentation이라 한다.\n",
        "\n",
        "- random flip: flip은 '반전'을 뜻한다. 이미지를 랜덤하게 좌우 또는 상하 반전시키는 random flip이다. \n",
        "- rotation: 이미지를 회전시키는 것\n",
        "- crop: 이미지의 일정 부분을 잘라 사용하는 기법\n",
        "- scaling: 이미지를 확대 또는 축소시키는 기법\n",
        "- cutout: 이미지의 일부를 사각형 모양으로 검은색을 칠하는 기법\n",
        "- cutmix: 두 이미지를 합쳐놓고 이미지의 label을 학습시킬 때 각각의 이미지가 차지하는 비율만큼 학습시키는 방법이다. 전체 중 비율이 70%:30%이면 labeling할 때 0.7, 0.3 으로 처리"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c0RxTTkzlhf5",
        "outputId": "fd0c2b2b-2712-4d6f-c74c-3286839a183d"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                  train = True,\n",
        "                                  download = True,\n",
        "                                  transform = transforms.Compose([                            # 불러오는 이미지 데이터에 전처리 및 augmentation을 다양하게 적용할 때 이용하는 메서드\n",
        "                                    transforms.RandomHorizontalFlip(),                        # 해당 이미지를 50%의 확률로 좌우 반전하는 것을 의미\n",
        "                                    transforms.ToTensor(),                                    # 0에서 1사이의 값으로 정규화하며 딥러닝 모델의 input으로 이용될 수 있도록 tensor 형태로 변환\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])) # totensor 형태로 전환된 이미지에 대해 또 다른 정규화를 진행하는 것을 의미\n",
        "                                                                                              # 정규화를 진행할 때는 평균과 표준편차가 필요한데 rgb순으로 평균을 0.5씩 적용\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                train = False,\n",
        "                                transform = transforms.Compose([\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "class CNN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(CNN, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(in_channels = 3, out_channels = 8, kernel_size = 3, padding = 1)\n",
        "        self.conv2 = nn.Conv2d(in_channels = 8, out_channels = 16, kernel_size = 3, padding = 1)\n",
        "        self.pool = nn.MaxPool2d(kernel_size = 2, stride = 2)\n",
        "        self.fc1 = nn.Linear(8 * 8 * 16, 64)\n",
        "        self.fc2 = nn.Linear(64, 32)\n",
        "        self.fc3 = nn.Linear(32, 10)\n",
        "        \n",
        "    def forward(self, x):\n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        x = self.conv2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.pool(x)\n",
        "        \n",
        "        x = x.view(-1, 8 * 8 * 16)\n",
        "        x = self.fc1(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc2(x)\n",
        "        x = F.relu(x)\n",
        "        x = self.fc3(x)\n",
        "        x = F.log_softmax(x)\n",
        "        return x\n",
        "\n",
        "model = CNN().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)\n",
        "\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))\n",
        "            \n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.8.1+cu101  Device: cpu\n",
            "Files already downloaded and verified\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train: torch.Size([32, 3, 32, 32]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n",
            "CNN(\n",
            "  (conv1): Conv2d(3, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (conv2): Conv2d(8, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
            "  (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
            "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
            "  (fc2): Linear(in_features=64, out_features=32, bias=True)\n",
            "  (fc3): Linear(in_features=32, out_features=10, bias=True)\n",
            ")\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:80: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Train Epoch: 1 [0/50000 (0%)]\tTrain Loss: 2.321579\n",
            "Train Epoch: 1 [6400/50000 (13%)]\tTrain Loss: 1.898040\n",
            "Train Epoch: 1 [12800/50000 (26%)]\tTrain Loss: 1.741167\n",
            "Train Epoch: 1 [19200/50000 (38%)]\tTrain Loss: 1.399217\n",
            "Train Epoch: 1 [25600/50000 (51%)]\tTrain Loss: 1.335448\n",
            "Train Epoch: 1 [32000/50000 (64%)]\tTrain Loss: 1.755757\n",
            "Train Epoch: 1 [38400/50000 (77%)]\tTrain Loss: 1.445097\n",
            "Train Epoch: 1 [44800/50000 (90%)]\tTrain Loss: 1.580356\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 1.3143, \tTest Accuracy: 52.49 % \n",
            "\n",
            "Train Epoch: 2 [0/50000 (0%)]\tTrain Loss: 0.909333\n",
            "Train Epoch: 2 [6400/50000 (13%)]\tTrain Loss: 1.205369\n",
            "Train Epoch: 2 [12800/50000 (26%)]\tTrain Loss: 1.572615\n",
            "Train Epoch: 2 [19200/50000 (38%)]\tTrain Loss: 0.950704\n",
            "Train Epoch: 2 [25600/50000 (51%)]\tTrain Loss: 1.340434\n",
            "Train Epoch: 2 [32000/50000 (64%)]\tTrain Loss: 1.071606\n",
            "Train Epoch: 2 [38400/50000 (77%)]\tTrain Loss: 1.369460\n",
            "Train Epoch: 2 [44800/50000 (90%)]\tTrain Loss: 1.077925\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 1.1681, \tTest Accuracy: 58.21 % \n",
            "\n",
            "Train Epoch: 3 [0/50000 (0%)]\tTrain Loss: 1.333817\n",
            "Train Epoch: 3 [6400/50000 (13%)]\tTrain Loss: 1.246729\n",
            "Train Epoch: 3 [12800/50000 (26%)]\tTrain Loss: 1.397109\n",
            "Train Epoch: 3 [19200/50000 (38%)]\tTrain Loss: 1.096369\n",
            "Train Epoch: 3 [25600/50000 (51%)]\tTrain Loss: 1.623523\n",
            "Train Epoch: 3 [32000/50000 (64%)]\tTrain Loss: 1.160185\n",
            "Train Epoch: 3 [38400/50000 (77%)]\tTrain Loss: 1.318623\n",
            "Train Epoch: 3 [44800/50000 (90%)]\tTrain Loss: 1.025650\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 1.0974, \tTest Accuracy: 60.95 % \n",
            "\n",
            "Train Epoch: 4 [0/50000 (0%)]\tTrain Loss: 0.886570\n",
            "Train Epoch: 4 [6400/50000 (13%)]\tTrain Loss: 1.191521\n",
            "Train Epoch: 4 [12800/50000 (26%)]\tTrain Loss: 0.915007\n",
            "Train Epoch: 4 [19200/50000 (38%)]\tTrain Loss: 0.934156\n",
            "Train Epoch: 4 [25600/50000 (51%)]\tTrain Loss: 0.955785\n",
            "Train Epoch: 4 [32000/50000 (64%)]\tTrain Loss: 1.177388\n",
            "Train Epoch: 4 [38400/50000 (77%)]\tTrain Loss: 1.007716\n",
            "Train Epoch: 4 [44800/50000 (90%)]\tTrain Loss: 1.390848\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 1.0368, \tTest Accuracy: 63.57 % \n",
            "\n",
            "Train Epoch: 5 [0/50000 (0%)]\tTrain Loss: 0.958666\n",
            "Train Epoch: 5 [6400/50000 (13%)]\tTrain Loss: 0.906851\n",
            "Train Epoch: 5 [12800/50000 (26%)]\tTrain Loss: 0.903545\n",
            "Train Epoch: 5 [19200/50000 (38%)]\tTrain Loss: 1.187562\n",
            "Train Epoch: 5 [25600/50000 (51%)]\tTrain Loss: 0.791414\n",
            "Train Epoch: 5 [32000/50000 (64%)]\tTrain Loss: 0.839916\n",
            "Train Epoch: 5 [38400/50000 (77%)]\tTrain Loss: 0.806148\n",
            "Train Epoch: 5 [44800/50000 (90%)]\tTrain Loss: 0.946282\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 1.0457, \tTest Accuracy: 63.22 % \n",
            "\n",
            "Train Epoch: 6 [0/50000 (0%)]\tTrain Loss: 1.244785\n",
            "Train Epoch: 6 [6400/50000 (13%)]\tTrain Loss: 1.018391\n",
            "Train Epoch: 6 [12800/50000 (26%)]\tTrain Loss: 1.152586\n",
            "Train Epoch: 6 [19200/50000 (38%)]\tTrain Loss: 0.798300\n",
            "Train Epoch: 6 [25600/50000 (51%)]\tTrain Loss: 1.060555\n",
            "Train Epoch: 6 [32000/50000 (64%)]\tTrain Loss: 0.997629\n",
            "Train Epoch: 6 [38400/50000 (77%)]\tTrain Loss: 1.010223\n",
            "Train Epoch: 6 [44800/50000 (90%)]\tTrain Loss: 0.923815\n",
            "\n",
            "[EPOCH: 6], \tTest Loss: 0.9903, \tTest Accuracy: 65.05 % \n",
            "\n",
            "Train Epoch: 7 [0/50000 (0%)]\tTrain Loss: 1.090542\n",
            "Train Epoch: 7 [6400/50000 (13%)]\tTrain Loss: 1.056737\n",
            "Train Epoch: 7 [12800/50000 (26%)]\tTrain Loss: 1.253563\n",
            "Train Epoch: 7 [19200/50000 (38%)]\tTrain Loss: 1.040993\n",
            "Train Epoch: 7 [25600/50000 (51%)]\tTrain Loss: 0.938453\n",
            "Train Epoch: 7 [32000/50000 (64%)]\tTrain Loss: 0.739768\n",
            "Train Epoch: 7 [38400/50000 (77%)]\tTrain Loss: 1.048925\n",
            "Train Epoch: 7 [44800/50000 (90%)]\tTrain Loss: 0.870516\n",
            "\n",
            "[EPOCH: 7], \tTest Loss: 1.0059, \tTest Accuracy: 65.55 % \n",
            "\n",
            "Train Epoch: 8 [0/50000 (0%)]\tTrain Loss: 1.357772\n",
            "Train Epoch: 8 [6400/50000 (13%)]\tTrain Loss: 0.789993\n",
            "Train Epoch: 8 [12800/50000 (26%)]\tTrain Loss: 1.134917\n",
            "Train Epoch: 8 [19200/50000 (38%)]\tTrain Loss: 0.789851\n",
            "Train Epoch: 8 [25600/50000 (51%)]\tTrain Loss: 0.970798\n",
            "Train Epoch: 8 [32000/50000 (64%)]\tTrain Loss: 1.015181\n",
            "Train Epoch: 8 [38400/50000 (77%)]\tTrain Loss: 0.972808\n",
            "Train Epoch: 8 [44800/50000 (90%)]\tTrain Loss: 0.533952\n",
            "\n",
            "[EPOCH: 8], \tTest Loss: 0.9741, \tTest Accuracy: 65.96 % \n",
            "\n",
            "Train Epoch: 9 [0/50000 (0%)]\tTrain Loss: 0.919060\n",
            "Train Epoch: 9 [6400/50000 (13%)]\tTrain Loss: 1.229538\n",
            "Train Epoch: 9 [12800/50000 (26%)]\tTrain Loss: 0.912528\n",
            "Train Epoch: 9 [19200/50000 (38%)]\tTrain Loss: 0.749151\n",
            "Train Epoch: 9 [25600/50000 (51%)]\tTrain Loss: 0.643934\n",
            "Train Epoch: 9 [32000/50000 (64%)]\tTrain Loss: 0.569144\n",
            "Train Epoch: 9 [38400/50000 (77%)]\tTrain Loss: 0.666641\n",
            "Train Epoch: 9 [44800/50000 (90%)]\tTrain Loss: 1.072916\n",
            "\n",
            "[EPOCH: 9], \tTest Loss: 0.9349, \tTest Accuracy: 67.58 % \n",
            "\n",
            "Train Epoch: 10 [0/50000 (0%)]\tTrain Loss: 0.728883\n",
            "Train Epoch: 10 [6400/50000 (13%)]\tTrain Loss: 0.834060\n",
            "Train Epoch: 10 [12800/50000 (26%)]\tTrain Loss: 0.706481\n",
            "Train Epoch: 10 [19200/50000 (38%)]\tTrain Loss: 0.536133\n",
            "Train Epoch: 10 [25600/50000 (51%)]\tTrain Loss: 0.899137\n",
            "Train Epoch: 10 [32000/50000 (64%)]\tTrain Loss: 1.154496\n",
            "Train Epoch: 10 [38400/50000 (77%)]\tTrain Loss: 0.804938\n",
            "Train Epoch: 10 [44800/50000 (90%)]\tTrain Loss: 0.887077\n",
            "\n",
            "[EPOCH: 10], \tTest Loss: 0.9326, \tTest Accuracy: 67.77 % \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CdL-02BCd60q"
      },
      "source": [
        "## 4. CNN Archiecture\n",
        "- imageNet: 이미지 분류 모델을 측정하기 위한 데이터로 가장 많이 사용되는 데이터셋. \n",
        "- network architecture: 과적합이나 gradient vanishing을 방지하는 activation함수, batch normalization, dropout, initialization, data augmentation 등등이 있다. 또한 네트워크를 깊게 쌓으면서 과적합을 방지하는 net architecture이 있다.\n",
        "- LeNet: 최초의 CNN 모델. 32x32 input과 convolution 2개, pooling layer 2개, fully connected layer 3개를 가지고 있다.\n",
        "- alexNet: 224x224 크기의 RGB 3 channel image를 input으로 사용. activation 함수는 ReLU를 사용.\n",
        "- VGG: 3x3 convolution layer을 깊게 중첩한다.\n",
        "- GoogLeNet: 구글이 제안한 모델로 google+net. inception 모듈이라는 개념을 사용. 기존의 CNN구조는 Convolution 다음의 pooling layer을 거치는 것이 일반적이나 inception modeld 은 한 layer 내에서 서로 다른 연산을 거친 후 feature map을 다시 합치는 방식. 이렇게 하면 한 feature map에서 여러 convolution을 적용할 수 있기에 작은 규모, 큰 규모의 feature을 한번에 학습할 수 있다. 또한 마지막 fully connected layer에서 GAP(global average pooling) 으로 대체해 파라미터의 수를 크게 줄이는 효과가 있다.\n",
        "- ResNet: 마이크로소프트에서 제안한 모델. residual block이라는 개념을 도입했고, 이전의 layer의 feature map을 다음 layer의 feature map에 더해주는 개념. 네크워크가 깊어짐에 따라 뒤의 layer이 희석된다. 그래서 이전의 정보를 뒤에서도 함께 활용하는 개념이다.\n",
        "- denseNet: resnet의 확장 버전. 이전 layer과 다음 layer에 skip connection을 적용하는 모델이라면 densenet은 모든 layer에 skip connection을 적용하는 모델이다. 첫번째 layer에 대한 정보를 두, 세번째, 마지막 layer에도 함께 학습시킨다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LY_YM1Xr1K6n",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "b01407801eb4472f8108ef1dbf9f4387",
            "598832004cb449bd913b3016921e42b1",
            "3a805384f21740958a8d0df4da70f2cb",
            "58e19de7d3ef4d018a67db4e60c0af74",
            "304829cc958243f0a9665c988f866c8d",
            "7bd3e8bc815c4183a7f2576bbdbd347c",
            "9baa080c78754c50a094ce61027d7568",
            "70dc2d202d324345a64e6b5d787742b1",
            "8c2c7ea42fcc488f9ea89ec20f6d3904",
            "d8c5b346a8e34ffaafe0c47ba1bac6e4",
            "4e493718f5074968b324f3eb50cccbaf"
          ]
        },
        "outputId": "a13b69ee-0fa1-469d-b0ba-fdd3d1ab9cdf"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "train_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                  train = True,\n",
        "                                  download = True,\n",
        "                                  transform = transforms.Compose([\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "test_dataset = datasets.CIFAR10(root = \"../data/CIFAR_10\",\n",
        "                                train = False,\n",
        "                                transform = transforms.Compose([\n",
        "                                    transforms.RandomHorizontalFlip(),\n",
        "                                    transforms.ToTensor(),\n",
        "                                    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]))\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                            batch_size = BATCH_SIZE,\n",
        "                                            shuffle = True)\n",
        "\n",
        "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
        "                                          batch_size = BATCH_SIZE,\n",
        "                                          shuffle = False)\n",
        "\n",
        "for (X_train, y_train) in train_loader:\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('off')\n",
        "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "class BasicBlock(nn.Module):                                                                                    # 반복적으로 이용하는 block을 먼저 정의\n",
        "    def __init__(self, in_planes, planes, stride = 1):                                                          # in_planes, planes, stride값을 인자로 받았을 때 basicblock의 인스턴스를 생성 stride는 기본적으로 1로 설정\n",
        "        super(BasicBlock, self).__init__()         \n",
        "        self.conv1 = nn.Conv2d(in_planes, planes,                                                               # basicblock이 input으로 이용되는 데이터의 채널 수를 의미하는 in_planes 값을 인자 값으로 받아준다. \n",
        "                                                                                                                # 특정 인스턴스를 생성할 때 입력해주는 값으로 이용하는 것이다. \n",
        "                                                                                                                # filter의 개수는 위에서 인자 값으로 입력된 planes 값을 통해 filter 개수가 정해진다.\n",
        "                               kernel_size = 3,                                                                 # filter의 크기는 3x3크기로 설정하는 단계\n",
        "                               stride = stride,                                                                 # filter가 움직이는 단위를 위에서 인자 값으로 받는 stride로 설정\n",
        "                               padding = 1,                                                                     # filter가 이미지 위를 지나다니면서 convolution연산을 진행할 때 이미지 구석부분을 더 연산하기 위해 zero padding한다.\n",
        "                               bias = False)                                                                    # 이미지의 각 픽셀 값, filter의 파라미터 값, convolutino 연산을 한 이후 bias 값을 더해줄 것인지를 선택\n",
        "        self.bn1 = nn.BatchNorm2d(planes)                                                                       # batch normalization은 각 layer마다 input의 분포가 달라짐에 따라 학습속도가 현저히 느려지는 것을 방지\n",
        "        self.conv2 = nn.Conv2d(planes, planes, kernel_size = 3, stride = 1, padding = 1, bias = False)\n",
        "        self.bn2 = nn.BatchNorm2d(planes)\n",
        "        self.shortcut = nn.Sequential()                                                                         # resnet의 특징인 shortcut을 정의하는 부분. shortcut는 기존의 값과 convolution 및 batch normalization한 결과를 더하는 과정\n",
        "        if stride != 1 or in_planes != planes:                                                                  # stride값이 1이 아니거나 in_planes와 planes가 다르다면, 즉 두 번째 블록부터 적용되는 shortcut를 정의\n",
        "            self.shortcut = nn.Sequential(                                                                      \n",
        "                nn.Conv2d(in_planes, planes,                                                                    # 위와 같이 in_planes와 planes를 인자 값으로 받음. filter 개수는 동일할 것\n",
        "                          kernel_size = 1,                                                                      # 적용되는 filter의 크기는 1이므로 1\n",
        "                          stride = stride, bias = False),                                                       \n",
        "                nn.BatchNorm2d(planes))\n",
        "    \n",
        "    def forward(self, x):                                                                                       # forward propagation을 정의\n",
        "        out = F.relu(self.bn1(self.conv1(x)))                                                                   # self.conv1를 이용해 채널 수가 planes인 feature map을 생성하고 self.bn1을 이용해 batch normalization을 계산.\n",
        "        out = self.bn2(self.conv2(out))                                                                         # 계산된 out을 self.conv2를 이용해 채널 개수가 planes feature map을 생성하고 self.bn2를 이용해 batch normalization을 계산\n",
        "        out += self.shortcut(x)                                                                                 # out 과 sortcut를 이용해 더한다. 이 부분을 skip connectino이라 한다.\n",
        "        out = F.relu(out)                                                                                       # 위의 결과값에 relu함수를 적용해 결괏값을 반환\n",
        "        return out\n",
        "    \n",
        "class ResNet(nn.Module):                                                                                        # resnet 모델 구현\n",
        "    def __init__(self, num_classes = 10):                                                                       # ResNet 클래스의 인스턴스를 생성했을 때 지니게 되는 성질을 정의해주는 메서드, 에측해야할 클래스를 10으로 정의\n",
        "        super(ResNet, self).__init__()                                                       \n",
        "        self.in_planes = 16                                                                                     #in_planes를 16으로 고정. 즉, ResNet 클래스의 인스턴스들은 in_planes값이 16으로 고정.convolution을 계산할 때 16 채널 수로 진행\n",
        "        self.conv1 = nn.Conv2d(3, 16, kernel_size = 3, stride = 1, padding = 1, bias = False)                   # 여기서 self.conv1는 basicblock 내에서의 self.conv1와는 다른 메서드다. filter 개수는 16으로 정의\n",
        "        self.bn1 = nn.BatchNorm2d(16)                                                                           # 벡터 크기가 16인 2차원 데이터에 적용할 수 있는 batch normalization 연산을 정의\n",
        "        self.layer1 = self._make_layer(16, 2, stride = 1)                                                       # 첫번째 레이어를 생성한다.\n",
        "        self.layer2 = self._make_layer(32, 2, stride = 2)                                                       # 두번째 레이어를 생성\n",
        "        self.layer3 = self._make_layer(64, 2, stride = 2)                                                       \n",
        "        self.linear = nn.Linear(64, num_classes)                                                                # make_layer 메서드를 정의하는 부분. planes, num_blocks, stride를 인자 값으로 받아 여러 층의 레이어를 구성해 반환하는 메서드\n",
        "        \n",
        "    def _make_layer(self, planes, num_blocks, stride):                                                          # make_layer를 이용할 때 인자 값으로 주어지는 stride를 이용해 stride범위를 basicblock마다 설정할 수 있도록 정의\n",
        "        strides = [stride] + [1] * (num_blocks  - 1)                                                           \n",
        "        layers = []                                                                                             # basicblock을 통해 생성된 결괏값을 추가하기 위해 빈 리스트를 정의\n",
        "        for stride in strides:                                                                                  # stride 범위를 반복문의 범위로 지정\n",
        "            layers.append(BasicBlock(self.in_planes, planes, stride))                                           \n",
        "            self.in_planes = planes                                                                             # self.in_planes 값을 매번 업데이트해 self.in_planes를 planes 값으로 업데이트한다. shortcut를 계산하기 위함.\n",
        "        return nn.Sequential(*layers)                                                                           # 여러 층으로 생성한 레이어를 nn.sequential 내에 정의해 반환\n",
        "    \n",
        "    def forward(self, x):                                                                                       # resnet 모델의 forward propagatoin을 정의\n",
        "        out = F.relu(self.bn1(self.conv1(x)))                                                                   # self.conv1을 이용해 채널 수가 planes인 feature map을 생성하고 self.bn1을 이용해 batch normalization을 계산한다.\n",
        "        out = self.layer1(out)                                                                                  # make_layer 메서드를 이용해 생성한 첫번째 레이어를 통과시킨다. 16채널을 input으로 받아 16채널을 output으로 계산하는 basicblock을 2개\n",
        "        out = self.layer2(out)                                                                                  # 16채널을 input으로 받아 32채널을 output으로 계산하는 basicblock 1개, 32채널을 input으로 받아 32채널을 output으로 계산하는 basicblock을 1개 생성\n",
        "        out = self.layer3(out)                                                                                  # 32채널을 input으로 받아 64채널을 output으로 계산하는 basicblock 1개, 64채널을 input으로 받아 64채널을 output으로 계산하는 basicblock을 1개 생성\n",
        "        out = F.avg_pool2d(out, 8)                                                                              # feature map에 2차원의 average pooling을 이용해 8x8크기의 filter가 움직이면서 64개의 feature map 값의 평균을 계싼해 1개의 feature map으로 다운 샘플링\n",
        "        out = out.view(out.size(0), -1)                                                                         # 1차원 벡터로 펼처줌\n",
        "        out = self.linear(out)                                                                                  # 1차원 벡터를 10개의 노드로 구성된 fully connected layer와 연결해 최종적으로 10 크기의 벡터를 출력\n",
        "        return out\n",
        "\n",
        "model = ResNet().to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "print(model)\n",
        "\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))\n",
        "            \n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, train_loader, optimizer, log_interval = 200)\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using PyTorch version: 1.9.0+cu111  Device: cpu\n",
            "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ../data/CIFAR_10/cifar-10-python.tar.gz\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b01407801eb4472f8108ef1dbf9f4387",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "  0%|          | 0/170498071 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting ../data/CIFAR_10/cifar-10-python.tar.gz to ../data/CIFAR_10\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "X_train: torch.Size([32, 3, 32, 32]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "  (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(16, 32, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(16, 32, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential(\n",
            "        (0): Conv2d(32, 64, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (shortcut): Sequential()\n",
            "    )\n",
            "  )\n",
            "  (linear): Linear(in_features=64, out_features=10, bias=True)\n",
            ")\n",
            "Train Epoch: 1 [0/50000 (0%)]\tTrain Loss: 2.386863\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-1-c16c6eccd36f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mEPOCHS\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 155\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlog_interval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    156\u001b[0m     \u001b[0mtest_loss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_accuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m     print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
            "\u001b[0;32m<ipython-input-1-c16c6eccd36f>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(model, train_loader, optimizer, log_interval)\u001b[0m\n\u001b[1;32m    125\u001b[0m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    126\u001b[0m         \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcriterion\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 127\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    128\u001b[0m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    253\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 255\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    256\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    147\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[1;32m    148\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 149\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # allow_unreachable flag\n\u001b[0m\u001b[1;32m    150\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAjwAAABNCAYAAACi7r7XAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9eaxdyX3f+flVneXu9y0kH/m49d7N7pa6W5FlyJItS6NI48SW7Tie8ZJlPAkSjDFA4iQzyAzgGSEOZknyR2aAMQIEDpKBnYEzNmQ5sh15ZFmyZcuyWi31wiabbLK58+3v3f1sVTV/1LnvPbLZ5OPSzUX3CxyQ795z6tTvnlO/+tZvK3HOMcEEE0wwwQQTTPAgQ93tDkwwwQQTTDDBBBO825gQngkmmGCCCSaY4IHHhPBMMMEEE0wwwQQPPCaEZ4IJJphgggkmeOAxITwTTDDBBBNMMMEDjwnhmWCCCSaYYIIJHnjcNuERkc+KyK/eic7cq5jIeP/jQZcPJjI+KHjQZXzQ5YOJjPcqdkR4RORnRORFEemLyGUR+T0R+ei73bkd9OtQ2afthxORf3gLbd2TMgKIyB+KyLKIdEXkZRH50Vts516W8ZdE5FURKUTks7fYxr0s3wP/DMcQkY+V4/Cf3uL1ExnvIkTkeRH5YxHpiMgFEfnFW2jjXpbvjIiMts0Zv3+L7dzLMn6fiPy5iPRE5JVb7de9LOMYNzMWb0h4ROQfAP8S+F+AOeAQ8MvALSnsOwnn3DnnXGN8AO8DLPCbN9POvSxjib8H7HPOtYC/A/yqiOy7mQbuAxnfBP574Hdu5eL7QL7vhmeIiITA/wF84xavn8h49/HvgT8CZoCPAT8vIp/Z6cX3gXwAP7Jt7vjUzV58L8soIjPAfwT+OTAF/DPgP4rI9E22c8/KOMZNj0Xn3DseQBvoAz95nXM+C/zqtr//X2AB6OAHzTPbvvtLwOtAD7gI/KPy813AF4ANYA34Y0Bdr2/v0Jf/GfjDm7zmfpPxQ0ACfOhBlBH4VeCzk2d4f8oI/GO8gv23wD99EJ/jgy4jMASevur+/8MDJN8Z4JM389zuJxmBHwaOXvXZCeBvPSgybmv3psbijSw8HwYqwOducN52/B7wOLAHeAn4tW3f/Qrwd51zTeBZ4Mvl5/8QuADsxjPJ/xFwACLyyyLyyze6qYgI8DeAf3cTfYX7REYR+YKIJHgm+xXgxZvo730h423gvpDvQX+GInIY+K+Bf3ITfdyOiYzXxnv9rv5L4G+ISCgiT5Z9/tIO+3o/yAfwa6WL+fdF5Lmb6CvcHzLKNf5+9ib6e8/LeCtjMbjB97PAinOu2GmDzrl/s61DnwXWRaTtnOsAOfC0iLzsnFsH1stTc2AfcNg59yae5Y3b+/kd3vqj+B/sN3ba1xL3hYzOuR8uzXefBI445+xO+8t9IuNt4L6Q77vgGf6fwC865/p+/XHTmMh4DdwFGb8A/N/APwI08E+cc9/cYXfvB/l+Fj8hC97V/EUReco5t7HDLt/rMn4dmBeRn8bPhz8DPArUdtpf7n0Z4RbG4o0sPKvALhG5ETECQES0iPxvInJKRLp40yF4sxXAT+BNW2dF5Ksi8uHy83+Oj+H4fRE5LSL/eEe9vxJ/E/hN51z/Jq+7b2R0zuXOud8DPnUzPnXuIxlvEfeNfA/qMxSRHwGazrlf36E818JExrff872WcQb4T/hVcwU4CHxaRHa6YLmn5QNwzv2Jc27knBs65/5XvDvl+3d6Pfe4jM65VXyczT8AFoH/HG+hu7CT60vc0zLe8li8gX+sDQyAv3qdcz5L6ccD/jpwDHgYz56n8Oapx666JgR+ATh/jfaeBZaA/+x6fbvqmireb/iJnV5zv8l41fVfAn7hQZSRW4/huS/ke1CfId4N0sX78BeAET4G4PMTGe8rGT8IrF/12d8HvvAgyPcO/TkGfOZBeYbXuDYAzgGfflBkvNWxeF0Lj/OmqP8J+L9E5MdEpCber/tDIvLPrnFJE0jx7LCGj+4GQEQiEfnZ0sSVl5215Xc/LCKPiYjgiYsZf7dD/DjeRPaHN3HNfSGjiDxV9qVa9uuvAT8AfPVBkbG8NhSRCt7qGIhIRUT0gyDfd8kz/EXgCeD58vht4F8DPzeR8b6S8YS/XH5GRJSI7AX+S+CVB0E+8aVMPlK2XRGR/w5vhfiTnch3P8hYXvtC2acW8C/wBOOLD5CMtzYWd8j2fhYfYDnAs6nfAb7vGiyvAXweH4l9Fh9E7IDHgAhvKl0vBf4m8NHyul/Am8AGeLPbL267978C/tUN+vdF4JdulvneDzICR/BBrj286fWbwI8/SDKW3//b8h7bj//qQZDvu+UZXuN53lQG00TGe0NG4BNlW52yb/8aqD0I8gHP4MnbAD85/wHwwQfwGf4/5fPrAL8O7HnQZLyVsSjlyRNMMMEEE0wwwQQPLCZ7aU0wwQQTTDDBBA88JoRnggkmmGCCCSZ44DEhPBNMMMEEE0wwwQOPCeGZYIIJJphgggkeeEwIzwQTTDDBBBNM8MDjulUUReS+TuFyzt2w3vR3g4wf//RPudXVJdbWlqg3Yur1OvVag9mZOdIkpygsn/zBH+T7PvQCH3z+acJYUBJgjfDtl95kmBSM0oLjb5wkzQ1JlvONl77CG8df5vSpY2BGd13GX/rf/51ToaAiRa1eJ4oioiiiWq0QRQFhGFCtVgmCgCAIiOOIIBR0IIRhgNYapTRaK5QCpUBE/OF7gXOGa+0G4ZzDWou11m8C4xwYhzMOaxxFXmCMwRhDlhWYwlEUljzLy+scn/74h64r43fDe3qFjApfoiws/87K44aNQLAbbAE2BxxELYhb4CrQrEI9hIXzkPYhH+KrfozvHJb3VtvumZef36BCyE5k/InP/Jx76NGnOPjI4/RtFy2OSAntWpNGo0qzWWV+/17iakQQB4gCZy3OOkRAiUKJ0IhDstySpIazF1YZJjl5bmg3NTNTLaan28zMzGCNpShyBoMegkOJoESgLMVf5BkmLzCFIc8dpvCHdYJWChFhvZOyuJCyvJTy83//I++pTo2jiFq1xhNPH+HQ4UPs3r2b3/6tz7O+tsZgMLiNlgWtKuggJIhCqvUZqrUWcbXJm0f/8Loy/tTf+5q71Mm4sJFxdikpC8rgN+EIQlAh/oUqQCxRqGhVFO2q0K4JmRNGVri0MqIwXl3E4ghDIQgU4HAmA1MQxYo4iIiDEC0KIQdyjIDW/lle7jkGXcuoayG1vsHxO20sWAd268V1x//6XZkXg/JQ+CqBSkEUa973kSe4dGaFC28ub56rFOw/VKPbyems5+/YZqUC8/NN5ve1mGq3aTQa1Oo1fuXfXPsZ7qhs9AT3N7rdAd1un26vjxNLHNcIgghREesbXZaXNzj72ApPPNZjNMpRSkCDSMDevbvoD1O6vSHOFVhjcMYx095FvTGLjluYYcLWjHF3EIYhKhR0qAhLUjM+tB7/q7cdCqUEpcUrDiUotaVElIBS2wyg1gLq7VvyAQ6HU4JDtuZOZ7E4RMr6DyJle4pCLEocgmCMZVIa4hrQQIyvoQ7+R90J4VEQzUGegh3666r7oLUXTAHtEOoB9ATsMuSrQMEWkangtaLG1221eMIz1pQ3Uw71Ghj21+l1h3Q6loFOqMYOHWuiSKjXQ5qtKo6U3FhMHuC09u+esWilEVcggHKWLCsYJTmD3gZpbjDGYSsVxBVoHGINzhTYIkcJGGMx9koBsizHFAVFXpAkliI3FLkBAoLAj5Fuv09vMKI/TG9P+B1Ca705XtvNFrt37eIHPvaDPPLYI8zOzvLKy68gIhRFgSpJmZcl21x4AIhSiNbY/MoJU7QGrTHZCJONyDJhmBgqo4Rq7caLt+99uMXp1YRqnHBxY0BWaLDaz+Q6gDDwbNsJOCFLHCtZwUrfUa8UoBVWCaNCwCqwiqLIPVlRFrQCI55gp4ZKbKjFiroyKJcjLqMAKqEmCjTOOJwtNc94TylVkh41Vli3tO/b2yDbWhK2tP5OhsX2dcWYixmr2LPvAN3VHNgiPNbB2saQLLl+m0kCa+sjnBSsdUbUGzWqtXfeMmxCeG4Snn/f7en95nDy1FmqtYjpXXvpdFYYXbzM0uIa73umRSAxs61dzLbmqMYNQLDWoZRDcDQaMUGoqFQDvv/7/wIbnT7rnT5h3WKVRbRw9KUvY8yO95h7V9Bs1iEQJBAq1Wpp4QmpVGKiKCQMA+I4JgxDgiAgigN06NCB21TsWilCpQjwh9ru8dUWxPljGyz2ihfCOYd1DqfBWoexjlwXm4o4DK238OSWvFTEE75zFQRfq9Xiy5gJV5KdEK+5rp6bNKgY5mdg3cBaClpg1zwcnIONDugMJIM4hlEVT3CG5f1iYK1s1+Drxo5f6ztkxEw5QW/UZn1tlnhXg0Ap4lARKIeIxbqCNB0iRkGmyZ0iHyUk/QEnXj1Kq9lgdmaWR585wnA4YqPT5cKFt+j3+oxGQ7QYms0m7XaLPXv2YEyBMZbDhx/yiwKlCIIAVVoui7xgMEoZjlKG/RFZasgzQxDEm9bObq9PanOIzZ35EW6AZ488zQeef4Enn36a+fl97N07x+FHHyWOY6yz/JUf+zEWFxfZ2Nhg3/w+wjDEWsf/96UvcfrUKS6cPw/A9OOP0H74MGf/4KvYfEs/NZ56hsZjT7Hwu1/A5X5GjZQmcBbJb/ygZ6vLyG5FrSYc6yrWOjAYOggFghx0ThSCMYIxCmxpprSOQT8BZUCsf1klBB2CVPBKpNQnGggd2JTEOrLUYUIhRhO5mKzwzahAqAQ1stiSFAWQe7bgnH93x7Xqi4Ir6cqNIZQcbtv/m/hhEpVHjh8mK+X/rzULiAKloR14sa2BpAAVQaUOrUaTOIqvvMjBoMOOJtrORkG3WyAqQcINrrf714Tw3AQE2NUMGGSWQXqbS733EFnuqKBQOiTNDK4wZMrQ6/TYt3uevbv3MVWrIIVh0B8Qx1WMtThVIFhv2bEZM9N1gtAhuiB7M6Eg92/QnVk83BaiKIJAIJBNd1YYhoRhVFp69CbZGf8dBM6THuWtL6K8dUejCEpNIZvrGO1H6zbC43CoK84bu7ccToGxDrF+1WWtxRiDiEOVx3sNAWYqUKmEhFFAd32EDhQ6UN4AX1jy3G5awG2pMwPxi04ojQ2uXKGxtbILBSINtVrp0TMwHPrrb2maDPAadHyD7cOtAtTLhktXQjwN9To061BtQ28AFNBsQbMBjaq38IwsDBPo9iDt4cnOuJ2wbLfPFtm5w4+p28+p9npU66vsbkeICXGFYIyjyA15luMsOOUNBGlhWV9aYeniJb70xS9yYO88jz78MCvDPhcuXuTcmbNcPneRNE3J8xzBEscRcexd19ZatNZ89CMf4fDhh5jfvx+lvFtMRBgmGb3+iG5vRL83oMgdxkCgC7SGIPBu4uZ0g2r73Z0uRISpqSk+8MG/wGd+5DPM7dtHq9mk0ajTaLXQWmOt5fnnnydJEowxTE1PoZXGGEOj0eCb3/hzvvXii5w89SajJMV1em+zoGbDIf31VZwzjB+wMUOyNMMUN97N5pXzq6REDExErCKCQPwAUA6lHTqAqWpEWsAoh0xJ6VYCdBWwXpdohZ+ddalDrX/olAsroSRDFiuOwkFUuttD5dDKIMoRKIPSQKC8hUk5fz+htDJts/zsUFk3KD105b9hAHEIe6chVuXwHHij1Mj5ZkcOEguDHJwFjL8u1BAH5VbtFqyA0VBpBjRnKgTOIPYa8+kOx55z4Azlb+y83ngHTAjPDiFAoGGmoXF97ivCIxLgnMZaIcsLXG4wOLqdDs889iTPPf0kgYAzOb1uj1Y7AgHrBLBYm2OLjNZMEysBo1zojjYYZkMKinvC2hWGobfwhKokOmFJeiKCQJUEp3RtBZow0KV1x6J9wA4iglaCdgrttsfzy9Y/st0w61dMPs5ni/A4cV7fKK4gPN78blECWl1RFv09gQhMVaDdCqjVq1zqJ4SRIqoGWCAZFYycxVg/1xclU4kUxOU8kG/7fHtYTaCgFsBs05OiLINi5PXPTRMehV8+gr/4agVWwW9NONo6NzoA09OwewoKDSoHhlBrQLUKlRBGEQwUDAroroPt4gvaa/xkJHjCM2Jn7rNbQG8Atd6Ien2d3cU05IILNcY48tyQJjmZslgs1lmSNGPhwkVOvXGCr37lKzzx0KMknT568Tyvv36Mo6+9Tn9t/bpmwiiKcMaQfzin0WwShuGmG2iYZGx0Bmx0hvR6fYwRrFVEQUEQQBgKs3Mz1KoNwrj+rvwmWgcoJQRBwIEDB/jABz/Ip/7SD/kx7by1wi8WfJ+PHDlCHMebhyu/n5+fp1GtYfKCy0uLjHLD+mrHv4TbkPa6pJcvbgV5AcaMMDt8Ub91doMgrCJBFe3aaK08WZaCILDEIczUKwwKh2QWAoszFmfA2goW5xlBYPEvnypNI6UFxppyYSWgvFlExJMkpRWhhlAMAQ6NIdQFKtCeQAV4eZXz7rKx9dne3Kq0yVYIXQBUQ7+geGifJy8aWF+GYQGV0ts/MNA33s1kMt/9KIJq4I+4NP9YfJhTezpiZk8DXWSIvT3roVAOAcN1Fc6E8OwQMzV/rC6nDN4by+4dwxMPP8XiwkUunLiItUNqrRlqzWkuXLrIpf1nWVvfxUMHD1IUfZaXQQVDmq069UYdqyKcdrjA0R1scOb8W7xx+gTffOlrrKxv0Ol2cPbuU544jkELEijiON608njSowhDVbqxhCDwAzFSQqg0SnwcgLfweEfW2IQ71hee/ngDr5UUN7b22MrmZCNWl1E8dqzGSleZ8xYTK2gRrPb+a8+RtsjSuw3r4K0OSHeEkGCtg1GBdLwmcrx93nRAaqC37Z0XYG8TeqknNgAjA4mB1UtX3u+mUcEvBR/CW1kG+N3HxtYY8Np4H1sPSEGvCqoGWQ0qMaQJuD4sFlAZeUJ29AwMu5B1wJ7FkxrDFuFJgGneVX/1qLcPM1X3q/KihxhbKugGw2HGcJRiMBhTYE1OkSYk3QG6JKGvnDzO0dMnQanNQPgb+USzLONzn/88C4tLLC0t8+wz70OUwlhLlll6gxG9fsJwkOCcf8fjsEK1FlOvVwnDiFq1QqVeve59bgVaa9535AX2zO1h7/wcP/ITP8JTTz1Zzvtm0xIVhuHmNTMzM4BfXOR5vrlw2LdvHz/64z/G93/sYzzzvd/LH33nNb7x6uv05KrxtboMaytXBPLeDL52KSwDjB26qklEIBKa9Yip2DEVO9oh7AtDgjAgCCyZKRhlhrNrEZ20oJ87v4I2yh+iwZWmEbFb3idVIVSOSmB4cjoncgZtQYcBSkWIcqykim4hkIo3p1wRLOPjiG6W8MCWDmzE0Gh6a+lwCKoCYQhl/DQYb1iK8EN3KoC81HFxAZH1nr7Aq0YEmJuDh5/cz6FHH2VpqY9Lb91nPP6pdjJsJ4Rnh6hGAdO1gOW1hOIuz+9j/bzTbnzP8y9w4cIuLk5Pk5sh1UaNqBZx+sRRuoNVzl08xfz+GTZ6Gd3+GoWpMzM7zVQ2hegqnV6fjW6P7qDDqTOnOXH6JBudNbqrq/TW1q+ZufReQ+ty2aFlMzDZxytogkChAynJjqADCJQjUIoQhTif/SL4FZFC/IqK7V5vt7mKEKdx2mApQPVRTiFOo1QNceXqDYUTwYpDl6RGcKCFQkp3mPb3lNuoDnGzMWV28+Rx0NHWd+16SLsegisYjgyDoWFkvUsr1lCvC4jPFmrVAiqFolUIo1HKMPN++dsyWO3Ba80YT3zAz/LjGMRx4MDY3j6O7TFAAqOuXxwHLd8XNJgEuqFXdINFyDOw48yr7e6ytPzXcsfida6FMDAE2qGVn9CzNEOJIq2N/ELcOQocxuZYU6BwdIZDFtdWvVvUvj3wmBCmp6aYak/h8pw8zzCmoD0zhbGGNM+5eGaBU6dOYa2l3ZqmUq2jg5AstSSjjHyUI4UDa3BYrFO4MMQWkA0KqpFBR3d2nM8Bh6KYn/rZn2bX3B6mp9o8+ewRpqen/PiFzcXIGM45tNabmZFFUZDnOUVRlNmXMXNzc3z8ox9hbv4A73vqSd6Ya3Pi5AlOnTmzlUV5Gy9qEU1jlZCLEDgovIEYrUEHGtFCP88JTE5QGBpVPx1rrciDHFPY8t3zwdOIeJ+MNSXh0aV52OuFWsOxqwnPPxTRX09ZW83pFYI1YBE6uSJ1ygesBaV844Huynvpm5NX4w1GYQBBHQghLxMHpKIJI82oyEhyyIw3KAXKW4PrARTOEx4xoAsvnjjv9o4j2FWLmIoUdSyS9XDF202qO0iM3EyOGydV3ggTwrMDCFCLAtq1CgUp9i47ccZe5p0amr7n+efZMzPD7NQM/XREVAMV5ly6cJxuf5UzFxzPvv9xTG5IRxmFaZAXQ4xNUGGN5bV1lpZXOX/5EqfOvMWps2fodjbor60yWFl7t8S8KSilvStc++yq8aG1KuNUxmRHCEo9EyBlcDI3IB5liukYNvJKKjBYUoQAJ5Ef5ThEDDhVxusAeOuR4P3pfmLzmWH+vjeOG3gnbF4pW7E113s7r/bkj88XYFe7wsP7mjibsrqWsiIpa7mjIo564Ni1S6M0iBIqcQWsxhphZaVgpW9JbnclsAevuQK8tivK/1dKQWt4606DrSCiBE9W2pBZyEbld7lvy6XQD7zyzZbLEImrVwzjx1vwrpIdKGNjlJ/Y8qwAl2KNoVqr4BCMdRQiFLbAOkMcBWwMByysr+Fwm1bIMAwx1mKdQTdD9h7cxyOHDpN2uwyHfdI05fDjh8lMTm8wYGOly8LiIssrq7zv2Q8wPbubWq1JMiqwmcVlFqV8oL2zDucUNjLYXEgGObU4x0V31rS9B3h/FPGTf/XHmNm9h0ocQ6R91qNzflyWFh5gM9txDBHBGEOapiRJQhiGNBoNms0GH/rACzzx2KMsr6zxtXrE7zjLhXPnSG7RqnMF4iksxrsdAaTUO4ATRS6aJE39ZKwMDkUQKKxSpFJgxmUPCDyp0QI2R6xBrEHpECflNO5ymrWcvbMFzxysclYcva5hlChSK2RWWDeakVOecVi7RehsuQJRZTD0TQQta7wBKohAVX0SWrrJPnw85MhkDHPIC8+ndOBDmeoRFD6xkGK8sMi8yBUNzQhmqhFNBVGRIlkfsekVVppxSB1cn/CMg6o1E8JzRyB4HdsKNc1aSCbXjkR/L3Gz4QUvPPcwlchgsiHnLl1GJMW6Ab3eZbobCUtLGq1z2o0WzVqTIDpAkm+wtHaB3iDj9NkLnD57juNvnmG906PT7ZN1+lhz9y07Y4RhSXgC2ZaKXgYsa0UUKKIgKFdhEGhV5mHJziwsUq6+cOCqQIxCUZGQwiiyVLi0uEGzoWg1NVqXju2tBlBK45ygnCNQDqN8ZOqturTGIScHKjAXwYkebDjv/Xmn87dnWQjQxZ8/C3zP00/wiU+8gLEpSZaSpAnrnR6rKytsrK1Rb9WY27eH3XO7UarCoJfSWe/zynfeILuwztrwne68Q4zw5CbEu7L65b9qW6d34UnOKnAKT3oC4Fn8wBiWQtXKQ2A0gqQPbr0UOuCupVmmowGdjQ2CICBJUqpxRDWOMaOcIA7RUUAQxzgNRjnWhindPCNRFhcL060pb8H45F/krUvneevieZ57/gWeP/IMTz38KK/+6R+zurpMf9Dloccew+AoipyPfegjfOUrf8rXv/4SJ0+d4GAOe+aq9Dp9AhSR0mAos7oMgXGgKogq6HdHYIVkmAFP3bHf4jLwHWs4c/YcEoXsmdtNkWSbcW1RFCBSLke2lYjYJO0i5HnOYDCg1+sRxzFKKaIo8gHQrRZTrRZzP/2zRL0e6vgxfvfSJfLbdcFXm95k4QofqFwmIfQLx2BgUYlgpQ4osHB+LUEph1IGY6qIC4hEgXIYcd4KHIa0CsdU4ZjNM0yaU6Qp4XDA3oUV5t9cZf10xFplF+vhLhIdMiBgQEjPhFilIVQgRZlxMCY4ZVCLvdJqdEMR8YRHhd5Vra0nFXkKM+0cCQxWQb+AzhDa2hMj0VCt+IWFcTC0Xm0q54lOqw7tOtSVRaV9ss4SygyoSU47gE6xFSx9PYzPGYf67XQmmhCeG6C04uECRRAH90RG0s1iYek8p88e5+jx73Du4ls4yXEqJRkMsKYgT4Tjb5yiVW8w3WoysytmNKoSxSFLaz3OX7zMpaUFllYWGQ1SsmGOLe6tQCallC+TU2ZcbdbZEUWgNKF495UW8ZbfMhtrTHauJh1ytd+fAFdmV0iQkSQFvUHGm691SEeQZ45Od50nn5rlqSO7qNV95oVs2k8oFblsZmD41eutu7Qcfu4PY9jV8lbs9RQ6GXTYit8br5ZiYL7mS3NYB2eGW+Q5BXqjPstri6SmIDMFWV4wSkY45ag2YlRYMEjXYT2lVZ8jzw3W5D4l607EcY1T0GM8yRlbcMq5Y/MYp4yPV5wGn04uV32Xlm0ZcGNBy8zdu2ek1RSFI01yOvRJw5AkTLCZIapGhLWIZruBizSFFi6sLDEsUhozbZ56/zNU4ohms4FUIuJWg3Y+y/zB/dSbDfI8o9fr0KhXmdszQ6PZpnC+HMLe3XvY2OiTZYZqrYbSGofgRCgKgyljYcCPpSiOiSsVKnGFMIhwzscC3UmEQF2EWjUmCDXWWQaDPj4RQOOsoJRF6SutOkrrzdEaBgH1eg2lfE0rYwyDwYB6vY4owVnL2vnzLC0usdjrYe9AkkCgrTeiEJTFIC1KvN3fqYBCNE40riRrKEGLQWPRxD6JQRyR61PPUhp5wp60w+zGOjOdNebSy9hihC0Sotwxo7pMqR7Di5rFvUeI9h6hXp0hdzGJiYl0k0J5qwoA1iLOeK+v8pE4eVb6lHaYHSriOVNRJgwEkSYMAoo8ZTR09LoWV/h7JkDTUdYu8wtKgtKik22FSqkIcgv9BGZdTpYNYeDIkh7aZdQjHwQ9rjkK1/ZijI2044Bq8GogKM+/noQTwrMDJIANNGElQO04POrewVvnTnD85Ku8/Nqfc/HyyTIdcws5cPqtCzRrFWanmjzy6F5GowpBqDm/sMbl5Qht1X4AACAASURBVGVW1lbpdDuYxL5rGSy3g3HQ8Zjw+KMkPKIIpayvs43wKCfbQlncJukRJVcSHgdjwiMY0ClJkrG8kPLl/7TCcGAwuQW9Qr0W8chje6iWaeybrqOrFa0IIuOQ5Vtn0QngynoWh3KYcdDN4bzz3xV4BVITaAgcrkEhMLDw2giy0g2WAksbG5w6d4ZhAYV1FNbhjCHUllAJRT5isNZjacOydxZMqkgHljTJKO4EAR7gLTxjjjgmLeNY2fHPZLjyHbT4mmVVvBZM8dYiAVrlueO/x4UE7xo01kCeGYpiRBHk5DrEpAVRPSJOI3QEYkNyLVxeWSIMhNbMNO12Da2EUCsyZ9CViPbsNHNzc0RRyGDQp9dZ5+CBeQ4dPEhmFLnxbpd98/t55tkRSmtWVjOCOMKKdxEVriQ81hKEAbEOPNmpVKlUqgShrxxsdprGtEPEQEuERr1KGAYU1tDrdREJ0DoGGxKEiiCUK3SWjitoKSfGMERpn6jQ7fYoioJBv0+lUvFu3iLnwrHjnDt3nnOd7u3WjfT9VhaDYPAFZhQGTYENAiwahwalEVE4Uf5vcgRDVIQYVWAlp52ssTfpsH/Q4anOArsWLjK7cIG50WsIfRwpMRXqpMRkHEexkBtajTZRO8BRITc5VsckgDjBiUWcRTvjDT7eLwh27H7bma4Zp3rbzP9b0QFBGJGalNEAuoGDwltxMrYsLEpKwhP5sAGVelJkS5aSZJDmYEvCY1xBOhgg1lENNrP7N4nJuHrQdu05JjtjwjNOKtl+zTthQnh2iDCMqFcb7BJYx+vm9wJjr+vtDNTP/d5/4OzpM1y8fPa6AcZKBSgVsrCwTBRpEMfCSpeljQ1WOx3syN59f947QkAUqkw/l3J/CK08yYmUIlIKwaEsmyudMQ/ZJDvvpBDc+EkIojKSUZ+VpR5/9ifnsCiaUxE//KOH2f/INGEdn8V1PditgOPbxasrcHIVPuxgtgqHpyEc+PRx67yZuRL7zIpza3DZwQJcEXyfAS8dX+Llkyvea7clOLAVuD3+XKlv+/McWGPvyMqZanmjBE9Q1vCDLQVm2Fr2FeU522NwLuNje6p4dxdsBTgN8Naju2rZGUMIgohqtU4YxlSikCgIcWIwGIZpQv/iOYoATKCYmm5Tr1aIA83RV7/FE48/xhOPP8aJM2eJ4wr1douD8weooZAk5dGHDtFsNgg0RFGNwgpFAS9/+w2mZ2f5gY9/ihdfOsogyemO1skLg0IIooDpqSmCMETrgGqlSqUaEFUcRTb0GY763ZkuFDDs9+h013nj+HGq1Smard3M7W5QLysuj0Y9H5xsLCEBgRICAURToMkJyF2fZDAgTxMkCKjWYsQWvPa1L3Py7Ckuc2ce/8GmY5BDv7AYHW9u12FVgFMap/S2qDyDsT68JlSGZthj1/oyu5cXeO4bX+Lh9CKHzSJ73UWqtqBqLVUM1tuTCck37b9TWA7NaD70RBX10cc4uVLwxqURp1e7pK5CITEUlkAMkRjiwNcCM9Yxaily6y0sO0GKj6G2pozvNzl2ZHE5dLuQDv3wquCH3MiC5BAmEDkf8KxCcDGkzg/njQ6YtCwmDZg0ZThIWV+AUQcYQMNtZYeNMc4pgK01TMhWsPJYY2u8WrheceYJ4dkhQh1QDSuEt5VTc/O4EwP01Mk36Wx0bphNlRcZ/WGfjf4alThCa8XCyhKd/ojRIMHdyF54F+H3CdryemgRNL6ujmiFUz5rSov4chWazQie8QzvyuylTRI0djuVbihnHRaHMyG1Wp35AwE//tNP4ICoqnn2uTZ79sXosADRV1CFK2jU+D6bf9zeutM4X/TrTWCYw5yCmYNlAgiQjmAwhPUBXLI+y/tavNWYm1nFvwsuzZSt7Ksy0HHTb9djK5ZnwJYGHGPse766a0n5+btQRPBWUBSudL1Ydu+eot2eotlqkhYjCpeQu4SMAYnJSI0hVNq/xwJzu/dQCSOG/QGDfh90GZhvHasLCyyfPcd3vvENKpWYRrNBELXZtWee2d37cC5iMCgo3IA9e/dyaWmR9cESWVYw3Zxl19Ru9u+b91YJAOeIgog4DAl1RL1Rpda4s2npOdB3jn5/QL/I6CUDFhcXmJ5RRJUpBmlKRkaQOqwtyPOCojBo10fZAmULkrwgyQxpXiBFAkUG1rCxsYGxNTSW5cuX6fd6d+zx17XPfBInuKBAaYdSQuoEI+KDksWisYiDXAdUjKGeDnnkjVc4vHGOw51zPD54hXnTZc71aTDcLPJXwb+2efn32OAZAVOBoKoBtflp6tOKudmc8OgF1gYjuklKJa6VrjODDgqssxQWMjSFVRRuZ7PX2Koy9hrnhWPkDGL8QikpfPr5OAlshLcgN7WPE5QyQazcVhCx0E19se6G8q6yLIP+EDrrvnaPs1fWsd20GrEVeje27IzJjuZK4jN2d70TJoRnhwhEU1ERkbr+D/pu4HYH6oWz53d0XpZn9Ec5a91408y8vLZKkhiK7XbLexDiHKrM7FD4rIGAMhNKySbhcWWqpskNpiQ8zhUluVGI+KJsPiOETSIk44gY53A2ot6IOFBt8JN/ba8nQVgqFUsQFmjt1YQ4tc2CtK2vZcPjvtyJwDALnMErEgXsP+AL7gUKNpagewFWRt6ysxOqsr1H7xlPSNnSXOOCg2MiM97XKsKTn2tt63Q1qRnX1inb0Wqr6v7dwrjAYFEYWq0We/buZXb3HvpZl1HWI8l7DK2PtHZJ6it+G58TdGDvPCKOzto6g16PKI6phhWUcawtLHHi1dd45dvfIQgU1VqVsDrNk0eeI4qbhNUZBv2cTi9l/6MHWBtsUCyOGGVDZsNZWtNtDhw+BAimMIwSPwEHSqjXYtpTTZrtxh39LVKgZx0ba+tkobA67LKytkpYadMuCrqjIW6UY0kJdORT8o1DjTJcnmCzEWsbPXrDhGGaMlOvUI00lSggt75CfKRgdXGJYf/O2eRj5XC61DVh4fff00K/gFw5CnHYoCCwDm0hVCHNLGW6t8aRV7/OU72TPJadZR8rTOFocmV5CY1/lcti4cBWUmEMTIswNdtiV1Djob2OjdUlzi72WcgzGjoqM7UMTqcY5zDKYQgxTmF2SHi0Lq3D5WGdIy8cypX7kwJtvPoaD1URqCtolvHcxvlMrZHxVc67GcwIVALIEuj3Yb0Dve6Wa307IRlrxrFKiCiDqbd9Hmw7xgQo5J0xITw7RJoMGPSWmZtyDLuw8S6nr95RRNywAiV4F0gxcpx4c4VWK6TR8H51B7ynZq1bgDiDshAUEBQFodZEWJS1vh5pWcW9s7bK2uJlXvzG1xmNUrLckJsOu+d2s2/+AB/5vk9SrdYJgoBeb4N0NCJLUjSOaq1BpVZHxxEEDhU4KhVVkizta/e4YHNGddtyxF1pyBnH3KIUmLyseVKwFahym78D5Sox9GTHOeiNYDGHs+yMs45DYTa34cFzjnd968iMLe01Dlwedzgtvx/vr3Mt0nL1O+7w5KgkO8/sg6UeLHTfpf7vAL3eAK0DwjAiywqyrCDNcmyR41yKc0NGvQ0ERS2MIdAsrS7T6a7zlz/1aS6eP8+ZM6foD/scOjjNw/sPsGtqGnv4ECrPmJ2tUqtUqDcaVGozZIUjzTO6G8uE1QZxtcHSwirTzSbf8/4j/MGXfp9jR1c4cfwYR448yez0LPVqHZulftZyFh0ookpEXLneVHLz6ABni5xvf/nL1B6ahz3ThNVpgkoDFwjHzxxlZXmF9bU1akGdZr1OvVYjLwZkowHD/gZ//mdf5623zrC4tMRf/OT38+ijj3Lw0EGqtTbdTgMxhvMnTtLr3mYG4TYYDGEAUQhhmKPKzYdbYYYOQYcKF/oFkwb2FRmz3/k6u//oK3w4/wP2u5Q9WCq4K1wy+bZjAXgLPxQu4j22e4CDiz32v75AXhhqdUW7HvPpj32Q19+8wLE3L3DstXOkLiJXFUah+PFTCLnJfaq77Gy5Pn8YTO6LUeeDcseKELKBJy6DHNLMW3aG+HXFYOgtNdPOF3kes7j1PpwdQN/BbOTT1i+cgV7m28rdlWRvfDTw65yx5abOVv7C+LPtVp+d1O2ZEJ4dotcbsnjZoq271+f+t6HWiMiHhnyH7gqTO4ZDv+lgkXg/7ju+RSI0pubKAmAZJilnmPcYzvrIOGdlKy3TWj9nFjnDfMhXv/hV3nrzJOffOsWF8+fIC1PuIJ1Qb9RpT01z8vg5Znbtolav860XXyRNUkzhd6ie2zPH/v0H+MFPfILGVJtq3e9wuZln5a6scuOc2xa0vL23pYVnvO/WHTQ5dIAzBrJTvligdtDrwNLA84VxxlaILypcw5vQK1yZCHW1WXlsaMnxyu08W56iO4qxW8pdo/F3IjrXQ3m+UnB4BrLiFglPwFZhwttAViQkacRwGHP58mUyY+inIyRM0FGKChLSZECt2qReryI6QqsppqeqzEy1KIbTFP1d9LsBext12lqzfO4Mx199lddffpnOyjJBEFCpxMzNH+TRx5/kiccf4cTxC6RZQi8rqOkGLs9wRZ+Lp07T6eWIqvHWm8dQjzxBdd8Bv+O4c76WlNZY6zPL7iQMkBQF57/1bQ7XK8w98hD9vCArLItLS5w4cZRTJ05y7tRbxEGbRx95hEcefoi86JGlIwb9LsfeeIPlpWX6vR7Hjr1Klg5Ih332zj9MvZ2gUFwuDL07OMYMxrvQcX7PQadxShGLoS5Q0z6+yGUD1KDHgZdep/Hmd6hnR1kkYYjlIluLn3GG0TiT8hBbZacMnuy8CDwMxIMhe1fWcLbMChOhWatwaH4GrSzDzoCLGwWLg4Kuq+GcD57OnMUyDqC+MabnZrC5xWSWtJ+hI4UOYbg8ZNjzZGhskK2y5XW+bKHR95u9pwKLwEoGAzd2jZUeaQtD413xBVv1RgPt62mNysBlUVD1Md9E5W8k246xOwu2vOH3VJbWzVaGvVfQ7yYsFAkR97yx421o1GsMbYYtcnBgrbl+PI+FLHU+wyOVbQ/r7U9NKc2e+cMMhiO6nQ6jtH9XfAbjyqvO+lTU8WGLgmQ0ZK2zym/95m/yysvf5uSJE9dsQ2vNsVePsXd+ntZ0m9/63G+TZ1tK/uFDhzny5FPsP7Cfhx97jGq1uskMbiTx2E22/WxfEt/eUcLTBboWzp72CiRmy0QOW2bhOnAYHws8hTdPj2MIxsWLDVu1/wK8EhuV9xg4T67Ge2/eMYwLAF6L8NwiREEQwP42LN2qdSco+3ObhCc3KWmWMBqNWFi4TGpyhvmISsvSbClqDYcpMkINrWpMYQzVqTo6nqYSQrMSsavZolpktJQiTEdcOHmc1156kT/7s6+T9FKc8+/yk0+v8cgjj/LE44+wdHGZxZU+/W6PoBpikxHZqMuF0+fo9BNEVzhx9GXqlQrTU1M4q1BYlHJEcUyRG0+C7iAskBnD5VdfZ//7nqHdnCZPU4ajIYPVFd584xgvv/gix15+lSjaRZGktGo1Cjsgz1MGwz6XFpYYDYdYZzl79i3EFpDnBGGd3DpUGLHgHP072G8lPltT8KTQOb9tTBQU1JxjykFsHaa3gls8T/2rv0OQnSNnkRNs6YqxK6jALzha+EVIs/ysWp7TY8va89BohFlf37qvc8RhyL7dbVqNgLXVDZJzHRbzAUMbYFUEEpIWBisKu8PZa2r3bkxeYLOcUW1IECt0KKh0xHrqMOUCSuF1yQZs/sZzI/9sh8BJtvSJwldl7hpPesYLqLJGKDU84Rnh9+QK8ZWZo8BbmsZZWWOyA1skB94e7HwtvKeERwHzkd+Xp3NvlXG5IYYjX+Pk4VlfPvt+QrN6hNnZmKgWYoaGxcunWV48c91rarUmtWaTldUeLsc7ZEm42mhYiSP+2//mb3L02HG+8c0/59i3Lux4E747ifF+OuPy+37Hbsfx14/yG7/xa3zuc/+h3GH5nWdRYwyvHTvO68dPgJIryA7A2QvnuXj5Msdff52//Xf/Dj/3t/8WM7OzPqDZbWV4vROBUeX+R8AVk8e7tYFoWh4CHAAO4pXquIbfeHPwOlAty+M78QVat0NLuTloDaYDOKDhwCqccz5u6DXehRDmO+gybsewpw61AmrWy7ujiI7tq7PtZV9va97vIRJ5IhGFNBoR0zMx1WlQOsNR8NAjBwmNww5W+PJvf55de+fYM7+XP/z3v8KlxT6LKwnOWfY2Q+aaPoD+zHKPi6spuHI/Ve0o0hwlQqNW54MffB/feeU11tYv0lvLCAONyXJ6iSMrQJmU3/v1X2H58nnWul0OPfkcFeWI8bVtrLV3PC0d/LtZ05pIx4iq0Ostc/HiRS5dPM+Z42/QWVlFKcWB+Xl2zc5SbzSpzewjtwVplvGZSpuNjQ69XgdJF4jEMRqNGA2GTO8Lqc/OlLF7dw7PzaabFaCtiijykDzX2GSA7QxYSUc4a7j4yp9y8ZU/YSU7gSW/pvVh+9/jElQ/jHdf7QH+C+AvA0fKc6fdiMRt+KrMYxuHywhVQaum+IEPP83eQz32nevwuy+do2MUIwlQUYi7iZpfzdl5TLlth26lBFGA0kKxukK0YXxmnb/7ZvG/Gn4BFbMVcF1utYXgt7/L8RardNt3Y+txDxhmVxZBj3KIc9/uuEB6+A6/404iId91wqMEDu6p0KzXaTbqPDG/lwRNJ7F87evfYpQVfi69xxEov+Or36l2a8F3P2CYFBSAcZapSosoGNfqH7+K2xPfBR3uYu/cExw6/BjDJCMd+cO6jI3OCp3OMslgESTASJM3zq5w5twCy5cW/YaUdwHGmLI0PqXVxGJtwerKMmtra/R6O1vamzJA9Fqw1pLZjMWVZY6+/jpf/5M/5dM/9EMEoR9G1yMusu37MTkbE7Q7vXK+GmNjyTjpaXvAny+HD86XDkGV7/Y4ecy4snSHKouKqXJvLTxxaOMV3Yh7dzzUI9hV90GYjRj2teB0bwe1EreboscBTGOte8vwNWPa7Sa7d88w3arTjBSSDrlw6QIXFi5SiwKwjjzLOXe5gw6rTDVq1APNXKtKI4jYMz/PI4f389DBeeJqnbVewlo/oV6pEeqAUAdMtxo8/cz7UTqiN9jg7LnTHH3t27z/uRcIqYGxzASKdQWJdSx3hxw7dpTMCY3d+2lEITGWYb+HKuvK3EkIPtlgOOzR7XXY6HQYJgPSbEiRJ9RrdR56+DEOHHyMJ594gbm5vVTrbQajjCRNybKMmV37aLZnydME0llMOsDlKUEcUqlUaNXqtEQYcP105ZtB8vLvoMIIHVVptPeAruJURGEyn+QQCD1XIbWW1aRgcBMpghnwBt4VtAf4K/g9x2rld5IX6GFaWnicLwdhS32HJdKwuxnw+FyNFw60udDJudxLuLCwikV2HMPjSp2ktKZSq/nNSsWVZQscgt2sEzomctUqzNahoX08qCrYirkr/8nZ0hXbic2Y/FxLh2yvsTPe61euOsZv5l1xaQleOYoIoRYO7a4wt3uKuT17eOG550DH9IYFrx99nZXOkGF275t7Yg2NyAeqBfpKN8G9jv5oSJBDnGh275sikHFYmEFEIyrAmqJ8ewLi6n7m9r6fp574HkRDvzek1x+QFYbzF0+RuTfJshFWYgrV5FtH3+Lym2dYvHCJu5XK5VeglKTHYq1/p3rdLqYoiMKQLL8zMQiDNOGNEyf4oz/6Yz7+8U+gtS4rmr4z3Hh/m21kZ/vxbmO8TVROaSqmVBwCTvnK80qXpMb5uC1VTviuPMcLAtitjIpqeYw9UfciKgG0Kr4AWj2CvS0409vBm7r9sYwDqsd7fN3iI1MqoFqt0m63aLdb1CshEQVFv8+lN8/w0ndeoxWFZM6SWotSmjT3z2Lv7j3smTLghCff/xxPvf/9PHbkGSSskKY+bXtXe4Y4rBDokNEwQQch1gnrnTXOnDnF0dde4ZknH8EpBUazK9ZkmWKUWTqZ4eTpU6ytrfCBH/g0ttmiqgPybEgUxkRR5cYC7hDjSUoBvZGvwbOxtkaSjSgKXyp7emqa+f1TtKZ28/TTL5DnltEoZeXSMoNBnzxPeeTxR4mjiFArxMww6q4z6ncIKxUqlQrNSoWWUtzJHf96L30BXa0T1FpU9z1EWG8QVKqEKkDrGlo3yNwMhSvo38TGyuPJe4mtLV9yvHVjjtLVkxuGowzBl8gYEx6Lw5TVAtsVCGZDXjjY4v9n782eLMuu877f3me888255qru6rkbQAMgGiAJUjRJ0KJJUbLkcDg4SHZYYVnhsMN+8YP9B5jhd714VIRebMo0g5YokwRIECQBAg2g0dVjVXfXlEPlnHc+4x78sO/Jm1VdVV1DdqPh0Iq4kVlZdzjn3H3W/tZa3/pWTfTRowHXNq6grVOpfhDTSmGrSfVhiB/4CGHxgxBPaiSGwZHnW6BWh+68oFEXqMJCCmJoD++Vkns3P9yrp6YCO1V7fjW7TDILzqp1BNMuzPuc17ECnmrOX03CuTMNonpEEAaMB3usJxMOtreZq9dpz3UJG3X+/b/z83znh1f4/qUPjvMwPhZrN+HUArSaNYJSUQx+rHKtD2WjvctTECox4wmTtE/FDu0snqQ9f5r1jRIjY7yoxYuf/xLd9jzDkSbRW+RFSVZo+omlrLXpnn+R6IkvMOpNmOz3+NE3/iVGpXws2iwPaFprR7CULktTlhrfEzx98Smyr3yFrlT8wde/Tl6Wx5Le/tGl17m5uspv/dZvcuHCBebm55zDuYdZQBuDmkZl1aRnrfXHUiq40yJcOauGixYbuLFUnnUaGSafAiI7i76qiEtq8LSbNF5VeTat0wQ84PbB459G643guoJ26Nphg0cN9QNmU9wr8sVD2qmTp1laWqTRivjRpe9T8zWN0BLYknKU8OzKGb72tb/Ffm+P3f1dTpx9kmdefJ4nn3uaIklJxgmTccpBqXhtNed7q5d4f32HuNGm0eoSxy3KSYrOMj578TRnludZ6jbIS4EqBSrT9DavYxcyolqHxZNLJGKfyd7QddzkJepgwHf+6Pd55Stf5XOf/xLG1ImnAOK47GhUfglo7+9x7voHBIunaDY6MGfxF1doL6zQnl/BRDGvv/sGP3j1B1x9/euO5xRG/Nrf/085e+YsJ1eWmZs/h5lfRqscpRRBFJGrlLLRQGeZE345BltbW0f4YHzBn1z6kRtGjuACMC8EHSGJbAutEmbF04/KPbiupEXg7zKbFVXl3itis28Fvpm2FQgPKwOM1K5ZA4mmRNkMbVIuLgny7T0G/bfZ++7/cjjQFH73I8+xNxjg+z5h6OYRSikIwoBWZ45GzVKTJaVxZ5dMX5OUgoPMY+HMScqyIJuksOqaWCyw95FX4MNWtZlXI/MiAYsdqMWSMKwGPxsEBqunncb3cafHBngE0PQENQGxtPSHJX5qkF5BP3UHFIdwbn2duWxMo9tGGYOdbpKe18QYhbVVcsu955zvyhTVxf1xmQUQkuWTJ1mY9GlvHTDkkQO9T9asay23FhrNeUptmKQuyRuFdZrNOVBvgxVYHbF5PaMfxESeT2lHrltLW9LSoo1GGYMSAWVaQJKgix8v2IGpKqiwaGGw2jr1X2Hpzi3wzPMvEfiSP/rmNymOCfBorUmzlLXVVebmuswtzM2GxkyTPWI6usIyzTpZO9USMRhtHbHaGtfO/jFayIyzc1SkqyIMWjuLvI42SRlme7rEKahWERXMSJcZn97sDrj5PLspvLMNp2qwNAfygLvfvHUOL0zkTac+H827Vz8f8StbmJ+j2apTq0c8+9zTLC00WVxokE0S0qQkTUp6hWb9oM/GxiY744KN/T1ef+cdVFFSFiVFUTJRCm0FysDecEwQLBDWlvEWzqKHu5jRNmtveawsn2BpcZm5RkmjWefzLz+Hh2Jve4NMbXL+qSdotmOWWoL1m0P6xjLRmsvvXWZuYZnFxRVe/MxnaTQaRFH0aCd9F7PcXlaVuUKMMsKTdeKaxSpBXI+otefwaw2UtSRFzmAyJs8SjFZYaynynDRLGU0mGHLC0A0PjaM6URThS4MoCsQxBhVf+trXqLdC/Ejwx9/8Lvkkw9OWL37ps8i9PfStLUa7/ancRKUmc2+vI4FTuKXXwpWJq0fEjONigMIo8jJ1CtnGzrKw1mWRtbWHWZB8MmC4c5O91bfRRYJVD+77XADphrMWZYkMPKQHSCeuWFgHdI6G/WkJB6lgoGqME8X+oLxNgf3oZ1eV4Y86Hh+IBSzOhTQbdZrNBgvdmCgOiEIfazTVIFetLKXS9x1zc6wZnponqElLIGCrXxyeTNWo7MuStbVbJHlCJ5tQBHUK5bjeUTRHWSaU5Zhq8/SE4HS7htKQlhZrXBuxMYbyE57UrQwoK1k5dYaVfcFCMGBU6p8IwOOmdBsEkka9S5IWuKRpjuf5REGEKDdBl5gc1t+/o4tJeE7ExtxZeX04c8J+05SqdcJ7d871elSzxh6CHqMsRhqstLTaXeKnnqMzP0e72SIvS3I1254/Ou66txljWF9f4/wT50FwpPPNUQOdaJdwwH7qjJTWaG0dKFMaY0r0nSzhY7aqu6EqZFbnnDMDNSkzwFMlvY8CHoFLblTgqXoffeR9Pq2WGTfDZ7gDc+fh2UXwr91+boipsnYD7NST1z13PTI9XfXHULdrNGLC0MfzBU899TRnzi+zcnKe/d0+WaoZj3O+9Vff4OqtbVZXN3AqLHc3dz9Nh9+KZYR/Es4axHANBte5YjZpdU8wt3iGVz53gVbg8fxzT9C/dYPdnQMOhikvf/Hvs9zxOBEnsD7CGsvEGK6t3mBhcYXFhWV+6kuv0Gw0ieLjAzwwAzwR4JcamZaEQQMTewgjqbdb+PU6IgwpkoRCleRHN20LeZ4xmYwJQp9xImh3mk4ksdYkCHw8k+Dl+bECnp/62i/R6kT4keGDq9coBwk1AhapfwAAIABJREFUAr7ytZ9n+PY77BQJ6d6I0JppQtB+iHNy9OFz+wz6EFjCNRqEzMa/GSDXJVmZUhpNMJUOwM54gdraKU9PkI769LZX2V67fFjifxgzxqC0doCndIDHIFBWkE0Bz1HfmZbQSwSDImZ/PGarl9+TJ1f5mPsdlS8gkoKmJzl5osHC8hJzS0u0222iKCIMApQqsUZhjUJpRVmUlPehLhwb4LHAVnFkWOId/wcONHznvREn9yacXNymeeIMk0mC73v81Cs/xdrNDa5fvwYUNHyPpVaL/+q/+2+QviDNEtZXb7B5/Qbr11f51nu3UJ8gQXaQwGbP48Izn8OvLdFuNfmfvvUW+adsavjd7MyZlxgMthgMdnj3ve+B7SBZwtBjc/0y2xvvofW9FokP8y9D9wW4/haYDRyl7uGt07lIt/s0pvQwqo8u99nqXf7IkRcPYmVZYo1EWA9dGjzpQE+S5ERxzNzSGf7xP/7P+cY3v8Fff/c7gCvr1Hm0VCs4h3BzbYPnDnpT2Xsz7d44bDzHWiitQWEo0WSqxNeSQEO/12dt9Tobt9Z48alnHvsa3MsyXHZ0iNtcKv2KqgW90tDIuHt9PeZ2vZ4Qt+8fFSf8STAVQWMeTp+E56TrFM2BbgRB6GaNtTwYC9diu6CdUmwOvMdsSsXj2Kvf/xa1epd2ewET1fiz732b6zc+IN/fdfeBtZSleoANqkZ3/gRzCycwCBqtNvV2B6/VoNn6PLX4FdauX2Hz+mVuXvkeG1e/X6lDgTGcW5rnqdNnWDl1no1yzECGpAG0DdQ0XAVeu/QDrrx/mSTJOXvmLMvLy/yT//IfPeYVcFatI7/6KUF6gjAIKfISpQV5GVAmGvIR+wc7mDKl24rYm3ZdKV1y6dK3WVpZZHF5nlZrnqXFZYp8hWazznBrgN7fJtb6vuq7D2u3tm/y7X/zI1594w2+/LMr/MZv/4d87au/wZXX3iF6Y5vooMV5Cy/ixrqVuHJyZ3reTVwmZ/nINYiAvwFexXUxncJxd8ZAQUhOgMcEZTXSKnzPFbusKhBKgXCkZYMBaxBKoScZKtXoUj60g2s0GjN+4VTeo8gtRakYGHNXn5kpH2Ujdsd19gceBz1zT4WSj7qPfAFfXIaFuSbzC/N85pVXaC8sUm+3Uao8HBBdFgqsI78b5WgCSt07KjnWDM/RpoZ7WT5NEUspmet2qdUyjBmyevMKg36l7GEpjSE1mqBZww8lxJITahnKDKFLvqh8Vvd6bPY/GdnURMN+AUUJi8sneVHWOPXqu+wmmvGnHPMMhzvk+QSwaJMCIZKANkvkZkx+z2KhAFY4c+F5zrz8VUZPXsAUA4weYHXK3u4OB7tbMLwyZbWGEFYqEgUUt6ubZtkBg8FVrBZYk2F0cmyEXaUUAg8hQBuNNhrPeK60ZQye7/Hyy1/k5vWrXHnjdZIkoRH4xIGPSLJHBjzb29sMhmNKZVHKATchxWHWAKwDPNagrRMpHOzvs7exxb/8w/+L3d0dhsM+/9k//S+O5Trc9Thxd1UfB1yOSrBXCfejCqeVHY1CFVBI16VoJfj5TMDwQdpBPxU2JR17EZzxYXnqF+fqEMUQRa5s10/dtYoN1BsQ1iFWcCOB9cds9VFakaYjjDW8+8679AYHjPojhBZY4zmpfjWbjBqG4T14Xoos7dM/0FgEyWSXsBchwpgoColrMeeeeJbTSwvolz/P2toae5trHGxvUCrNKEnZHwzY2NphtzdhmFoONG4UAm5TLrQmT8Z87/vf5vJ7HRqNxrEBnqNrZhE4ubTI6eefoRcGWGspi4JyMkZTUOqEtfVrbG3dYDi4ddhBhLVMRnsEXoZVA+yyJg4C6nEdhWYyHpNu7zKw9lhVwn/46ne5ceMWg96E99894L3Guzw56DJ+9S3E++/TGe2yZC3nmG3s9ekjZDZwsxopUT3quPt0FXiSWXanQJNjnfj4dB5g6Pv4QriOVMw0aLQIC7osybKMolQI4RMGdR50Snpl9UYDXXWQCoH0p4P5ZMRsTuCHTRvLzk7fzV58BKcqgJX5FicX2lxY8Oh0W3TmujTm5wgbDUQYIaR0w6GFwJMB1rg5h8KzSF/j3yeb94kLD1pcq1sURizMdanX+hijuXH9ndueVxjDWJUoqRHStc225tsU6Ty2yKlTQxnziQGe1EBPQZYrlpaW6cyf5HQzICtKxp/yvvrJeB8QhEHNLRbh4+GxaM/SU5vkOoUp9c7delW2RwKLnDrzJF/48ufYu/giOrfoQqPLHuLdt+nrS5jR1SngqUFwAkQKdgzFmKMQOMv2ybJ9Pg5zNWcHNpRWeNqbChEatNJ4nuS5517knQsXOb+ywv7eHlEc4EcBfqEotX5o8GWNZWdnh+FwRKkcUXo6lAshQQiLFRZlNMZOOTx5ydbGBm//8HX+t//9fyVJP/4ZJRUHYIzLUlR8nqNUlKOy7BUIqoilZvr6VIL0XXVTFI7w/BMFeKZ+hADORo6IHRroNl1LbRwDOeyHsOc5AvdyCxaWQCZObPFxAQ+AUjlqUvLelSsgpvzGoIY1HkaBVi44AQgCBwA+DHhK0qRHmvTu+hlhFPOZFz/P6fMv0F1Y5PVLr3Pt7R+gszGTieu43OkNuHZzncmwzzAx9DTUrAM7DZz8Rm41b7z92uOf9F2sKuecrNU4c+Y0Z194jknfbdxFWZKXA7JiyCTtcePmO2xvbzEYbuOqeBIhoMxHjIcpphwQR03qcZNms4sRliLLGPZHDKw9tpZ0gB9+/4cMczAFXH23xzv91zn9xh6dt67R1ENaTDjLLItVlZSrR0VIPirzVAnzpTjAM56+1rEjNSX6MKPqiaqk7GZmGfRtgEeViizL3KBVL6BWa041ex7c6o0GSmuUnop0CIEwFrzQOYC7mqMo7O8cMKMy3908yWGW5lDKREDgeZw9scCLT55kqR3SaDVotFpEjSYiDJ144rSdVEq3BirAYzAgJELeO+/8sQKeCrkerZXPASdbLc6dXKIVCML7fA/GGHZvrYLU5EVKOwoZ93bIRgesLC/R2qp/nId/m0lca+gkyallCj8OOX3hHLt2i82tuzudT4v93Of/A2qNNo3WHPML52g020S1OlvDAT/8/rfovfYtYAuCp8A/D+kfM5vcuM/atcvov1zkiWdfptVpU6vV8eQptPEwpebq2r/CmKm6wuQCM3bHJ2dubIaTey9Ll/IUUiI8Dzz3exSF/Mqv/l1++pWfZn9/i639bTa2b/Fnf/51Vje22dp7uOZVY12GZ++gx2CcHFEywunWCIMnLL7v41nQWcG/+r3f50++/qf8xV/+xScCdsBFk11gARdFChyAOWAGcdWRR5VfEEDcgKyEtIBUORqXBC4wG1VR53jKPR+7jSBNnPDp5z8D5QGUQ1g44cBOFDo16bgL4QLc6kOwBOESZBugjkmGJgoiQj9klB1MuWyQ3rYjz4D3ZPJorRpFnvH7/+KfIf1FwtpJfv7Xf5lf+OVf4/xv/kesXnmD1y69yaW33+UP//TbdOKAduzRiSJSUbJdKtrA2YWI7lzIX18doY6ZpGVwSt8vxnX+zn/93/LkV3+WhWeepX1lg/2DHlJYdrZW2T24xd7BJjs7mxijabVaNOOaK9sg6LRbGF1itCaZBi5CCGpxl/hMg07Qoe79c/xjzPHcOiJp4ANqa43JzgZntGYOSxdXoqqyOkcneoPzjOkd/76CgwgXgC8AX8IBzyqgqJ57YAv6xZDx5XeYf+IincUVSgzCulE6AQK0RSlN3KqzeKLD2QvzyEvioVzy0tJJCq0otOM8Wm3RpeZAbVLecy3c6UHubp6Ely9EnDh1irmlE2zv9wGJH0Q8/exTtJt1mrUIz2o86eFLH12CNSXCmyp+ex7C8xy/yWhKo0EZpJ3KadzD7gt4VqaHXzIjHj+MzTXrdBo1buwcHLK1fQClKNOEpL9Hmd0dCQpAGsPerZt4vkWbkqhZRyV9bDEip4YoisP0YMaxirN+yDSQW8P+QZ+g3qbmxdRacwTxANegO0PwxxlNHIctnvocca1Brd6k3ugSxjWk77N1sMooqdQengD/BEQNyCoSioBgnmFPYa6skxQN4nabqN4gEJq9a9c4WN2YpZiFhKUL05ClgHTf/TQlqIoWm+NYM5XG5vGYKkuEkQjrFGGVUkgp8f0ALTVKSEpPEMUtguWQerdL58QKi6dPMRj1Ubz20IDHWstoPCbLc5Sxh05QCoEwYI1G6YK9gx7rN1e5ce06/+ZP/pgr7135RMBONZtnDnePCFxbZ024n+iptgezAeQ5t9/rfunaPA87uqbvU6mrVn/7dOc4ZzZOYLcHzzXdZPkCl8EJIzd+YlhAPoG+chvQxDil13EJ+TFheKWVa9Q9Bu7a/awoMigGFAVc+dFfcbDa4r1Wjf7ekP1+RlhbobvUoOZbIlmST3LQI0yp3N7oefhhMC2HHN837AHPI3jl5Zf50itf5oVf/Fu0z5zB83ykBD8QBKEHNkfaEl9oGnHk1MwtmFCR5zmqLLEINxRTCoKwThDG7p7PFTIIiDptGkIcrtfjMHPH7+vW8ENtGNOkRklMwWkszwBP4bJlR18juH0mlJz++ywOIJ3B7b1VJqgCTSmwDrxe5NT+7z/gK3/73+XLv7BI6AswArQgy0qGwyG3NrfYvrHK3uZNRqPth+ZJLsx1KJQiVyWTIkMXmjLNKNMEXX5UaHPvtSKAyPP47Gde5MSpk3QXlrmQFiB9pB8wN9dBSpDWIoxBWoFEIHC8LTttAGGWFJqKzGp3P32EEM99Ac8izgEmOCf4sNZt1jm7NMfqXg8zLfsIoCxykuGIwNPkyYcjmGpBBNawtXaTMBJ40tLUHcrxAJ2OyIoYiowajhBm+XgBjwGUteztHRC25mjFLURQR3gzOly1weTc/ZoHnoe25hNXI24tPUcUhoRBBMKirE9RGNZubTEYHeAg2nMg29zO7hPgd5kMSiaTDbbH4LXb+K0mvskp1tco1zeAYNpyEeOdvIgULVA+Zn+AySfYYgLJPm4VDfC8jKqg4spOyrUWPoZppRBWIrCHYEdIga8UctrNUviS0AuJwpjGXIeOXWS5PMFo3OfG+hZceuuhPrMCPMPRmNF47NK+QiKlwGqFLlLKZMLa1av84Lvf49Xvvspfv/591Cc0e6MSBuwyS5t7AiIJjenkwgRHZt5lBnh6HFm/d/FtlZOuOrU+zR1ad9ooga0DCE9BoFy02V1ypGUkDIeudNcrHNG7riEoYZi5OUDHYRXH7OM2ISR+AL5fsP7+j1h7rxq50qXRXqA9t8DJU6fxybHlmMlo4nSYjEYrhfE8rDy+IoAfRljtuos+12zxM1/5aX7md36bU5/9DKWBJCtAGDzPAR5faALPEAcSXYsd98+C1iW6VOQqQ+lpAVb4RHGdMKrhBxFlXmCDkLBRo4Xzy8d2HtN0i7WOj7oBjBH0aeDuKMVTvsQzhjPGUptOsKp07e/M+FRZ0vO4AaHncd6xGgsT4dxygSt3/VVZUvw//5r26ZN89itfQvgCowym1AwGEzY2bnHt6nU+uHyZvL9B2tvE9Vc9uHWadUqtyZXCyySlzEmLApVOMHcDPFIc+lmt9T3BvC8E9Sjg+ReeZ3llmVani/Vit49Kj0Jl5FlGWRSgjCujaXOoKl1JfFjPujKdtDhVD4ux+iPP8b6r+TKz6O2RSJ3aoEp9+GKLU5FkJyfvFZw5PWAyuP2dq7LXUh26dc0f/Nm7dDxYrgnCLy4x3p8w2ku5+FSbGEMDt+CO231U6rEVm+VsDBfrlq3NbUbGx9sd8v9+8zsMslk+J8At3MGH347A8/iFzz7P9e1dPrj1aF1Oj2r7WsBIIbQCkxGFEikNyXCAyge4jMs3YVKHJMYNzwKXAngTqIGsg3keYU4jwhMkpcXWW3D2GegtQOTjNWJe/uxTdJfPUO+usNbX3NreYWdzEz54H+wEL8j5zNO/iPAlylrWt7ZINn5EvvXmY51jXpYY44EFnZbkKEopscon9yS+8dHKEPmCSFj8AvzAI4oaPHH+IvNz8w/9mdZa9vZ2+MPf/z9599JrPP3UU0RxjJCSSz96nZurN1i/dQsz3UCUUp8Y2AEXAGRwqDIrcINFTxk4MVUrvQl8wO0g/X73ehWV9piBnpCfHB7P5r4ry/3Oc9BsgJczHSbm6AnauBJW28JwC0wIWsLBEJJPW+r2PiaEZGH5Al/52Z/lS698mXy0TzoeMRoMuXT5Gutr62xcf53Nm9+l1ZlnfnGFf+83/h55Mqa3v8MbP3yVTKWs7eeH8lKPY34Q8XO/9lts37zGcHOV/+Sf/S5PvfASK+efQAtBnmbkeUaRu+GnYRjRbi6QZxnpOGE/6VOWpdvsrHWk3KJg0DsgikJqtTqNWp1Ou0O3OwcqR5ceWpecxt0De8x4a48Tcr5yAWwORQqv9xy3K8Gyw647Vz+AL36VL9zqI9e2kdxCTgFHldeueHHg7p0zdxxXDxeExLh9ReL2uQ+ANy3YUcEfffMHbPY1l177Plu7u+z2+od8L6f1pfGtwcfQDSzG44HnHPZu3XJUAE/SiEMGRUI22IVxz3XuHDUhqJ08wdLSCt3uAm+/eQU97kP+4ZGtJ040efLcAmHskxcpqq+IGh3wAkcQnJrneWAE1twu/VJ9/+D4mtLzCYQFzzi1eGOR91mv9wU81bWpQMjDlo0mk5Q9Yz8kPlRot0CKwgnGHTWLW5S9EiYJZIUmkDC2grLQ9CaarYFibnBAPbZcONtha2OIfcSsya/97V9j4/332Lj6/mGrXXW+FfXJenCqWWOx26A/zjhQu+TbY4Z5TnHEG1Sbxt2ORErBudNL9NIEbj3SoT6yFaPhNN2ngQG5ytE2oT/eICsq+UQFJGCriUtMf06AHMwEUjC7G6ik6QC8Nk5rIM0gl5gsZOuNEv/5hFZDEMmAINTIRp3wxJNos4sn9vmprket04Rmg9XzZ3n31T3e23qbx8kVlIVG+BJpLaVvEUojtCXQGVJpEBnCCxHWR9jAEds86QYLWouw9nC62MOYtZbdnR3KomB7ewvf90EINjc36fd7jEb3z42ePXOGs2fPPNRnPqhoF8wyO5X1cPt7y84yo/fT0fOFyxJX/199ZgVyKgHDT3WjYnWgQGFgXICJQeVQZjAYuAAn8mG/hLIGtWXQfUgtkLihhj8BChSH5gmY7wQsdALmWnD5xk0a9Zhz5+c5+8xZNrd22NrcIk3GWOsTBDFnzywhWaIsTrKw0GZ0sE9/b4/rO3+DuU+r70dZ1GjRXVjhSz/zZezLL8BkwLkXXqC1uAhCOu+jDGWpDpsPPM/H81xuQxlBWboyVlmW5JOEUim0MfjNBp4XEIYxXhA4zp4UBIGPkAKjoTXXpqVLmlnOCOfpHuerjL02uW8wYcVXqTxo1T1m8LIMo8YU0wLx0fEH1T1pmQUN4ErLVXm5P31U9HWDk0ZYq47dwo3VVdIsY+vWOsPJhCT9MCL3AoEfCNfBZO/DN77DrrzxJmEcE9Zi6p0Wo0GP/v4enjJE1gGx6tOElHTnOjQ7LeJGjXqzTqZyyrJwzO4jVquFzHXrKFWQFwJPa0QQITzjJN0RTqRVa5c+M/pQ0NViD4e2OsKymJbqHPHf88DzJP59BqQ+0OlXAKDPQwKeJEUn6Yccs8K1pxeKu5LhciApoZKGMRZKK1DK0s9gfWRZPujR7DQ4e7rFq7cevVPr13/113mVf01x9QP2XWUdiTvflieo+RLlGZabDdpz82xsjRj0CoalIDPmto2iKgnczYQQLC90aN2KH0vs7lHMjAcgFIgcxRa57ZGoHoPxKqo4eu3upqxWcBiLFAPMAZh7UF0sHhu7Q+pRwdw8CNtE5E6GL5xfoVQlnh3yrD+i247xV2KW4yfpX/8B7x32Az2aqdIR94TFAZ5AIZVCqwwrnKS68GOwEZYQvAirA6wQlMoQ+D7teo1xnrt2TPvgooSD4YDBcMDN1ZsPdcxhEPDkk0/w5Ve+9MCvqTpb7jVo7+jzqsdRcDTGJd1zbhchvJd5U6BwNJ6wcBsn4vZevE+hVXUEXOdVqqEMHBm7KOHWABoWGh5sZWB8kC3Ip61see74O5+w1ukjm8DNGeo0oBkrQpmwu/0BtfNnWT5xgs++8jP0BkN2d/fpHSQM+2OyScaJpRb1eoMwjLlw8QKbN9e4+f41vvE3r8JjAJ56s8PS6fN88ctfYLlZp+1LVs6cwfd8jLEYOwU8hcYYRzr2PB8hQ4zwUFagtaIoCrIsY7TfA08igwAhfHzfzfnyfB+kxCIIIx/pSXQJ9VaT5nhMM8sPRTIfB/B4po0RBYWs9MnvWP3W4I9G2HxAweAwiD4qtnf08ythwT6uArLKbC+5ycwDX+F2GcrNrU02tzbve6y+L4hrEq0tYiqA+CD2/ptvU2+1aHRadBfmSSZDxsMevjLE1gVN1ZkLIeh0WjQaNcLIp9msY9KUcpJ8CPDEUUi3XUfpHFG6cTtemSOMRXjGtZ0Y6wDPtKR1mLGR1Tn5M8CDOXxIAZ6U+PIxAU/1xIdpUqi4LHeqMVbHLS2s77oU+51W3PHcs8sBzy4HZJOCYabYN/CnN1POtTNONngsTsypp8/T+eESXlRH5I5PJHDR7+efX+L5FxZ5/8Y2AxuzYww39nbpF5qJAWNnyP2j3IExhrVrN8gOerR4NBL4o9pcOkCGE6w34MbmN9ka77A76aP2DceSrz40DbzL1R++x41Lv+danC1YIkYL/wAb5Aivx//413/BXGOBTucUuydeorf2No8rYVvmOUpZcl+AH9HOS5oioyEDpIjBi0hMTOo5uUFfRgRG4xUFCo9f+eVf4sufe47f++f/M+9v7rN2MKGDi2I+jkpGGAT8va/9O7z08hd4+vkXH+g1MTPhwArw3K0fogpQmrgS6wEOlKQ48bN5HD+v24BGCWFx70Amv8fyeBRO34/NKnU7BVa5rM7lbahloA7gG5fANiDsQK0Lg4krYa1uw6mGe3S6MJnA4JNprHsss4Ayls31TbZX1ziztMhTF5+jNT8Hfo1skiK0phmHzJ1fQZzKnITEYBU/aeGbOZoLS2x98B676zecfP9j2PLJZV56+QW+8MI5FuoNalIS4LuZctYyHpckY0uWOCV26Xl4oYf23VBbMX2AwGoPgjpxPabeaNBuzVOLawReg0DG+PhIK4imrdhlUrC3vkUxHh4KaFYjUR7ZBhNskmHT7K5SFtZYDnb7jIv08HMqekQVZFRUyS0ciHkbl71ZxwGbleljlRmH5y2q9pgHtzI1ZJmhEbnhwA868H60n2CVRZiSdDwizxOKPKWRWWrK8QIrrp8QEISSMJLEccD8Yody1GOiPtyQ1Kz7LM3HxLHT9bEYjNVIFCAQIqYaN1WqEh+JZCacKKUkCAI8z3NlLwDl2uFLo1w5xj5iW/pXXzyPLTJEkdHWmv1c0840+6OCnNnkZU8IPCFn4+qxnKzHZKUiKdXhVmaYRYMalyIW1qWTq6LK0W1P4JyzX2gmYyfAFJaKEx6sa9hLLIXikQSOKpMYPF8SRAFeIWAKYjyg3Wlz4swpNoYJNzYzLu/s0y812TQqqYTbHgQyaGO4dOMWOpuwWHfdIp8Y4OlIvDBGBJCr88SNBu1xj2uTbdIsc6nHYzON0Rqjj75njh286kpIsmSQp+Rmj36Rk6QJ+ejxOU2mdItdoyiLlHK0SVFsUUQSr9nBb3UQrQVE3ELELbx6G98XBNIwHzpyp/INF06tUI+bnFsqMIVhtXfAer//2MdXmQTOnznFUxfO89JnXmJ5eRn5EKJgR0UDBQ7UuMjG0az8wIkDrihoTLuxdlO4VcCOggsxnKvByZrLaMwPYKFw6q7VtlaRKn1c95LSbpadH0EYgx+6cjPWObs45LCWm5bTzK2aHuy9xiB/kqaZDSMyLsvz12/BCQ9aBq5noBXIHMKRG0ORZi7LPMyh5oN0nMqfGLPWMhxn7PeG7O716M53aMQ1Yj+kSCbkaUaRpkTNGgfbq+xuXOPKpbd56sLTPPnk07z/5ju88dY7vPne++jHTG0tLy7x/DPP0olrxL6HtKCx07EFikmWk6mSEqen4rpw3OgZz/MIw5AgiKlFHtJqlPJcE4Zfo17rUK83qNUa+MLHQ+LjmgfqUUzDCuatpWcdcKjGojyO6UlKvVSE1h4GRdXe5bI5lijv42mX7z9KczDMEgdj4DvA13H3Xw2XOXkRN1piDnfMlRr6SWYd00ctmqZpq8852v3l4/bHXDlRSfmArsazYIqSfGLxooAyLygyTTAdu3KncrXn+TTqLTrdBcbDjF5YOYWZ1YB2FDHXbhJFIQYPbQTSk9PHtFyFdCMyPLdWMMbx0pEuY20qcrKdihkZjFYYrSjR96Vn3xfw/PxnnsQmA+xkQJ6X7I8K5ocFV03C2Lju5dhCKD0C6blhbqpAac25doPRJKVfKjIcwcgKQaKnBy9AC0FgXW1RW8gFTtVRSLQ1WGNZEOAVhtEE6r6lKSRhTdJTghLYV1CL3ZdqYCqHzQOLyBld4EkI4xB/NKurAtSaTbrLK/g3N9jLhry3eTu+9rmd2Fwtsrv5d20sb67tcLoOyzWnzfdJIZ5WW+KFNWQQo7hIO5tnodnjYK/EmoO7Ap6j5ZDHNw3JG1SxSoGmKCYMiwmMto7lE6zSGBQWic4UxfY6+c47+F5K2F1EzC3jzy1Do4NstAnaiwSRTxh41EROkQ1gdMDZ5TlOducwSnKQaNQ1we5kSH5v8YmPNCkEnifxpEfkezx38Um++soXufjM0wg/mrX1P8h5MgM8lSR9IBzI8ZtOMTgO4VwOsXQcnNg64cyBhtMxnOjCYhd8De0cOkM3LMQcef9qZlYjhLx05Z8ogkYbai2we+6ekwLajUO/42hg2TRw8fgwiejHYXc+kKEIAAAeFUlEQVSALgV89x242IazTbiloCxxaa47QuiJgl4O860Hj44/yqQQzh/ayl8dvyOwwDgt2O+N2N3ZZ2FhnkB4+EAyGJKkCVmaUZMh22sf8NZr3+VP//QNfuHLBU2vxre+822u3FznxmM2WMT1BmdOnebFZ56jEQR4whFRDYJcK7IiZ5ylZMqirDkUC60CZ9/3iKKYKGwgjcGXlrwQBL5P4MXUam0ajTb1epPAC/CFm6CNtcRhRN0PWZAeO8wyJY8LeGya0cRlXK9P/1ZlWi3gY2kUQ6otvxLyhNv9aQ83TuJf4EDNi8DngM/iAv0GTo15C3d/nsE1xLgi1ky28FDLzs72ryowqo4pV84X+A+4hoUBnSsyq4isQeUalVryqdxaNcm9Ml9GNBpt5ucX6e0PCcPbhQAE0BLQrUXMddrEcUxpBEI733gIeoTAWIHTJ/BcHbkiKQsHJo1RYA3WeMhQulZ1ozGlcuKu97md7gt4nnnxIr4tCEyBUoZESRItEWETGYRIL8Bagy5LtNLE9Yir73/A1fc/oCV8trd2yVVCmsLpEx1WVtpsvbFOt+1xfj6k1mqQTBKGw4S1HcNKM2SxE3Nq5TRXNvd4f3OXeAHmFhssLnV4+uKz6EKgcvjV5QWEJ0C4ybrGuEi03x8zmZSk6YMlLfe3b2F0SafTwd/bo7SWAreQdxBMjOXd69fZPfgwO+fO7PYJH5Y8eDu/t4+/lcBWyn2/lOO2/bykHCvyQpFOfGzZxCqfF059kfd5m9HkwxyoeXy6eFwnP8a24/uxnB7znScpBAoRFOTDPfSl10h+9B3nOIS7gUQkCOoC0RSoOQntGN2qocOA/b0RBwdjnjzXJl4+QbR4EtlZ5qmnNM9dlfwff3aV4hFAjxSCcwstnnziSS5evMjLn/vclNxXxygw5YMrPFdJCo1z3OH0d4wrlR9sOadQOdpAgJVwU8GudZHh5QHk1mU05muwr51DraLT6nMqUcH+aPb3dADpEOdgrZP+KAQkuxDXIKpBWYC+11CuT9KODgu7i02At0dweeQyPveyQQ6jwm1o42M4Jx9YWZhnaWGBg9LQ7x0w7D2c/tODmgH2dve4/M67jHs7LC0vsLg4Ty2KGAyGjMcTXn7xea58/y1e/dYb7JWa7/7gR6y++S6vTUYUj9lRGNfq/JP//n/gV776Cj//+ZfwjHG9E0CGZlQWjLOUYZpRFJoiV6SlItOGwlrwIqJ6h7YFVQZMhmMmwzHDcUoUxdTrDeKwQbvZpTs3T9j0sfWQoS3YP9jDWEtD+gTxIrVU0SzHDHl8wBPhSsJzwDdwmRqDE/Zs4Mo9X5j+PMCBlhruvkyYZWd/iCtZVUv0MnADt9a+iANAXeASDhidOzwCSdQ4hS5HqGLAyLhMbxPwfBeESOEAuq0kehS3kfc/ykYD1zgVBGDLgjyBYuKyRD6O8lGnap2X1OMF6o1l6q0Vas19/PB2IQAp4MIJOHOiw/LKWawfUmhDYQxSeoeDcKXVKDTWavxKVhrPJRKMQRtNnhUuuSAlMRHoEqkMunT1oft50/sCnqJI0FahTIm2hlwLCi2whcHTHnJKDqpSkJ60xJGh2ZSYSUGhFalyOh80YpoLHYTYYJhpNvoFpw1kSUk2sWQWao0Gp5YXWF5eZG2YIKSgu9wmrnsYYai16/T2x/SSMRcWniCOQjxPkKUlILBWMDfXIU1y0uTByjTvvPUmBzs7h9maSl5/AAzKklGaUZb6vjwhASx7sBzBfOhk9+911S2fLNgB2N7fxWiL1gadlZR5SlmkFPmEdAJ3cO5xfHhzjEDn47c8y5wyp5EkBzdoDPeplYoWMwdjSihz0BNgACbK8KMxmefjZwXzeUFDgb9j8epjgvlbnJ2MCMdDRnXLtQTWylntWgIXm7C8vMjC0iIgEV6A9Hz8qI4IIrwwZr7TYnFxicWlJeaXlvACD+GBVo4c/aAJnqN7uGJGPK6iuGL6S9XyOgbGxoGdCe7v+xbqqRupMJnAXjrrBLnT7B1/19aBpcp3GqYO1YLOp40Ieupcf9z2ANdU249OPlX36zCF8hgyVQYYJSlGHJBqjzx7cBQVMONx7fNgCeJkkrC3bRhMxjQ3d2nVa5zsxIxGKaNRytbmPqs319nJNRrYL3JypZy67qOcYGW1Nt7yKT7/hRc5e/YkQRhgjJpmtaCwljQrGU9y8rygyEuyvCDNcwqtMVISxDUiazDWQwQZhoRSK4JAUquFNFt1gmBKYMWN4ZBCYpQmHY6R2mU2h8UYpQtCHFCZTK/fo5rAfQ9tZpQGM33fqmOxGgoKbi+p/EWFN0ocV2fvyPtW3KIqc1vDBSk9HLfn6HHr0sdoedtrC8A3U42f6Q06FZpHmwenXwBkBsLppJwsmxL8zbQ7U0DowUoEedjE1LtIv05WQH+UURqBlQEEEZQ5EdCSguWVLu2FLkGz7cpO2iCN67yC6UXSGiM0HtOukekqtNML70ZJaMf/MgJrfUcIlx5aunFC99ur7wt4sskQYRTCaLQwZMqSKUtp3AdLYR0qE8IRzUQGZkIcGoaDhKwsmZTuS9NhSNRsgIBBakgyQ7ssyXIXOWW4iGBxbp5Gs0EYBAghmF/qgs4pS4X0BeNswtbBLn7k02jVicOAkRxPBd88PD8iTzKy9MEcyZuXLuEPEoxSt7XnjoFhqRgkKQg5/VLufiElsOQJFkNLuwZe/7h1hB/PtvY2kcKRvzwtybKMLEtJBmPSHKRoYmx1vdx5KgwF5lNzDh9leZ4RWo0IINu5Tm3Sczfa9P81YLXToVAZiCFUlfcMCCXUPJCTFGtTrN3B78JKDMsBNGvwPQ3SzNLUgYTPduC5J+a4+MwTQIAMY7yoRticQ9bbyFqboN7EC0Kk72avaVtipnLt1kisebCYsyo1VRHlvb6bCowMgR3roszquX2gVjii8hDnQB+UlF05zNtyp9M3VuWd//FjtmMupU2OieZmgGGSMEwS3Lb24Afp49Zzk9u/0/tZmmaYNGO033egQMCzizWSRDGclEzevUbB7KsbGcPoGBoZws4C7fNP8+JzT7C8OIeVAjXlW1ojKJQmzRTjJKcsCvI8I00z0jyntAYjJWFcQ1tBqSVWBCjjJqT7gSSuhTQaNQd4BFhj8DyJsBZbKpLhmHKSIfOcg3xIZgo8XKlo5zHPzTBTQK6acxQz3SvF4ZxaJG7/C3EApoIoJfA+cCCEK+McueY1HKDymekH7dxx3Gq6HisApafHYcwsMKooFlJMfd8DAPzK8umJCjUdhaHc3xo4vxf4sNyAtFGnaC6ijGA4TMgVpGnuxk/4IbLMaQBzUrB0cpHm/Bx+vemEYo3Fm4ITa+1hKdOTEivFbZo7zqwDPHYqRGgs1hpXIvZ8tKex9v6iA/fX4bm+gZDW1a4DjxCJbyHNc7RRaKMoyhJVKrTSDEPfAY0kw/YTdKoPPzoZjDjY2HKkNNzFT0dwYDnUv7FZSrG3x1995xLrRYknBWdbTW5dz9i43mMtep2b62PWbk1YP/sm8uQKtYV5oix3IkRSYIzFNyXRA4aZf/5X35/O33AT2o9abzRmfeeA06dOszE+gL27kVcFFsmkaJJHGeics7hzOj6q6+PZeze/TrPWptXosjR3ilajQUfMoRYbdCYt+uMuN7d6GDuDaRmfLtD2UTYYDaiFATWhya5eYr6fHjqNyskcHXR5VO20IjOGAJmrXwsNInFpYeHBK234qQX4pw0oPTDSPawHMrmKePsGpQelFJQCCiExXojxQnTQQgU1rF+HWhsbxZggBK8OXozw4gc6x1BCUzonVA3quJfF0hEP78wmVpX/Ahcx3n/E37+1j9cerkaW4tbs0fLjg3xClXC2uAzd23splTr/x3V//+ov/Cz/4Lf/IU/Nd7HSo18YN2Wm0OhSMymN685KC0yeMZlMGI/dQ3sS43sEgc/+/oTtrU1GeweYJCUyIPyQKIyI4og4lEhfoeyEdGQIhZP46/kJ5UGPbGebN5U6VDlu8bj9oI5PswAsA/8xjv5wA+fvq1Eu53FdVnM4cFObPjxmenYfACy0eHq+xfvrtzCFRSh3jH1cyet3mVZIbjMD7FATJXXhgrCqa7PC+WZ6LNa6BgJjH647bQBExj0C5YKsCQ6IVUNRRSjpj8ds7d6gvHIdCBAiwNoEY0qkLbkgHUDvBh4XLj7J/IkTyHoTssSBHcs0K+MewlowbghqnucYYw4H51aZICnlVK9JIDwP3w+Q0gMvRZYKVd77G74v4Nl+5xZWuLS1rcpXuEGNpTUoYyiMptTudyslhdZkpWaUKfYze9iVtTdIsdqgp4jO4MDO0bb1nVHCO9qwnheMjUVYweC9HQYHCaNcs3qtz2hYIHNF78pNavt9bLfl5ihNAY/WpTs+82DLulT6Q6VNAbRbdfYOUr73+hp+nlLzAl554RwvffkXubl+wAfXNli7fsmhUAQ9cmyuGRi3yYS4L7rmubRq+iF0fVQp5eNldabpGK1KsjwhScdIGSLwsdqQFzlZkX6IR/IwTvXTYMNsQllalMnxRiVeYQmZdRJWEVd1xZ1I1RTQTMl8fpXEm9ZshJzWwsWU7GhATv+vqo1bwBYGkxlS5bqZSuvSwdYUWONRyhQlA5QMKIOY0vMpPJ9UBhjpYx9QDay0kJj7CwUyPT8/ciW8TN3+PR4FOx/K1nyE+TxcWvzf2vFbpSPzMPfmnc/9uEvqP/dbv8VLP/0znDx5gvFYY/ycQghsaVCFRhWG/ihlMBkxmiSgC9IsJ8sL8ixzewpOl2d4sM/wYB9PFaAUulROd0U70mZQl3jCIoyCwokRYi3KCxjdWqf3wWXWtD4EPBGuRCQQnGyeZFSMGBUPJ7IwwYGQPs7PP4Gbg9XHAZoKEID7ru7sDKtKzj1ABAHNWg2hXW1YAa/iskdy+jl338kKpDW3beBHNbeqLHRmnJ+C2xTVPtISZlx/MT3ndPp6aZxa+XBkGZcFRelA7Iwq7SbsSWEJIxd8xTVBs9MhiOtY6TvOjgTsrKRlrZ3OxrIYY1BKTVWjb98fq8yPEM4RC+EhPB8viKYzuR4xw7N3ZfvwpI/eZJWjrOZ9lMy6lSoppgS3ALLpZTgYZfRHLnle7St9bt/qd8YZB+PscJJsbCx77+0ymL7f+ur48KAPPtjA296laAYYY5FSIAVoXTjA8xCtlNV51eLaIXBaWuzS749YX92nK+HixRVeeuYUv/mPfofvvXaTP//L17m1ehlj8um5ZIwLCAqXNvVwi7bruXMp9J2wpuLSH12mH48VRUFRFIwnI/Z7H53QrY7oJ2ljG2UJJRllOWJ+YvH0bP6MYJbpkUwBjjdtNQ5cirYi+lntiL5Wu+cIMUsLCw0inzqv6dclPLClIw2bsQNEnnZ/ozBQGFJbkk+fX/FvMlyq+2GuczHN2HxktUaAH0/BzR3e0uLuz2qC3cNEu5XT/klaF/9/s09b5fBu9kv/8Hd4en6JTqdDf5BjfIHxXeZUFYai0Owd9P+/9s6sN44rPcPPqVNLd3MVF+0SZGsZaYLYicd2MkjGCIJc5gfkIrnIVZCbIEB+Sn5IEEyQiwAJBgGyODOAE4/iwYxlyZJtkhLJJtndtZ8lF6dOd5EjUpStSJZRL9AgWeylqrrqnPd83/u9H5N0TJanCGrKoiQvCso8IysL8qqkqhQHu9tM9obMaxAN4dEYV5GjdOPpZhFaY0uF0jVK1Ziwz+7WJlv3f8Em5tfuFykC1ufOYuG5CY+f257gRMWXcCXjBbOKLO+G7gsMfMqp7QN0AMxLSRJFCOVeoHGE59lQbvFmZ6XuXt/XJjyVdY/GQ/PUhMcfi2GWrvOEKWiKHoYHlhSFPmYUERZE5JryJn3BYG7e9VOzbtnpZDEudeUdlH3Vom8ArbWeRn882otzQeBWpjJEWkA2neOPwYmEZ2m+lbc3TvjUEGukcSHz9hfrv0jVnJglnJ/AiFl6RDQns2T2JbUJlL+ZfbrhXvPTd0Sn+Xsrh1FR0d+pptvaNt3PU+mZAEu9Hn/xV3/NYGERQsnGl/f4zw9/yk9/9hGpAbH1hJCCsNjjj//wHf7oDz7g335yl/rgU7CbgEDhGHq7c8ROdTR07B1OeswCkd5l+NXHVAQuDJvzIpqxvryYwN7BLnG+RT/b5IJR02jOAbN0lU/fCAuDynUCl8Jp60LpHlHkfkrcdhm4Csl2QE43buemdkJWq9zv1dilm4La3SeFnYWv/WDjB6c5mtw4p09s+HvsWb2rhIDFFVjfc2LbDQ5fWf4z/SB4WrzqwqsOrwf+9N3fpMgNWaa49+gxURSS9BIWBivUdU1eTtj84gHjyT5pOmJ0MGxW/AGTtGRvb4+94ZD9gxF5llLlBUL2KOvKZRWqimw8ISZAGhgM+vSSHgdpjq5ytCpgsMhWnvLlMcUX2hruPvm8KX/3VrCnw3bz+C/cfXgRwVUEv4uZ6nYMjgzFwM+ZjT1/grsXxzQp5eGQrBi5yNRzwhculLiRNmQWYPDzoLew8Dqj08LP0f6s+Lk7ZaZR2uHkhZcBtsbQX4HBIlMjyHRvjC3Hrg1E6PbUp67qqkJVri1Fm+TUtRuphBD0er1pe4mknyDCGGSERoByFV7H4UTCc+m33pgyxVqZqTOm1p78ON2LpUl7IVz7CyxGBE3Uxzohl7Fo4/qlKKOpjcHoempWqJpOqDRipFAExEHAspRTXwXr1dwClmVEEgTEgWsdL5rUQ+il3Kcsv1tZXuD86ipXzp/nwrlzBEmCwvLm9ev88tPPpl+cMpayVgx3dllcvcrSmXl+/0fv8b8/z3n4+WMcbaqbI57NjnZa0+IlZD650sNdUj4U6ONeU8rGq1jLBSLg6oULPB6Pycdfv2WHw8sjcelojC1S4rygZw8Ta0+e25qkEpciktZ5sEjl0lq92gny4siFbqcmn9atUGmiLCZwoWKlXQsU3Xi5eDJU2ZkZWZvytcm9DxM/r5Ozl7r6VaOHoDH3wkWaAvP09hEBs0a3Gd9c09ChQxu7G4/QSJQJMGKXSseYYkAo5lEqpSz2ycaPSQ+GTEb77G59hQxjZJiwN6o5GI0Yj8YUeU6ZZpRZRlVvNat9jVSu/UCBpNaaQdaj3+thCsAqBAo12WScjk9se2JtxKWLF1m/eJaPJ/vo/V3Yf7ZFwNGMxzZ2Gv3wY80Z4PvADVzp+R7uPr+Cc1b+pHm+qTTa2GMX6L7aKxAwOfIcH3nxm/2M4XV67WX01xmJn/b8NuF5FkWzfv9iSTKfYIxAlQrSHGEVtuWI7PtnBUIigwgb2mlvNWut61EIIARxnEydlqUMsYHEigApY4TQBCeQxxMJz/m338CbGam6xuDcL62hIT7W5e6EdYaB+JAUBGHYhFnc/5Q2KK3Jshyjaoyqqctsmo/zymtrQWuDDEKiICJJIkd2rHsf2xx0L+kRyXBq6Ebg2J9smI89JeFZXzvDrZs3+I07d1hdX3U+PFqzcnmd9fU14iiiqmu0gVIZhsM9zmYZC+uCDz74bbLJAx5+/j+46cMHAj3H9jvhg5x+qolx05af/oLW8yJmMaFXQHgCwdn186QWeCGE5+UgG4+RZcZcVdNvtvkwrBcLwuzmd0YGzTejDht1mcSltXRjsBXK5hJvmEtt3P894VGNs3DVaHiqRpvWVml5eJKS41ZPz2tZI5j57PhIqh+YfCR0yYKuOLYzsq/26jfn4TXoltDhNcLD+79E9hKCOCardsHMIVlC2iWMPqAst8knW47w7O+xv/k5MuoRxgOeDGuytCAvnGC1SnPK0Zhq8hUC08TG5zAE5CJwKbBeTD9JkDYmiiSRtGSPH5NOxk+9tgMhCWXM/Pw6t27d4dZbt/l0c4fswT2Muv/M4ztKBFzTT3uoz9Uczt9qE3efP8FlOlaB+zjCUwNaWaojXWnb40aCc1KOhNOBtkdUT7zaqea69bcnPi+q+MQTGM3pelIJQAkI4pC4H1NXmjwrCHWADDUqlISRnIqQjTaEBDgZlov4WaWmAmUXyGiqsWWEDCVaWxC2aQLtXncSTtzvHO0IjrUEUWvylhEEgSM4tZs6vPDI5+LiOHLl6kHA3MICURQThiGqdsK0ssypiwyjm7r5wNXSB0HTSyUIkUFEHEfUqqZWNUVWIKUkDEPCMJzakA8GA8IoRErpKsaMQZ+Qx2vj5u07vPPue/zw/fe5+b07BHEEMqCfxOwPd8n2d/mHf/oJ27mi2BeYeMAoyxHbm/zgnTe5+/EN4BqOxwe4QKaXrUXMGmcY3PTWvpz9tAWzKbfdV9dHgF5eqqvWmn+5+9+HwomvAw7GD4maAKuP7mjcwJPgBOR+m6edbfhvYgIMS6gqN3gsAPPCvYfvAadwZMc0L/QRoKbfPClusPO9e3xExr9/xixl6KtongeeUsfN/rWNhAtgy8K/brkVoS9hb8NriHJODkl36PB18I///HdsbH/Jxs6XpKMJV9dvcv3S93n/d35ImIxQZoetJxscDFMmBymTosDmFUqP+Oz+Y8KoR9Lro4IQ8oxkMmIeO01Nx6Tsj3P20i3m5q5RRAVlLFhYXSUM5xBxQrlVoY4xTrpx4TZv3fwBf/m3f0NiFNnBiI2PH3F37QL3l64/8/gOSxSejhT4GfBR6/kW573TloC04Y9vgNMVysCJg/2LfWuJ6shrZWu7L4E5Gv19UWibkp50DiIcUbtyBs70NaUu+OiTT5DRgDBMnDN8HBMmMWEkXdDCCra2thFY4khw49YV9vf32d0ZUlZO02O0ZmnxDEaD0oa6tqyfPc/a+lmGwyFl6dJhf/bnT9+vEwlPEEq00c0IK5m2/AlDEMIJtGQ8JTnALO0lBSZwHj2FUU73g3ZCpX7CoB+DmW9ydwallcvLCSdCkkHYODAKpInccrsJZbnwluugq7UmmOsjmpIbGUduQjtlf6KzZ8+xsrbGwsoKIpSIwNm+y1Dyxptv8ns/+oCP77rLdHllmWR5BR2G5HXF0mKf1XPrrF++ws7Go8ZPxV+2nrzEPL0w2ic2vJbHa3tE6/ltl4eXB/UNHVZfBTSKADsVKvvVjU80en+M9tltx9/aNBMOV7IIe5iiWlyZZztN5QmTp6d+wLHM0kaeEPm8e976/bTwq6y2rMjvqv/8GlB2phlqw19lIYejQ8dhZmDfocPpkGV7lPU+tTpg51FBtf0FBxslYTwmLzMORiO+uj+hzGqqsqbMS6x1bvmjyQQpQ8I8wogAmxdIcm5jWaHPgB4fss8YQ2EsVbkLtYASUj0hinuEQUSmdknt4fhOAFxO5rl+7RrX33ubSPb44ot7fPqLT7B7ioWFHutvfe+ZxzfPTKvqJ1BfDNDG00jNcSOrvyd9f8baOtmItyLweYH2WOXHL3+P+zzCy1gi+/f3Y1B7nOkJmO8FzPUC5nsKKQxFVTHe2aYoBEXuelHGsaTXCzl3fg2spa5rHj18QpJIFhd7XLl2jqIsmWQZm5vbFEVFXRkWF4YUhaEsDYN+jzSrGI1SNjY2GE9ysvT4EfWZhMco57orpJw5IoYhVjjNjRACEQTT/1mlXElZI/Y0AnRdIo2adjrtJT3iOCGK5FSBnefti7MpNWtSZBhDEIXEPZDShcCstui6wmoFSYxt/BeEgDB0UaLTYHV1lcXlZXpzcyhrkAYETq908fIV3n0frvz9j4nigLVzayRLZzBRTKkUq0sxZ9ZXWLt8id1N58czK4Jua3K8lK1NeFKmLZynSpOjhMc3D+hUFs+CbZ19n0v3qx3ffA/cGT56ZQRHtpfMBo/242mrGh+789UM7bJQT2n9PhytavSd2J83wuPjhN5DqE14PI57z3YfrtN87rdHTt/hdYHWOSIoCWNFtgPjepfH4ZBk/iseb5dsbJRUI059UUU4z5sr9FlkmR9zQNHcZXnV0tyku8yow6+bNwRCcDVZ4NrVy1x++zZFWvOrXz3g3//jQ1g4R//qTc7efOOZ+zPPbLHi7z/DN4uoeLLjCYu2blE1bn2GFzvA4THJz5x+zPILrpcBPw75MU8AfQGL/YClpZA+CiEMZVWzU+6xs10w3MnJK9fzb24QuE7ndUWW5Tz47AkLiwlrZxep6pqqrinKko3NTSbjirLQLCzEjMeaLDVcvLBMVSnGo5QHDx4w3EsZjY5XRYr/j8Z1HTp06NChQ4cO3ya8oP6/HTp06NChQ4cO3150hKdDhw4dOnTo8J1HR3g6dOjQoUOHDt95dISnQ4cOHTp06PCdR0d4OnTo0KFDhw7feXSEp0OHDh06dOjwncf/ASSJgz0YH8cIAAAAAElFTkSuQmCC\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xSbPGZ9h3Ls"
      },
      "source": [
        "''' 6. PyTorch 내에서 제공하는 ResNet34 모델 불러온 후 FC 층 추가 및 Output 크기 설정하기 '''\n",
        "import torchvision.models as models                                                       \n",
        "model = models.resnet34(pretrained = False)                                               # models resnet34모델을 불러온다. 모델 구조가 imageNet 데이터에 대해 미리 학습된 파라미터 값을 함께 불러올 수 있다. \n",
        "                                                                                          # false이면 모델의 구조만 불러오고 모델 구조 내에 존재하는 파라미터는 특정 initializer에서 랜덤으로 샘플링한 값을 이용해 모델을 불러옴\n",
        "                                                                                          # 이때 비슷한 모델끼리 분류하는 모델을 이용한다면 더 정확도 높은 모델을 구축할 수 있다.\n",
        "num_ftrs = model.fc.in_features                                                           # models를 이용해 불러온 resner34모델에 대해 fully connected layer을 구성하고 있는 부분에 접근. \n",
        "                                                                                          # in-features는 resnet34 모델의 fully connected layer의 input에 해당하는 노드 수를 num_ftrs로 저장\n",
        "model.fc = nn.Linear(num_ftrs, 10)                                                        # fully connected layer의 input에 해당하는 노드 수를 이용해 CIFAR-10 데이터의 클래스 수인 10개로 Output을 설정. \n",
        "                                                                                          # CIFAR-10을 분류하고자 하기에 최종 OUTPUT의 노드 수를 10개로 설정\n",
        "model = model.cpu()\n",
        "\n",
        "''' 11. IMAGENET 데이터로 학습이 된 ResNet34 모델을 불러온 후 Fine Tuning 해보기 '''\n",
        "model = models.resnet34(pretrained = True)                                                # pretrained = true는 imageNet 데이터를 잘 분류할 수 있도록 학습된 파라미터를 resnet34 모델에 적용해 불러오는 것을 의미\n",
        "num_ftrs = model.fc.in_features                                                           # CIFAR-10 데이터를 분류하기 위해 최종 output의 벡터를 10 크기로 설정해야 한다. \n",
        "                                                                                          # CIFAR-10 데이터의 클래스 종류는 10개이므로 각 클래스를 포현하는 원핫인코딩 값의 크기가 10이기 때문이다.\n",
        "model.fc = nn.Linear(num_ftrs, 10)                                                  \n",
        "model = model.cpu()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.001)                          \n",
        "\n",
        "for epoch in range(1, EPOCHS + 1):                                                        # ImageNet 데이터에 학습이 완료된, 즉 학습을 통해 얻게 된 파라미터를 resnet34 모델의 초기 파라미터로 설정한 후 CIFAR-10 이미지 데이터를 10개의\n",
        "    train(model, train_loader, optimizer, log_interval = 200)                             # 클래스로 분류할 수 있도록 기존 실습 내용과 동일한 환경으로 실험을 진행\n",
        "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S28EbPlCQrRH"
      },
      "source": [
        "## 5. Transfer Learning\n",
        "강아지와 고양이를 구분하는 딥러닝 모델을 구축한다. 이때 앞에서 서술한 ImageNet 데이터를 미리 학습해 놓은 딥러닝 모델(pre-trained model)을 가져와 재학습시키는 방법을 사용한다. 이를 전이 학습(Transfer Learning)이라 한다. 이때 pre trained model을 로드한 후 fully connected layer 앞단 네트워크의 weight를 가져오고 fully connected layer을 디자인한다.\n",
        "\n",
        "이때 fully connected layer도 그대로 사용하고 output layer만 디자인하기도 한다. pre trained model은 우리가 분류하고자 하는 문제보다 훨씬 더 큰 문제를 푸는 모델이기 떄문에 output layer의 dimension을 수정해야 한다. 그 후 우리가 보유한 데이터를 input으로 해 학습을 진행한다. 일반적으로 pre trained model의 fully connected layer 이전의 weight는 학습하지 않는다.\n",
        "\n",
        "이때는 weight를 freezing한다고 표현하며 보유하고 데이터를 갖고는 fully connected layer 부분의 weight만 학습을 진행하는 것. 이 과정을 fine-tuning이라 한다. transfer learning은 보유한 데이터가 많지 않을 때 사용한다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/",
          "referenced_widgets": [
            "7517300a47d84660b1c1f737e23f683d"
          ]
        },
        "id": "aklCHjJ3NHj3",
        "outputId": "80937468-8d2b-4635-a472-7f33992e286e"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    DEVICE = torch.device('cuda')\n",
        "else:\n",
        "    DEVICE = torch.device('cpu')\n",
        "print('Using PyTorch version:', torch.__version__, ' Device:', DEVICE)\n",
        "\n",
        "BATCH_SIZE = 32\n",
        "EPOCHS = 10\n",
        "\n",
        "''' 3. 개미와 벌을 분류하기 위해 개미 이미지 데이터와 벌 이미지 데이터 불러오기 (Train set, Test set 분리하기) '''\n",
        "data_transforms = {\n",
        "    'train': transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),                                                 # 해당 이미지를 224 사이즈로 변경하되, 변경되는 이미지 픽셀 값은 랜덤으로 선택된다.즉, 이미지 내 랜덤으로 선택해 224 사이즈로 변경하는 것\n",
        "        transforms.RandomHorizontalFlip(),                                                 # 해당 이미지를 50%확률로 좌우 반전\n",
        "        transforms.ToTensor(),                                    \n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "    'val': transforms.Compose([\n",
        "        transforms.CenterCrop(224),                                                        # 해당 이미지를 224 사이즈로 변경하되 센터를 바꾼다. \n",
        "        transforms.Resize(256),                                                            # 모든 데이터를 256 사이즈로 변경한다.\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.5, 0.5, 0.5], [0.5, 0.5, 0.5])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "data_dir = '/content/drive/MyDrive/data/hymenoptera_data'\n",
        "image_datasets = {x: datasets.ImageFolder(os.path.join(data_dir,x),                        # 이미지 데이터를 불러오는 것을 의미. ../data/hymenoptera_data 위치에 접근해 train 폴더와 val 폴더에 접근해 데이터를 불러온다. \n",
        "                                          data_transforms[x]) for x in ['train', 'val']}   # 기존 정의한 data_transforms의 학습 데이터셋에 이용되는 전처리 과정, 검증 데이터셋에 이용되는 전처리 과정을 각각 적용하는 것\n",
        "dataloaders = {x: torch.utils.data.DataLoader(image_datasets[x],                           # 불러온 이미지를 mini-batch 단위로 구분하기 위해 utils.data.dataloader 함수를 이용. 각각 적용하기 위해 dictionary 구조를 사용\n",
        "                                              batch_size = BATCH_SIZE,                     # mini-batch를 구성하는 데이터 개수는 기존에 정의한 batch-size로 설정\n",
        "                                              num_workers = 0,                             # num_workers = 0 은 처리하는 프로세싱에 관련된 내용이며 멀티 프로세싱으로 진행하지 않는 한 0으로 기본값을 이용. \n",
        "                                                                                           # 프로세스를 동시에 처리하는 개수만큼 num_workers를 지정\n",
        "                                              shuffle = True) for x in ['train', 'val']}   # 데이터 순서를 섞는 의미로 shuffle = true \n",
        "\n",
        "''' 4. 데이터 확인하기 (1) '''\n",
        "for (X_train, y_train) in dataloaders['train']:                                            # 32개 이미지 데이터가 1개의 mini-batch를 구성하고 있고, 가로 224개, 세로 224개의 픽셀, 채널 3\n",
        "    print('X_train:', X_train.size(), 'type:', X_train.type())\n",
        "    print('y_train:', y_train.size(), 'type:', y_train.type())\n",
        "    break\n",
        "\n",
        "pltsize = 1\n",
        "plt.figure(figsize=(10 * pltsize, pltsize))\n",
        "\n",
        "for i in range(10):\n",
        "    plt.subplot(1, 10, i + 1)\n",
        "    plt.axis('on')\n",
        "    plt.imshow(np.transpose(X_train[i], (1, 2, 0)))\n",
        "    plt.title('Class: ' + str(y_train[i].item()))\n",
        "\n",
        "''' 6. 불러온 특정 모델에 대하여 학습을 진행하며 학습 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def train(model, train_loader, optimizer, log_interval):\n",
        "    model.train()\n",
        "    for batch_idx, (image, label) in enumerate(train_loader):\n",
        "        image = image.to(DEVICE)\n",
        "        label = label.to(DEVICE)\n",
        "        optimizer.zero_grad()\n",
        "        output = model(image)\n",
        "        loss = criterion(output, label)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        if batch_idx % log_interval == 0:\n",
        "            print(\"Train Epoch: {} [{}/{} ({:.0f}%)]\\tTrain Loss: {:.6f}\".format(\n",
        "                epoch, batch_idx * len(image), \n",
        "                len(train_loader.dataset), 100. * batch_idx / len(train_loader), \n",
        "                loss.item()))\n",
        "  \n",
        "''' 7. 학습되는 과정 속에서 검증 데이터에 대한 모델 성능을 확인하는 함수 정의 '''\n",
        "def evaluate(model, test_loader):\n",
        "    model.eval()\n",
        "    test_loss = 0\n",
        "    correct = 0\n",
        "\n",
        "    with torch.no_grad():                                                                   # 평가에서는 gradient를 통해 파라미터 값이 업데이트되는 현상을 방지하기 위해 no.grad 메서드를 이용해 gradient의 흐름을 억제\n",
        "        for image, label in test_loader:\n",
        "            image = image.to(DEVICE)\n",
        "            label = label.to(DEVICE)\n",
        "            output = model(image)\n",
        "            test_loss += criterion(output, label).item()\n",
        "            prediction = output.max(1, keepdim = True)[1]\n",
        "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
        "    \n",
        "    test_loss /= (len(test_loader.dataset) / BATCH_SIZE)\n",
        "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
        "    return test_loss, test_accuracy\n",
        "\n",
        "''' 8. PyTorch 내에서 제공하는 미리 학습되지 않은 ResNet18 모델 불러온 후 Output 크기 설정하기 '''\n",
        "import torchvision.models as models\n",
        "model = models.resnet18(pretrained = False).cuda()                                          # model resnet18 모델을 불러와 imagenet데이터에 대해 미리 학습된 파라미터 값을 함께 불러올 수 있다. \n",
        "                                                                                            # false는 모델의 구조만 불러오고 initailzer에서 랜덤으로 샘플링한 값을 이용해 모델\n",
        "num_ftrs = model.fc.in_features                                                             # model를 이용해 불러온 resnet34 모델에 대해 fully connected layer을 구성하고 있는 부분에 접근한다. in_features는 input에 해당하는 노드수를 지정\n",
        "model.fc = nn.Linear(num_ftrs, 2)                                                           # fully connected layer의 input에 해당하는 노드 수를 이용해 새로운 레이어를 추가하고 개미와 벌을 분류하기 때문에 클래스 수가 2개로 output을 설정\n",
        "model = model.cuda()\n",
        "\n",
        "''' 9. Optimizer, Objective Function 설정하기 '''\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)                               # back propagation을 통해 파라미터를 업데이트할 때 optimizer을 정의. learning rate 값을 0.0001로 설정\n",
        "criterion = nn.CrossEntropyLoss()                                                           # 모델의 output값, 원핫인코딩 값과 계산한 loss는 crossentropy를 이용해 계산하기 위해 설정\n",
        "\n",
        "print(model)\n",
        "\n",
        "''' 10. 미리 학습되지 않은 ResNet18 학습 실행하며 Train, Test set의 Loss 및 Test set Accuracy 확인하기 '''\n",
        "for epoch in range(1, EPOCHS + 1):                                                          # 학습을 진행할 때는 전체 데이터셋을 이용하는 횟수만큼 반복문을 실행\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval = 5)                         # 정의한 train함수 실행. model은 기존에 정의한 모델, train_loader은 학습 데이터, optimizer은 adam, log_interval은 mini-batch의 index를 이용해 과정을 출력\n",
        "    test_loss, test_accuracy = evaluate(model, dataloaders[\"val\"])                          # 정의한 evaluate 함수를 실행해 검증 데이터셋에 대한 loss값과 정확도를 저장\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, test_loss, test_accuracy))\n",
        "    \n",
        "''' 11. IMAGENET 데이터로 미리 학습이 된 ResNet18 모델을 불러온 후 개미, 벌 이미지 데이터에 맞게 Fine Tuning 해보기 '''\n",
        "model = models.resnet18(pretrained = True)                                                  # 다른 데이터셋으로 학습해 얻게된 파라미터 값을 이용해 새로운 데이터에 학습하는 fine-tuning과정을 진행하기 위해 true로 설정\n",
        "num_ftrs = model.fc.in_features                                                             # model을 이용해 불러온 resnet34모델에 대해 fully connected layer를 구성하고 있는 부분에 접근.\n",
        "model.fc = nn.Linear(num_ftrs, 2)                                                           # 개미와 벌을 분류하기에 클래스는 2개로 지정. imagenet데이터의 클래스는 1000개이므로 최종 output 노드 수는 1000개로 설정하지만, 이때는 2개로 지정\n",
        "model = model.cuda()\n",
        "\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr = 0.0001)\n",
        "EPOCHS = 10\n",
        "for epoch in range(1, EPOCHS + 1):\n",
        "    train(model, dataloaders[\"train\"], optimizer, log_interval = 5)\n",
        "    valid_loss, valid_accuracy = evaluate(model, dataloaders[\"val\"])\n",
        "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".format(\n",
        "        epoch, valid_loss, valid_accuracy))\n",
        "    \n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using PyTorch version: 1.8.1+cu101  Device: cuda\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "X_train: torch.Size([32, 3, 224, 224]) type: torch.FloatTensor\n",
            "y_train: torch.Size([32]) type: torch.LongTensor\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n",
            "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "ResNet(\n",
            "  (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
            "  (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "  (relu): ReLU(inplace=True)\n",
            "  (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
            "  (layer1): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer2): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer3): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (layer4): Sequential(\n",
            "    (0): BasicBlock(\n",
            "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (downsample): Sequential(\n",
            "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
            "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      )\n",
            "    )\n",
            "    (1): BasicBlock(\n",
            "      (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "      (relu): ReLU(inplace=True)\n",
            "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
            "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    )\n",
            "  )\n",
            "  (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
            "  (fc): Linear(in_features=512, out_features=2, bias=True)\n",
            ")\n",
            "Train Epoch: 1 [0/244 (0%)]\tTrain Loss: 0.699236\n",
            "Train Epoch: 1 [160/244 (62%)]\tTrain Loss: 0.563642\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.8657, \tTest Accuracy: 45.75 % \n",
            "\n",
            "Train Epoch: 2 [0/244 (0%)]\tTrain Loss: 0.696494\n",
            "Train Epoch: 2 [160/244 (62%)]\tTrain Loss: 0.574629\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 0.8293, \tTest Accuracy: 43.79 % \n",
            "\n",
            "Train Epoch: 3 [0/244 (0%)]\tTrain Loss: 0.693888\n",
            "Train Epoch: 3 [160/244 (62%)]\tTrain Loss: 0.591289\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 0.7536, \tTest Accuracy: 55.56 % \n",
            "\n",
            "Train Epoch: 4 [0/244 (0%)]\tTrain Loss: 0.494049\n",
            "Train Epoch: 4 [160/244 (62%)]\tTrain Loss: 0.577575\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 0.7657, \tTest Accuracy: 54.25 % \n",
            "\n",
            "Train Epoch: 5 [0/244 (0%)]\tTrain Loss: 0.461665\n",
            "Train Epoch: 5 [160/244 (62%)]\tTrain Loss: 0.550261\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 0.7374, \tTest Accuracy: 54.25 % \n",
            "\n",
            "Train Epoch: 6 [0/244 (0%)]\tTrain Loss: 0.477244\n",
            "Train Epoch: 6 [160/244 (62%)]\tTrain Loss: 0.471464\n",
            "\n",
            "[EPOCH: 6], \tTest Loss: 0.6014, \tTest Accuracy: 70.59 % \n",
            "\n",
            "Train Epoch: 7 [0/244 (0%)]\tTrain Loss: 0.486024\n",
            "Train Epoch: 7 [160/244 (62%)]\tTrain Loss: 0.432582\n",
            "\n",
            "[EPOCH: 7], \tTest Loss: 0.7743, \tTest Accuracy: 60.78 % \n",
            "\n",
            "Train Epoch: 8 [0/244 (0%)]\tTrain Loss: 0.416265\n",
            "Train Epoch: 8 [160/244 (62%)]\tTrain Loss: 0.461668\n",
            "\n",
            "[EPOCH: 8], \tTest Loss: 0.6523, \tTest Accuracy: 68.63 % \n",
            "\n",
            "Train Epoch: 9 [0/244 (0%)]\tTrain Loss: 0.437802\n",
            "Train Epoch: 9 [160/244 (62%)]\tTrain Loss: 0.496307\n",
            "\n",
            "[EPOCH: 9], \tTest Loss: 0.7698, \tTest Accuracy: 64.05 % \n",
            "\n",
            "Train Epoch: 10 [0/244 (0%)]\tTrain Loss: 0.347137\n",
            "Train Epoch: 10 [160/244 (62%)]\tTrain Loss: 0.764821\n",
            "\n",
            "[EPOCH: 10], \tTest Loss: 0.6653, \tTest Accuracy: 69.93 % \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/resnet18-5c106cde.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-5c106cde.pth\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7517300a47d84660b1c1f737e23f683d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=46827520.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Train Epoch: 1 [0/244 (0%)]\tTrain Loss: 0.644069\n",
            "Train Epoch: 1 [160/244 (62%)]\tTrain Loss: 0.258888\n",
            "\n",
            "[EPOCH: 1], \tTest Loss: 0.2474, \tTest Accuracy: 92.81 % \n",
            "\n",
            "Train Epoch: 2 [0/244 (0%)]\tTrain Loss: 0.168042\n",
            "Train Epoch: 2 [160/244 (62%)]\tTrain Loss: 0.186289\n",
            "\n",
            "[EPOCH: 2], \tTest Loss: 0.1930, \tTest Accuracy: 94.77 % \n",
            "\n",
            "Train Epoch: 3 [0/244 (0%)]\tTrain Loss: 0.080499\n",
            "Train Epoch: 3 [160/244 (62%)]\tTrain Loss: 0.114115\n",
            "\n",
            "[EPOCH: 3], \tTest Loss: 0.1879, \tTest Accuracy: 94.77 % \n",
            "\n",
            "Train Epoch: 4 [0/244 (0%)]\tTrain Loss: 0.103036\n",
            "Train Epoch: 4 [160/244 (62%)]\tTrain Loss: 0.060239\n",
            "\n",
            "[EPOCH: 4], \tTest Loss: 0.1970, \tTest Accuracy: 94.12 % \n",
            "\n",
            "Train Epoch: 5 [0/244 (0%)]\tTrain Loss: 0.049806\n",
            "Train Epoch: 5 [160/244 (62%)]\tTrain Loss: 0.094379\n",
            "\n",
            "[EPOCH: 5], \tTest Loss: 0.1868, \tTest Accuracy: 92.81 % \n",
            "\n",
            "Train Epoch: 6 [0/244 (0%)]\tTrain Loss: 0.031492\n",
            "Train Epoch: 6 [160/244 (62%)]\tTrain Loss: 0.072770\n",
            "\n",
            "[EPOCH: 6], \tTest Loss: 0.2170, \tTest Accuracy: 92.16 % \n",
            "\n",
            "Train Epoch: 7 [0/244 (0%)]\tTrain Loss: 0.027202\n",
            "Train Epoch: 7 [160/244 (62%)]\tTrain Loss: 0.025805\n",
            "\n",
            "[EPOCH: 7], \tTest Loss: 0.2120, \tTest Accuracy: 93.46 % \n",
            "\n",
            "Train Epoch: 8 [0/244 (0%)]\tTrain Loss: 0.023435\n",
            "Train Epoch: 8 [160/244 (62%)]\tTrain Loss: 0.042672\n",
            "\n",
            "[EPOCH: 8], \tTest Loss: 0.2394, \tTest Accuracy: 92.16 % \n",
            "\n",
            "Train Epoch: 9 [0/244 (0%)]\tTrain Loss: 0.059535\n",
            "Train Epoch: 9 [160/244 (62%)]\tTrain Loss: 0.036683\n",
            "\n",
            "[EPOCH: 9], \tTest Loss: 0.2530, \tTest Accuracy: 92.81 % \n",
            "\n",
            "Train Epoch: 10 [0/244 (0%)]\tTrain Loss: 0.051263\n",
            "Train Epoch: 10 [160/244 (62%)]\tTrain Loss: 0.122258\n",
            "\n",
            "[EPOCH: 10], \tTest Loss: 0.2202, \tTest Accuracy: 92.16 % \n",
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 720x72 with 10 Axes>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 322
        },
        "id": "xwFEM6egVjT0",
        "outputId": "740a4688-707c-4c53-b3af-70be3914ddd4"
      },
      "source": [
        "image_datasets = {x: datasets.ImageFolder(\"drive/MyDrive/hymenoptera_data\", data_transforms[x]) for x in ['train', 'val']}\n",
        "## https://blog.naver.com/gogsally/222257938679"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-25-83e4ae55f4f1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/hymenoptera_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-25-83e4ae55f4f1>\u001b[0m in \u001b[0;36m<dictcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mimage_datasets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mImageFolder\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"drive/MyDrive/hymenoptera_data\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_transforms\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'train'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'val'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, transform, target_transform, loader, is_valid_file)\u001b[0m\n\u001b[1;32m    254\u001b[0m                                           \u001b[0mtransform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtransform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m                                           \u001b[0mtarget_transform\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtarget_transform\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 256\u001b[0;31m                                           is_valid_file=is_valid_file)\n\u001b[0m\u001b[1;32m    257\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mimgs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, root, loader, extensions, transform, target_transform, is_valid_file)\u001b[0m\n\u001b[1;32m    124\u001b[0m         super(DatasetFolder, self).__init__(root, transform=transform,\n\u001b[1;32m    125\u001b[0m                                             target_transform=target_transform)\n\u001b[0;32m--> 126\u001b[0;31m         \u001b[0mclasses\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_find_classes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    127\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mroot\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclass_to_idx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextensions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mis_valid_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torchvision/datasets/folder.py\u001b[0m in \u001b[0;36m_find_classes\u001b[0;34m(self, dir)\u001b[0m\n\u001b[1;32m    162\u001b[0m             \u001b[0mNo\u001b[0m \u001b[0;32mclass\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0ma\u001b[0m \u001b[0msubdirectory\u001b[0m \u001b[0mof\u001b[0m \u001b[0manother\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    163\u001b[0m         \"\"\"\n\u001b[0;32m--> 164\u001b[0;31m         \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0md\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscandir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdir\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0md\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_dir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    165\u001b[0m         \u001b[0mclasses\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msort\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \u001b[0mclass_to_idx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mcls_name\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcls_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mclasses\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'drive/MyDrive/hymenoptera_data'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aNO2Ii8-t6bl"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}